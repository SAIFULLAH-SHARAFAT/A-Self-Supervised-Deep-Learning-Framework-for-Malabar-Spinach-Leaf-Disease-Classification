{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimSiam ResNet PreTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-05T20:47:59.117349Z",
     "iopub.status.busy": "2025-07-05T20:47:59.117047Z",
     "iopub.status.idle": "2025-07-05T20:47:59.123422Z",
     "shell.execute_reply": "2025-07-05T20:47:59.122829Z",
     "shell.execute_reply.started": "2025-07-05T20:47:59.117319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simsiam_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simsiam_model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim=2048, hidden_dim=2048, out_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim, bias=False),\n",
    "            nn.BatchNorm1d(out_dim, affine=False)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    def __init__(self, in_dim=2048, hidden_dim=512, out_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimSiam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights=None)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projector = MLPHead(2048)\n",
    "        self.predictor = PredictionHead()\n",
    "        for m in self.backbone.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "                m.requires_grad_(False)\n",
    "\n",
    "    def _forward_backbone(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.projector(self._forward_backbone(x1))\n",
    "        z2 = self.projector(self._forward_backbone(x2))\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"SimSiam(backbone=ResNet50, projector={self.projector}, predictor={self.predictor})\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T20:48:35.824903Z",
     "iopub.status.busy": "2025-07-05T20:48:35.824643Z",
     "iopub.status.idle": "2025-07-05T20:48:35.831576Z",
     "shell.execute_reply": "2025-07-05T20:48:35.830971Z",
     "shell.execute_reply.started": "2025-07-05T20:48:35.824884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simsiam_pretrain.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile simsiam_pretrain.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "from simsiam_model import SimSiam\n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filepaths = [\n",
    "            os.path.join(root_dir, fname)\n",
    "            for fname in os.listdir(root_dir)\n",
    "            if os.path.isfile(os.path.join(root_dir, fname)) and fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        if len(self.filepaths) == 0:\n",
    "            raise RuntimeError(f\"No images found in {root_dir}\")\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filepaths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            view1 = self.transform(img)\n",
    "            view2 = self.transform(img)\n",
    "            return view1, view2\n",
    "        else:\n",
    "            return img, img\n",
    "\n",
    "def negative_cosine_similarity(p, z):\n",
    "    p = torch.nn.functional.normalize(p, dim=1)\n",
    "    z = torch.nn.functional.normalize(z, dim=1)\n",
    "    return -(p * z).sum(dim=1).mean()\n",
    "\n",
    "def pretrain(\n",
    "    root_path=\"/kaggle/input/minida/mini_output1/pretrain\",\n",
    "    checkpoint_dir=\"/kaggle/working/\",\n",
    "    epochs=150,\n",
    "    batch_size=64\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"logs\"))\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = UnlabeledDataset(root_dir=root_path, transform=train_transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    model = SimSiam().to(device)\n",
    "    base_lr = 0.05 * batch_size / 256\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"simsiam_checkpoint.pth\")\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(\"Resuming from checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.backbone.load_state_dict(checkpoint['backbone'])\n",
    "        model.projector.load_state_dict(checkpoint['projector'])\n",
    "        model.predictor.load_state_dict(checkpoint['predictor'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    print(f\"Starting SimSiam pretraining for {epochs} epochs...\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_idx, (x1, x2) in enumerate(dataloader):\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            x2 = x2.to(device, non_blocking=True)\n",
    "            p1, p2, z1, z2 = model(x1, x2)\n",
    "            loss = 0.5 * (negative_cosine_similarity(p1, z2) + negative_cosine_similarity(p2, z1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'backbone': model.backbone.state_dict(),\n",
    "                'projector': model.projector.state_dict(),\n",
    "                'predictor': model.predictor.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }, checkpoint_path)\n",
    "\n",
    "    torch.save({\n",
    "        'backbone': model.backbone.state_dict(),\n",
    "        'projector': model.projector.state_dict(),\n",
    "        'predictor': model.predictor.state_dict()\n",
    "    }, os.path.join(checkpoint_dir, \"simsiam_pretrained.pth\"))\n",
    "    print(\"Pretraining complete! Model saved to\", os.path.join(checkpoint_dir, \"simsiam_pretrained.pth\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrain()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T20:48:51.877032Z",
     "iopub.status.busy": "2025-07-05T20:48:51.876766Z",
     "iopub.status.idle": "2025-07-05T23:10:33.215549Z",
     "shell.execute_reply": "2025-07-05T23:10:33.214543Z",
     "shell.execute_reply.started": "2025-07-05T20:48:51.877014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-05 20:48:57.026027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751748537.227460     338 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751748537.289623     338 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using device: cuda\n",
      "Starting SimSiam pretraining for 150 epochs...\n",
      "Epoch [1/150] Batch [0] Loss: -0.0016\n",
      "Epoch [1/150] Average Loss: -0.0099\n",
      "Epoch [2/150] Batch [0] Loss: -0.0135\n",
      "Epoch [2/150] Average Loss: -0.0284\n",
      "Epoch [3/150] Batch [0] Loss: -0.0292\n",
      "Epoch [3/150] Average Loss: -0.0444\n",
      "Epoch [4/150] Batch [0] Loss: -0.0753\n",
      "Epoch [4/150] Average Loss: -0.0815\n",
      "Epoch [5/150] Batch [0] Loss: -0.1145\n",
      "Epoch [5/150] Average Loss: -0.1373\n",
      "Epoch [6/150] Batch [0] Loss: -0.1810\n",
      "Epoch [6/150] Average Loss: -0.2327\n",
      "Epoch [7/150] Batch [0] Loss: -0.2824\n",
      "Epoch [7/150] Average Loss: -0.3476\n",
      "Epoch [8/150] Batch [0] Loss: -0.4095\n",
      "Epoch [8/150] Average Loss: -0.4570\n",
      "Epoch [9/150] Batch [0] Loss: -0.5279\n",
      "Epoch [9/150] Average Loss: -0.5678\n",
      "Epoch [10/150] Batch [0] Loss: -0.6039\n",
      "Epoch [10/150] Average Loss: -0.6428\n",
      "Epoch [11/150] Batch [0] Loss: -0.7262\n",
      "Epoch [11/150] Average Loss: -0.7124\n",
      "Epoch [12/150] Batch [0] Loss: -0.7652\n",
      "Epoch [12/150] Average Loss: -0.7390\n",
      "Epoch [13/150] Batch [0] Loss: -0.7747\n",
      "Epoch [13/150] Average Loss: -0.7773\n",
      "Epoch [14/150] Batch [0] Loss: -0.7423\n",
      "Epoch [14/150] Average Loss: -0.7624\n",
      "Epoch [15/150] Batch [0] Loss: -0.7551\n",
      "Epoch [15/150] Average Loss: -0.7984\n",
      "Epoch [16/150] Batch [0] Loss: -0.7784\n",
      "Epoch [16/150] Average Loss: -0.8081\n",
      "Epoch [17/150] Batch [0] Loss: -0.8563\n",
      "Epoch [17/150] Average Loss: -0.8290\n",
      "Epoch [18/150] Batch [0] Loss: -0.8141\n",
      "Epoch [18/150] Average Loss: -0.8313\n",
      "Epoch [19/150] Batch [0] Loss: -0.8278\n",
      "Epoch [19/150] Average Loss: -0.8381\n",
      "Epoch [20/150] Batch [0] Loss: -0.8282\n",
      "Epoch [20/150] Average Loss: -0.8459\n",
      "Epoch [21/150] Batch [0] Loss: -0.8323\n",
      "Epoch [21/150] Average Loss: -0.8509\n",
      "Epoch [22/150] Batch [0] Loss: -0.8754\n",
      "Epoch [22/150] Average Loss: -0.8549\n",
      "Epoch [23/150] Batch [0] Loss: -0.8576\n",
      "Epoch [23/150] Average Loss: -0.8561\n",
      "Epoch [24/150] Batch [0] Loss: -0.8423\n",
      "Epoch [24/150] Average Loss: -0.8561\n",
      "Epoch [25/150] Batch [0] Loss: -0.8525\n",
      "Epoch [25/150] Average Loss: -0.8692\n",
      "Epoch [26/150] Batch [0] Loss: -0.8660\n",
      "Epoch [26/150] Average Loss: -0.8424\n",
      "Epoch [27/150] Batch [0] Loss: -0.8859\n",
      "Epoch [27/150] Average Loss: -0.8751\n",
      "Epoch [28/150] Batch [0] Loss: -0.8912\n",
      "Epoch [28/150] Average Loss: -0.8783\n",
      "Epoch [29/150] Batch [0] Loss: -0.8845\n",
      "Epoch [29/150] Average Loss: -0.8773\n",
      "Epoch [30/150] Batch [0] Loss: -0.8705\n",
      "Epoch [30/150] Average Loss: -0.8675\n",
      "Epoch [31/150] Batch [0] Loss: -0.8620\n",
      "Epoch [31/150] Average Loss: -0.8800\n",
      "Epoch [32/150] Batch [0] Loss: -0.9097\n",
      "Epoch [32/150] Average Loss: -0.8528\n",
      "Epoch [33/150] Batch [0] Loss: -0.9088\n",
      "Epoch [33/150] Average Loss: -0.8789\n",
      "Epoch [34/150] Batch [0] Loss: -0.8867\n",
      "Epoch [34/150] Average Loss: -0.8889\n",
      "Epoch [35/150] Batch [0] Loss: -0.8998\n",
      "Epoch [35/150] Average Loss: -0.8876\n",
      "Epoch [36/150] Batch [0] Loss: -0.8964\n",
      "Epoch [36/150] Average Loss: -0.8814\n",
      "Epoch [37/150] Batch [0] Loss: -0.9174\n",
      "Epoch [37/150] Average Loss: -0.8823\n",
      "Epoch [38/150] Batch [0] Loss: -0.9004\n",
      "Epoch [38/150] Average Loss: -0.8837\n",
      "Epoch [39/150] Batch [0] Loss: -0.8411\n",
      "Epoch [39/150] Average Loss: -0.8716\n",
      "Epoch [40/150] Batch [0] Loss: -0.8108\n",
      "Epoch [40/150] Average Loss: -0.8789\n",
      "Epoch [41/150] Batch [0] Loss: -0.8886\n",
      "Epoch [41/150] Average Loss: -0.8927\n",
      "Epoch [42/150] Batch [0] Loss: -0.8542\n",
      "Epoch [42/150] Average Loss: -0.8877\n",
      "Epoch [43/150] Batch [0] Loss: -0.8905\n",
      "Epoch [43/150] Average Loss: -0.8985\n",
      "Epoch [44/150] Batch [0] Loss: -0.8962\n",
      "Epoch [44/150] Average Loss: -0.8963\n",
      "Epoch [45/150] Batch [0] Loss: -0.8982\n",
      "Epoch [45/150] Average Loss: -0.8984\n",
      "Epoch [46/150] Batch [0] Loss: -0.9085\n",
      "Epoch [46/150] Average Loss: -0.8948\n",
      "Epoch [47/150] Batch [0] Loss: -0.8656\n",
      "Epoch [47/150] Average Loss: -0.8723\n",
      "Epoch [48/150] Batch [0] Loss: -0.8928\n",
      "Epoch [48/150] Average Loss: -0.9042\n",
      "Epoch [49/150] Batch [0] Loss: -0.8920\n",
      "Epoch [49/150] Average Loss: -0.9054\n",
      "Epoch [50/150] Batch [0] Loss: -0.8891\n",
      "Epoch [50/150] Average Loss: -0.8968\n",
      "Epoch [51/150] Batch [0] Loss: -0.8958\n",
      "Epoch [51/150] Average Loss: -0.8996\n",
      "Epoch [52/150] Batch [0] Loss: -0.9007\n",
      "Epoch [52/150] Average Loss: -0.8996\n",
      "Epoch [53/150] Batch [0] Loss: -0.9236\n",
      "Epoch [53/150] Average Loss: -0.9037\n",
      "Epoch [54/150] Batch [0] Loss: -0.9054\n",
      "Epoch [54/150] Average Loss: -0.9072\n",
      "Epoch [55/150] Batch [0] Loss: -0.9051\n",
      "Epoch [55/150] Average Loss: -0.8986\n",
      "Epoch [56/150] Batch [0] Loss: -0.9262\n",
      "Epoch [56/150] Average Loss: -0.9059\n",
      "Epoch [57/150] Batch [0] Loss: -0.8702\n",
      "Epoch [57/150] Average Loss: -0.9029\n",
      "Epoch [58/150] Batch [0] Loss: -0.8805\n",
      "Epoch [58/150] Average Loss: -0.9019\n",
      "Epoch [59/150] Batch [0] Loss: -0.9359\n",
      "Epoch [59/150] Average Loss: -0.9184\n",
      "Epoch [60/150] Batch [0] Loss: -0.8904\n",
      "Epoch [60/150] Average Loss: -0.8959\n",
      "Epoch [61/150] Batch [0] Loss: -0.8709\n",
      "Epoch [61/150] Average Loss: -0.9132\n",
      "Epoch [62/150] Batch [0] Loss: -0.9377\n",
      "Epoch [62/150] Average Loss: -0.9136\n",
      "Epoch [63/150] Batch [0] Loss: -0.9420\n",
      "Epoch [63/150] Average Loss: -0.9065\n",
      "Epoch [64/150] Batch [0] Loss: -0.9081\n",
      "Epoch [64/150] Average Loss: -0.8977\n",
      "Epoch [65/150] Batch [0] Loss: -0.9014\n",
      "Epoch [65/150] Average Loss: -0.9041\n",
      "Epoch [66/150] Batch [0] Loss: -0.9015\n",
      "Epoch [66/150] Average Loss: -0.9017\n",
      "Epoch [67/150] Batch [0] Loss: -0.9043\n",
      "Epoch [67/150] Average Loss: -0.9080\n",
      "Epoch [68/150] Batch [0] Loss: -0.9053\n",
      "Epoch [68/150] Average Loss: -0.8995\n",
      "Epoch [69/150] Batch [0] Loss: -0.9194\n",
      "Epoch [69/150] Average Loss: -0.9106\n",
      "Epoch [70/150] Batch [0] Loss: -0.8997\n",
      "Epoch [70/150] Average Loss: -0.9162\n",
      "Epoch [71/150] Batch [0] Loss: -0.9172\n",
      "Epoch [71/150] Average Loss: -0.9082\n",
      "Epoch [72/150] Batch [0] Loss: -0.9125\n",
      "Epoch [72/150] Average Loss: -0.8934\n",
      "Epoch [73/150] Batch [0] Loss: -0.8919\n",
      "Epoch [73/150] Average Loss: -0.9102\n",
      "Epoch [74/150] Batch [0] Loss: -0.8746\n",
      "Epoch [74/150] Average Loss: -0.9081\n",
      "Epoch [75/150] Batch [0] Loss: -0.9008\n",
      "Epoch [75/150] Average Loss: -0.9026\n",
      "Epoch [76/150] Batch [0] Loss: -0.9231\n",
      "Epoch [76/150] Average Loss: -0.9111\n",
      "Epoch [77/150] Batch [0] Loss: -0.9293\n",
      "Epoch [77/150] Average Loss: -0.9098\n",
      "Epoch [78/150] Batch [0] Loss: -0.9174\n",
      "Epoch [78/150] Average Loss: -0.9071\n",
      "Epoch [79/150] Batch [0] Loss: -0.9303\n",
      "Epoch [79/150] Average Loss: -0.9183\n",
      "Epoch [80/150] Batch [0] Loss: -0.8729\n",
      "Epoch [80/150] Average Loss: -0.9052\n",
      "Epoch [81/150] Batch [0] Loss: -0.9439\n",
      "Epoch [81/150] Average Loss: -0.8899\n",
      "Epoch [82/150] Batch [0] Loss: -0.9246\n",
      "Epoch [82/150] Average Loss: -0.9167\n",
      "Epoch [83/150] Batch [0] Loss: -0.8875\n",
      "Epoch [83/150] Average Loss: -0.9023\n",
      "Epoch [84/150] Batch [0] Loss: -0.9352\n",
      "Epoch [84/150] Average Loss: -0.9088\n",
      "Epoch [85/150] Batch [0] Loss: -0.8917\n",
      "Epoch [85/150] Average Loss: -0.9148\n",
      "Epoch [86/150] Batch [0] Loss: -0.9141\n",
      "Epoch [86/150] Average Loss: -0.9130\n",
      "Epoch [87/150] Batch [0] Loss: -0.9447\n",
      "Epoch [87/150] Average Loss: -0.9172\n",
      "Epoch [88/150] Batch [0] Loss: -0.8997\n",
      "Epoch [88/150] Average Loss: -0.9125\n",
      "Epoch [89/150] Batch [0] Loss: -0.9350\n",
      "Epoch [89/150] Average Loss: -0.9236\n",
      "Epoch [90/150] Batch [0] Loss: -0.9155\n",
      "Epoch [90/150] Average Loss: -0.9164\n",
      "Epoch [91/150] Batch [0] Loss: -0.9087\n",
      "Epoch [91/150] Average Loss: -0.9207\n",
      "Epoch [92/150] Batch [0] Loss: -0.9114\n",
      "Epoch [92/150] Average Loss: -0.9179\n",
      "Epoch [93/150] Batch [0] Loss: -0.9236\n",
      "Epoch [93/150] Average Loss: -0.9031\n",
      "Epoch [94/150] Batch [0] Loss: -0.9184\n",
      "Epoch [94/150] Average Loss: -0.9101\n",
      "Epoch [95/150] Batch [0] Loss: -0.9161\n",
      "Epoch [95/150] Average Loss: -0.9139\n",
      "Epoch [96/150] Batch [0] Loss: -0.9114\n",
      "Epoch [96/150] Average Loss: -0.9163\n",
      "Epoch [97/150] Batch [0] Loss: -0.9121\n",
      "Epoch [97/150] Average Loss: -0.9279\n",
      "Epoch [98/150] Batch [0] Loss: -0.9135\n",
      "Epoch [98/150] Average Loss: -0.9170\n",
      "Epoch [99/150] Batch [0] Loss: -0.8954\n",
      "Epoch [99/150] Average Loss: -0.9131\n",
      "Epoch [100/150] Batch [0] Loss: -0.8960\n",
      "Epoch [100/150] Average Loss: -0.9179\n",
      "Epoch [101/150] Batch [0] Loss: -0.9311\n",
      "Epoch [101/150] Average Loss: -0.8814\n",
      "Epoch [102/150] Batch [0] Loss: -0.8891\n",
      "Epoch [102/150] Average Loss: -0.9171\n",
      "Epoch [103/150] Batch [0] Loss: -0.9182\n",
      "Epoch [103/150] Average Loss: -0.9138\n",
      "Epoch [104/150] Batch [0] Loss: -0.9130\n",
      "Epoch [104/150] Average Loss: -0.9175\n",
      "Epoch [105/150] Batch [0] Loss: -0.9078\n",
      "Epoch [105/150] Average Loss: -0.9150\n",
      "Epoch [106/150] Batch [0] Loss: -0.9003\n",
      "Epoch [106/150] Average Loss: -0.9123\n",
      "Epoch [107/150] Batch [0] Loss: -0.9448\n",
      "Epoch [107/150] Average Loss: -0.9241\n",
      "Epoch [108/150] Batch [0] Loss: -0.9128\n",
      "Epoch [108/150] Average Loss: -0.9091\n",
      "Epoch [109/150] Batch [0] Loss: -0.9095\n",
      "Epoch [109/150] Average Loss: -0.9037\n",
      "Epoch [110/150] Batch [0] Loss: -0.9113\n",
      "Epoch [110/150] Average Loss: -0.9152\n",
      "Epoch [111/150] Batch [0] Loss: -0.9076\n",
      "Epoch [111/150] Average Loss: -0.9101\n",
      "Epoch [112/150] Batch [0] Loss: -0.9029\n",
      "Epoch [112/150] Average Loss: -0.9042\n",
      "Epoch [113/150] Batch [0] Loss: -0.9254\n",
      "Epoch [113/150] Average Loss: -0.9133\n",
      "Epoch [114/150] Batch [0] Loss: -0.9062\n",
      "Epoch [114/150] Average Loss: -0.9094\n",
      "Epoch [115/150] Batch [0] Loss: -0.9335\n",
      "Epoch [115/150] Average Loss: -0.9183\n",
      "Epoch [116/150] Batch [0] Loss: -0.9161\n",
      "Epoch [116/150] Average Loss: -0.9053\n",
      "Epoch [117/150] Batch [0] Loss: -0.9301\n",
      "Epoch [117/150] Average Loss: -0.9174\n",
      "Epoch [118/150] Batch [0] Loss: -0.9081\n",
      "Epoch [118/150] Average Loss: -0.8845\n",
      "Epoch [119/150] Batch [0] Loss: -0.9270\n",
      "Epoch [119/150] Average Loss: -0.9217\n",
      "Epoch [120/150] Batch [0] Loss: -0.8946\n",
      "Epoch [120/150] Average Loss: -0.9176\n",
      "Epoch [121/150] Batch [0] Loss: -0.9450\n",
      "Epoch [121/150] Average Loss: -0.9176\n",
      "Epoch [122/150] Batch [0] Loss: -0.9128\n",
      "Epoch [122/150] Average Loss: -0.9143\n",
      "Epoch [123/150] Batch [0] Loss: -0.8991\n",
      "Epoch [123/150] Average Loss: -0.9111\n",
      "Epoch [124/150] Batch [0] Loss: -0.9046\n",
      "Epoch [124/150] Average Loss: -0.9133\n",
      "Epoch [125/150] Batch [0] Loss: -0.9006\n",
      "Epoch [125/150] Average Loss: -0.9072\n",
      "Epoch [126/150] Batch [0] Loss: -0.9490\n",
      "Epoch [126/150] Average Loss: -0.9175\n",
      "Epoch [127/150] Batch [0] Loss: -0.8909\n",
      "Epoch [127/150] Average Loss: -0.9126\n",
      "Epoch [128/150] Batch [0] Loss: -0.9175\n",
      "Epoch [128/150] Average Loss: -0.9202\n",
      "Epoch [129/150] Batch [0] Loss: -0.8590\n",
      "Epoch [129/150] Average Loss: -0.9071\n",
      "Epoch [130/150] Batch [0] Loss: -0.8909\n",
      "Epoch [130/150] Average Loss: -0.9146\n",
      "Epoch [131/150] Batch [0] Loss: -0.9153\n",
      "Epoch [131/150] Average Loss: -0.9241\n",
      "Epoch [132/150] Batch [0] Loss: -0.9337\n",
      "Epoch [132/150] Average Loss: -0.9159\n",
      "Epoch [133/150] Batch [0] Loss: -0.9243\n",
      "Epoch [133/150] Average Loss: -0.9104\n",
      "Epoch [134/150] Batch [0] Loss: -0.9104\n",
      "Epoch [134/150] Average Loss: -0.9094\n",
      "Epoch [135/150] Batch [0] Loss: -0.9224\n",
      "Epoch [135/150] Average Loss: -0.9189\n",
      "Epoch [136/150] Batch [0] Loss: -0.9325\n",
      "Epoch [136/150] Average Loss: -0.9170\n",
      "Epoch [137/150] Batch [0] Loss: -0.9352\n",
      "Epoch [137/150] Average Loss: -0.9165\n",
      "Epoch [138/150] Batch [0] Loss: -0.9337\n",
      "Epoch [138/150] Average Loss: -0.9185\n",
      "Epoch [139/150] Batch [0] Loss: -0.9149\n",
      "Epoch [139/150] Average Loss: -0.9090\n",
      "Epoch [140/150] Batch [0] Loss: -0.8920\n",
      "Epoch [140/150] Average Loss: -0.9097\n",
      "Epoch [141/150] Batch [0] Loss: -0.9059\n",
      "Epoch [141/150] Average Loss: -0.9225\n",
      "Epoch [142/150] Batch [0] Loss: -0.9097\n",
      "Epoch [142/150] Average Loss: -0.9121\n",
      "Epoch [143/150] Batch [0] Loss: -0.9243\n",
      "Epoch [143/150] Average Loss: -0.9249\n",
      "Epoch [144/150] Batch [0] Loss: -0.9127\n",
      "Epoch [144/150] Average Loss: -0.9149\n",
      "Epoch [145/150] Batch [0] Loss: -0.9290\n",
      "Epoch [145/150] Average Loss: -0.9304\n",
      "Epoch [146/150] Batch [0] Loss: -0.9339\n",
      "Epoch [146/150] Average Loss: -0.9181\n",
      "Epoch [147/150] Batch [0] Loss: -0.9123\n",
      "Epoch [147/150] Average Loss: -0.9186\n",
      "Epoch [148/150] Batch [0] Loss: -0.9179\n",
      "Epoch [148/150] Average Loss: -0.9195\n",
      "Epoch [149/150] Batch [0] Loss: -0.9176\n",
      "Epoch [149/150] Average Loss: -0.9075\n",
      "Epoch [150/150] Batch [0] Loss: -0.9355\n",
      "Epoch [150/150] Average Loss: -0.9180\n",
      "Pretraining complete! Model saved to /kaggle/working/simsiam_pretrained.pth\n"
     ]
    }
   ],
   "source": [
    "!python simsiam_pretrain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FineTune SimSiam Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T06:20:02.771454Z",
     "iopub.status.busy": "2025-07-06T06:20:02.771103Z",
     "iopub.status.idle": "2025-07-06T06:33:14.487901Z",
     "shell.execute_reply": "2025-07-06T06:33:14.486839Z",
     "shell.execute_reply.started": "2025-07-06T06:20:02.771433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1210, Acc: 0.3870 | Val Loss: 0.9577, Acc: 0.6162\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0841, Acc: 0.4134 | Val Loss: 1.4521, Acc: 0.7071\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0019, Acc: 0.5105 | Val Loss: 1.2403, Acc: 0.6061\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9395, Acc: 0.5521 | Val Loss: 0.7087, Acc: 0.8182\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9791, Acc: 0.5596 | Val Loss: 0.8092, Acc: 0.6465\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8941, Acc: 0.6241 | Val Loss: 0.7275, Acc: 0.7576\n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8907, Acc: 0.6009 | Val Loss: 0.5825, Acc: 0.7475\n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8968, Acc: 0.5906 | Val Loss: 0.5862, Acc: 0.7778\n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8427, Acc: 0.6493 | Val Loss: 0.4738, Acc: 0.8586\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8826, Acc: 0.6224 | Val Loss: 0.5190, Acc: 0.8788\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8319, Acc: 0.6588 | Val Loss: 0.5646, Acc: 0.8283\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8045, Acc: 0.6708 | Val Loss: 0.4469, Acc: 0.8586\n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8108, Acc: 0.6702 | Val Loss: 0.5361, Acc: 0.8283\n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8321, Acc: 0.6540 | Val Loss: 0.5014, Acc: 0.8384\n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8787, Acc: 0.6346 | Val Loss: 0.4580, Acc: 0.8788\n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8573, Acc: 0.6508 | Val Loss: 0.4449, Acc: 0.8687\n",
      "EarlyStopping counter: 6 / 7\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8387, Acc: 0.6503 | Val Loss: 0.4137, Acc: 0.8889\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8239, Acc: 0.6452 | Val Loss: 0.4635, Acc: 0.8586\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8061, Acc: 0.6692 | Val Loss: 0.4592, Acc: 0.8586\n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7450, Acc: 0.7052 | Val Loss: 0.4199, Acc: 0.8687\n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8431, Acc: 0.6602 | Val Loss: 0.4036, Acc: 0.8788\n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8319, Acc: 0.6274 | Val Loss: 0.4150, Acc: 0.8788\n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8679, Acc: 0.6110 | Val Loss: 0.4144, Acc: 0.8687\n",
      "EarlyStopping counter: 6 / 7\n",
      "\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7923, Acc: 0.6845 | Val Loss: 0.3956, Acc: 0.8990\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8174, Acc: 0.6403 | Val Loss: 0.4109, Acc: 0.8889\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Test set results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3199, Test Acc: 0.9495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.86      0.93        37\n",
      "Healthy Leaf       0.86      1.00      0.93        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.96      0.95      0.95        99\n",
      "\n",
      "Confusion Matrix:\n",
      " [[32  5  0]\n",
      " [ 0 31  0]\n",
      " [ 0  0 31]]\n",
      "Test ROC-AUC (macro): 0.9984\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TTA Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.97      0.89      0.93        37\n",
      "Healthy Leaf       0.88      0.97      0.92        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.95      0.95      0.95        99\n",
      "\n",
      "Confusion Matrix:\n",
      " [[33  4  0]\n",
      " [ 1 30  0]\n",
      " [ 0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Seeding for Reproducibility ---\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Paths & Class Names ---\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_pretrained.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "\n",
    "# --- Mixup ---\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# --- Data Loaders with Balanced Sampling ---\n",
    "def get_loaders(batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "\n",
    "    # Balanced sampling\n",
    "    class_sample_count = np.array([len(np.where(np.array(train_ds.targets)==t)[0]) for t in np.unique(train_ds.targets)])\n",
    "    weights = 1. / class_sample_count\n",
    "    samples_weights = weights[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(samples_weights, len(samples_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# --- Model Definition ---\n",
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        checkpoint = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        self.backbone.load_state_dict(checkpoint['backbone'])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes))\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# --- Training/Evaluation Functions ---\n",
    "def train_epoch(model, loader, criterion, optimizer, use_mixup=True, mixup_alpha=0.4):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "            outputs = model(imgs)\n",
    "            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset), np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "# --- Early Stopping Helper ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_acc, model, path):\n",
    "        if self.best_acc is None or val_acc > self.best_acc:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(\"Validation accuracy improved, saving model.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "def main(epochs=25, batch_size=32, mixup_alpha=0.4):\n",
    "    train_loader, val_loader, test_loader = get_loaders(batch_size)\n",
    "    model = FineTuneModel(pretrained_path, num_classes=len(class_names)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    early_stopper = EarlyStopping(patience=7, verbose=True)\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, use_mixup=True, mixup_alpha=mixup_alpha)\n",
    "        val_loss, val_acc, _, _, _ = eval_epoch(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "        early_stopper(val_acc, model, best_model_path)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # --- Evaluation: Standard + TTA ---\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nTest set results:\")\n",
    "    test_loss, test_acc, test_labels, test_preds, test_probs = eval_epoch(model, test_loader, criterion)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "    # ROC-AUC (macro, micro)\n",
    "    try:\n",
    "        test_labels_onehot = np.eye(len(class_names))[test_labels]\n",
    "        roc_macro = roc_auc_score(test_labels_onehot, test_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    # Calibration curve (Reliability Diagram)\n",
    "    def plot_reliability(y_true, y_prob, n_bins=10):\n",
    "        \"\"\"Plots reliability diagram (expected calibration error).\"\"\"\n",
    "        from sklearn.calibration import calibration_curve\n",
    "        plt.figure(figsize=(5,5))\n",
    "        for i, name in enumerate(class_names):\n",
    "            prob_true, prob_pred = calibration_curve((y_true==i).astype(int), y_prob[:,i], n_bins=n_bins, strategy='uniform')\n",
    "            plt.plot(prob_pred, prob_true, marker='o', label=f\"{name}\")\n",
    "        plt.plot([0,1],[0,1],'--', color='gray')\n",
    "        plt.xlabel(\"Mean Predicted Probability\")\n",
    "        plt.ylabel(\"Fraction of Positives\")\n",
    "        plt.title(\"Reliability Diagram\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_reliability(test_labels, test_probs)\n",
    "\n",
    "    # --- Test-Time Augmentation (TTA) ---\n",
    "    print(\"\\nTTA Evaluation:\")\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomHorizontalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomRotation(15),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ColorJitter(0.3,0.3,0.3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(280), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.GaussianBlur(3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    ]\n",
    "    test_ds = ImageFolder(test_dir)\n",
    "    tta_probs = []\n",
    "    with torch.no_grad():\n",
    "        for t in tta_transforms:\n",
    "            test_ds.transform = t\n",
    "            loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "            probs = []\n",
    "            for imgs, _ in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                probs.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "            tta_probs.append(np.concatenate(probs))\n",
    "    final_probs = np.mean(tta_probs, axis=0)\n",
    "    final_preds = final_probs.argmax(axis=1)\n",
    "    print(classification_report(test_ds.targets, final_preds, target_names=class_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(test_ds.targets, final_preds))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(epochs=25, batch_size=32, mixup_alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid loss: Supervised Contrastive + CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T20:56:59.320423Z",
     "iopub.status.busy": "2025-07-06T20:56:59.319505Z",
     "iopub.status.idle": "2025-07-06T21:13:09.220205Z",
     "shell.execute_reply": "2025-07-06T21:13:09.219402Z",
     "shell.execute_reply.started": "2025-07-06T20:56:59.320387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2743, Acc: 0.3448 | Val Loss: 1.0416, Acc: 0.3737\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2386, Acc: 0.4364 | Val Loss: 0.8677, Acc: 0.6566\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1882, Acc: 0.5017 | Val Loss: 1.0483, Acc: 0.6465\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1720, Acc: 0.5604 | Val Loss: 0.9984, Acc: 0.7879\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1784, Acc: 0.5750 | Val Loss: 0.6242, Acc: 0.8384\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1116, Acc: 0.6574 | Val Loss: 0.5287, Acc: 0.8182\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1529, Acc: 0.5761 | Val Loss: 0.5526, Acc: 0.8586\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1647, Acc: 0.5483 | Val Loss: 0.7659, Acc: 0.7374\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1245, Acc: 0.6030 | Val Loss: 1.1365, Acc: 0.7576\n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1413, Acc: 0.5952 | Val Loss: 0.6063, Acc: 0.7980\n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0790, Acc: 0.6868 | Val Loss: 0.4783, Acc: 0.8485\n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1212, Acc: 0.6359 | Val Loss: 0.5170, Acc: 0.8384\n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0870, Acc: 0.6703 | Val Loss: 0.4726, Acc: 0.8687\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1324, Acc: 0.6610 | Val Loss: 0.4566, Acc: 0.9091\n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1050, Acc: 0.6499 | Val Loss: 0.5466, Acc: 0.7980\n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0790, Acc: 0.6306 | Val Loss: 0.5334, Acc: 0.8182\n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0920, Acc: 0.6482 | Val Loss: 0.4640, Acc: 0.8788\n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1113, Acc: 0.6381 | Val Loss: 0.4767, Acc: 0.8788\n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1032, Acc: 0.6231 | Val Loss: 0.4494, Acc: 0.9091\n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0712, Acc: 0.6792 | Val Loss: 0.4448, Acc: 0.8788\n",
      "EarlyStopping counter: 6 / 7\n",
      "\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1239, Acc: 0.6265 | Val Loss: 0.4493, Acc: 0.8990\n",
      "EarlyStopping counter: 7 / 7\n",
      "Early stopping triggered.\n",
      "\n",
      "Test set results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3602, Test Acc: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.92      0.96        37\n",
      "Healthy Leaf       0.94      1.00      0.97        31\n",
      "  straw_mite       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n",
      "Test ROC-AUC (macro): 0.9969\n",
      "\n",
      "TTA Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.94      0.86      0.90        37\n",
      "Healthy Leaf       0.88      0.94      0.91        31\n",
      "  straw_mite       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           0.93        99\n",
      "   macro avg       0.93      0.93      0.93        99\n",
      "weighted avg       0.93      0.93      0.93        99\n",
      "\n",
      "Found 4 TTA-flip examples.\n",
      "\n",
      "Running Grad-CAMs for each class on random test images...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_pretrained.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def get_loaders(batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "\n",
    "    class_sample_count = np.array([len(np.where(np.array(train_ds.targets)==t)[0]) for t in np.unique(train_ds.targets)])\n",
    "    weights = 1. / class_sample_count\n",
    "    samples_weights = weights[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(samples_weights, len(samples_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, test_ds\n",
    "\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.size(0)\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        anchor_dot_contrast = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(batch_size, device=device))\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + self.eps)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + self.eps)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss\n",
    "\n",
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        checkpoint = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        self.backbone.load_state_dict(checkpoint['backbone'])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes))\n",
    "        self.feature_layer = nn.Linear(2048, 128)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        feats = self.backbone(x).flatten(1)\n",
    "        features = F.normalize(self.feature_layer(feats), dim=1)\n",
    "        logits = self.classifier(feats)\n",
    "        if return_features:\n",
    "            return logits, features\n",
    "        return logits\n",
    "\n",
    "def train_epoch(model, loader, ce_loss_fn, supcon_loss_fn, optimizer, use_mixup=True, mixup_alpha=0.4, supcon_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss, total_ce, total_supcon, correct = 0, 0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "            logits, features = model(imgs, return_features=True)\n",
    "            loss_ce = mixup_criterion(ce_loss_fn, logits, y_a, y_b, lam)\n",
    "            loss_supcon = supcon_loss_fn(features, labels)\n",
    "            loss = (1 - supcon_weight) * loss_ce + supcon_weight * loss_supcon\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            logits, features = model(imgs, return_features=True)\n",
    "            loss_ce = ce_loss_fn(logits, labels)\n",
    "            loss_supcon = supcon_loss_fn(features, labels)\n",
    "            loss = (1 - supcon_weight) * loss_ce + supcon_weight * loss_supcon\n",
    "            correct += logits.argmax(1).eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        total_ce += loss_ce.item() * imgs.size(0)\n",
    "        total_supcon += loss_supcon.item() * imgs.size(0)\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, correct / n, total_ce / n, total_supcon / n\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, correct / n, np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_acc, model, path):\n",
    "        if self.best_acc is None or val_acc > self.best_acc:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(\"Validation accuracy improved, saving model.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "    plt.title('Normalized Confusion Matrix (hybrid loss)')\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_per_class(y_true, y_score, n_classes, class_names, save_path=None):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        if np.sum(y_true==i) == 0: continue  # skip missing classes\n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve((y_true==i).astype(int), y_score[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "        except Exception as e:\n",
    "            print(f\"ROC error for class {class_names[i]}: {e}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Per-class ROC Curves (hybrid loss)')\n",
    "    plt.legend()\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_tta_stats(tta_probs, test_probs, class_names, save_path=None):\n",
    "    mean_probs = np.mean(tta_probs, axis=0)\n",
    "    var_probs = np.var(tta_probs, axis=0)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.bar(class_names, mean_probs.mean(axis=0))\n",
    "    plt.title(\"TTA Mean predicted probability (hybrid loss)\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.bar(class_names, var_probs.mean(axis=0))\n",
    "    plt.title(\"TTA Prediction variance (hybrid loss)\")\n",
    "    plt.tight_layout()\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return mean_probs, var_probs\n",
    "\n",
    "def show_tta_flip_examples(test_probs, tta_mean_probs, test_images, test_labels, final_preds, class_names, n_show=5):\n",
    "    orig_preds = np.argmax(test_probs, axis=1)\n",
    "    flip_idx = np.where(orig_preds != final_preds)[0]\n",
    "    print(f\"Found {len(flip_idx)} TTA-flip examples.\")\n",
    "    if len(flip_idx) == 0:\n",
    "        print(\"No flip examples found.\")\n",
    "        return\n",
    "    n_show = min(n_show, len(flip_idx))\n",
    "    for idx in flip_idx[:n_show]:\n",
    "        img = test_images[idx]\n",
    "        plt.imshow(np.transpose(img.numpy(), (1,2,0)) * 0.229 + 0.485)\n",
    "        plt.title(f\"True: {class_names[test_labels[idx]]}, Orig: {class_names[orig_preds[idx]]}, TTA: {class_names[final_preds[idx]]}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"tta_flip_example_{idx}_hybrid_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs, train_ce_losses, train_supcon_losses):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Total')\n",
    "    plt.plot(val_losses, label='Val CE')\n",
    "    plt.plot(train_ce_losses, label='Train CE')\n",
    "    plt.plot(train_supcon_losses, label='Train SupCon')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curves (hybrid loss)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy Curves (hybrid loss)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"loss_acc_curves_hybrid_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_gradcams(model, test_ds, class_names, device):\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from PIL import Image\n",
    "    target_layers = [model.backbone[-1]]\n",
    "    model.eval()\n",
    "    cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    for i, cls in enumerate(class_names):\n",
    "        idxs = [j for j, t in enumerate(test_ds.targets) if t == i]\n",
    "        if not idxs:\n",
    "            print(f\"No samples for class {cls}\")\n",
    "            continue\n",
    "        idx = random.choice(idxs)\n",
    "        img, label = test_ds[idx]\n",
    "        # Convert tensor to PIL image for proper transform\n",
    "        img_pil = transforms.ToPILImage()(img)\n",
    "        # Apply transforms that were used during test\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=[ClassifierOutputTarget(i)])\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        img_np = np.transpose(img.numpy(), (1,2,0))\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        cam_image = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "        plt.imshow(cam_image)\n",
    "        plt.title(f\"Grad-CAM: {cls} (hybrid loss)\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"gradcam_{cls}_hybrid_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "def main(epochs=25, batch_size=32, mixup_alpha=0.4, supcon_weight=0.5):\n",
    "    train_loader, val_loader, test_loader, test_ds = get_loaders(batch_size)\n",
    "    model = FineTuneModel(pretrained_path, num_classes=len(class_names)).to(device)\n",
    "    ce_loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    supcon_loss_fn = SupConLoss(temperature=0.07)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    early_stopper = EarlyStopping(patience=7, verbose=True)\n",
    "    best_model_path = \"best_model_hybrid_loss.pth\"\n",
    "\n",
    "    train_losses, train_accs, train_ce_losses, train_supcon_losses = [], [], [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        t_loss, t_acc, t_ce, t_sup = train_epoch(\n",
    "            model, train_loader, ce_loss_fn, supcon_loss_fn, optimizer,\n",
    "            use_mixup=True, mixup_alpha=mixup_alpha, supcon_weight=supcon_weight)\n",
    "        v_loss, v_acc, _, _, _ = eval_epoch(model, val_loader, ce_loss_fn)\n",
    "        scheduler.step()\n",
    "        print(f\"Train Loss: {t_loss:.4f}, Acc: {t_acc:.4f} | Val Loss: {v_loss:.4f}, Acc: {v_acc:.4f}\")\n",
    "        train_losses.append(t_loss)\n",
    "        train_accs.append(t_acc)\n",
    "        train_ce_losses.append(t_ce)\n",
    "        train_supcon_losses.append(t_sup)\n",
    "        val_losses.append(v_loss)\n",
    "        val_accs.append(v_acc)\n",
    "        early_stopper(v_acc, model, best_model_path)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs, train_ce_losses, train_supcon_losses)\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\nTest set results:\")\n",
    "    test_loss, test_acc, test_labels, test_preds, test_probs = eval_epoch(model, test_loader, ce_loss_fn)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_labels, test_preds, class_names, save_path=\"norm_confmat_hybrid_loss.png\")\n",
    "\n",
    "    try:\n",
    "        test_labels_onehot = np.eye(len(class_names))[test_labels]\n",
    "        roc_macro = roc_auc_score(test_labels_onehot, test_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "        plot_roc_per_class(test_labels, test_probs, len(class_names), class_names, save_path=\"perclass_roc_hybrid_loss.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    def plot_reliability(y_true, y_prob, n_bins=10):\n",
    "        from sklearn.calibration import calibration_curve\n",
    "        plt.figure(figsize=(5,5))\n",
    "        for i, name in enumerate(class_names):\n",
    "            try:\n",
    "                prob_true, prob_pred = calibration_curve((y_true==i).astype(int), y_prob[:,i], n_bins=n_bins, strategy='uniform')\n",
    "                plt.plot(prob_pred, prob_true, marker='o', label=f\"{name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Reliability curve failed for {name}: {e}\")\n",
    "        plt.plot([0,1],[0,1],'--', color='gray')\n",
    "        plt.xlabel(\"Mean Predicted Probability\")\n",
    "        plt.ylabel(\"Fraction of Positives\")\n",
    "        plt.title(\"Reliability Diagram (hybrid loss)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"reliability_diagram_hybrid_loss.png\")\n",
    "        plt.close()\n",
    "    plot_reliability(test_labels, test_probs)\n",
    "\n",
    "    print(\"\\nTTA Evaluation:\")\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomHorizontalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomRotation(15),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ColorJitter(0.3,0.3,0.3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(280), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.GaussianBlur(3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    ]\n",
    "    tta_probs = []\n",
    "    for t in tta_transforms:\n",
    "        test_ds.transform = t\n",
    "        loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        probs = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                probs.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "        tta_probs.append(np.concatenate(probs))\n",
    "    tta_probs = np.array(tta_probs)\n",
    "    final_probs = np.mean(tta_probs, axis=0)\n",
    "    final_preds = final_probs.argmax(axis=1)\n",
    "    print(classification_report(test_ds.targets, final_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_ds.targets, final_preds, class_names, save_path=\"tta_confmat_hybrid_loss.png\")\n",
    "    plot_tta_stats(tta_probs, test_probs, class_names, save_path=\"tta_mean_var_hybrid_loss.png\")\n",
    "    show_tta_flip_examples(test_probs, final_probs, [img for img, _ in test_ds], test_ds.targets, final_preds, class_names)\n",
    "\n",
    "    print(\"\\nRunning Grad-CAMs for each class on random test images...\")\n",
    "    save_gradcams(model, test_ds, class_names, device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(epochs=25, batch_size=32, mixup_alpha=0.4, supcon_weight=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBAM SIMSIAM RESNET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T23:52:54.248006Z",
     "iopub.status.busy": "2025-07-05T23:52:54.247226Z",
     "iopub.status.idle": "2025-07-05T23:52:54.254118Z",
     "shell.execute_reply": "2025-07-05T23:52:54.253343Z",
     "shell.execute_reply.started": "2025-07-05T23:52:54.247980Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cbam_resnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cbam_resnet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(x_cat)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAMBottleneck(Bottleneck):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        planes = self.conv3.out_channels\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def cbam_resnet50(**kwargs):\n",
    "    model = ResNet(CBAMBottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T00:04:18.547649Z",
     "iopub.status.busy": "2025-07-06T00:04:18.547051Z",
     "iopub.status.idle": "2025-07-06T00:04:18.555266Z",
     "shell.execute_reply": "2025-07-06T00:04:18.554282Z",
     "shell.execute_reply.started": "2025-07-06T00:04:18.547619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simsiam_cbam_pretrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simsiam_cbam_pretrain.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "from cbam_resnet import cbam_resnet50\n",
    "\n",
    "# --- Seed for reproducibility ---\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_all()\n",
    "\n",
    "# --- SimSiam Model ---\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim=2048, hidden_dim=2048, out_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim, bias=False),\n",
    "            nn.BatchNorm1d(out_dim, affine=False)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    def __init__(self, in_dim=2048, hidden_dim=512, out_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimSiam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projector = MLPHead()\n",
    "        self.predictor = PredictionHead()\n",
    "        for m in self.backbone.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "                m.requires_grad_(False)\n",
    "    def _forward_backbone(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return torch.flatten(x, 1)\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.projector(self._forward_backbone(x1))\n",
    "        z2 = self.projector(self._forward_backbone(x2))\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "# --- Dataset ---\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filepaths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir)\n",
    "                          if fname.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filepaths[idx]).convert('RGB')\n",
    "        return self.transform(img), self.transform(img)\n",
    "\n",
    "# --- Loss ---\n",
    "def negative_cosine_similarity(p, z):\n",
    "    p = nn.functional.normalize(p, dim=1)\n",
    "    z = nn.functional.normalize(z, dim=1)\n",
    "    return -(p * z).sum(dim=1).mean()\n",
    "\n",
    "# --- Pretraining function ---\n",
    "def pretrain(root_path=\"/kaggle/input/minida/mini_output1/pretrain\",\n",
    "             checkpoint_dir=\"/kaggle/working/\",\n",
    "             epochs=200, batch_size=32, accumulation_steps=4):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"logs_cbam\"))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = UnlabeledDataset(root_path, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "    model = SimSiam().to(device)\n",
    "    base_lr = 0.05 * batch_size / 256\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        for idx, (x1, x2) in enumerate(dataloader):\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "            p1, p2, z1, z2 = model(x1, x2)\n",
    "            loss = 0.5 * (negative_cosine_similarity(p1, z2) + negative_cosine_similarity(p2, z1))\n",
    "            loss.backward()\n",
    "            if (idx + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        scheduler.step()\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"simsiam_cbam_epoch_{epoch+1}.pth\"))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"simsiam_cbam_pretrained_final.pth\"))\n",
    "    print(\"Pretraining complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pretrain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python simsiam_cbam_pretrain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CBAM-ResNet fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:42:34.794601Z",
     "iopub.status.busy": "2025-07-06T22:42:34.793908Z",
     "iopub.status.idle": "2025-07-06T23:07:10.805318Z",
     "shell.execute_reply": "2025-07-06T23:07:10.804368Z",
     "shell.execute_reply.started": "2025-07-06T22:42:34.794581Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 1.0797, Acc 0.4428 | Val Loss 1.1021, Acc 0.3131\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 1.0514, Acc 0.4315 | Val Loss 1.1091, Acc 0.3131\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 1.0452, Acc 0.4233 | Val Loss 1.0132, Acc 0.4747\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 1.0478, Acc 0.4563 | Val Loss 0.9460, Acc 0.6869\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 1.0646, Acc 0.4371 | Val Loss 0.9650, Acc 0.6162\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 1.0260, Acc 0.4961 | Val Loss 0.8190, Acc 0.6869\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.9878, Acc 0.5293 | Val Loss 0.7635, Acc 0.7273\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.9395, Acc 0.5544 | Val Loss 0.5978, Acc 0.8384\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.9318, Acc 0.5686 | Val Loss 0.5133, Acc 0.8788\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.8408, Acc 0.6399 | Val Loss 0.4725, Acc 0.8384\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.8235, Acc 0.6594 | Val Loss 0.5732, Acc 0.7778\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.8280, Acc 0.6499 | Val Loss 0.4551, Acc 0.8485\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.8032, Acc 0.6788 | Val Loss 0.4415, Acc 0.8889\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.7189, Acc 0.7159 | Val Loss 0.4325, Acc 0.8889\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.8371, Acc 0.6578 | Val Loss 0.4500, Acc 0.8990\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss 0.7392, Acc 0.7146 | Val Loss 0.4594, Acc 0.8182\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss 0.8212, Acc 0.6590 | Val Loss 0.4256, Acc 0.8990\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss 0.7327, Acc 0.7387 | Val Loss 0.4640, Acc 0.8283\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss 0.7776, Acc 0.6827 | Val Loss 0.3873, Acc 0.9091\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss 0.7947, Acc 0.7034 | Val Loss 0.3819, Acc 0.9293\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss 0.6738, Acc 0.7706 | Val Loss 0.4699, Acc 0.8485\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss 0.7487, Acc 0.7139 | Val Loss 0.3828, Acc 0.8889\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss 0.7398, Acc 0.7155 | Val Loss 0.4218, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss 0.7984, Acc 0.6800 | Val Loss 0.3936, Acc 0.9091\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss 0.7769, Acc 0.6762 | Val Loss 0.4109, Acc 0.9091\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss 0.7512, Acc 0.7150 | Val Loss 0.4405, Acc 0.8788\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss 0.7297, Acc 0.7033 | Val Loss 0.3844, Acc 0.8788\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss 0.6994, Acc 0.7555 | Val Loss 0.3401, Acc 0.9495\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss 0.7122, Acc 0.7373 | Val Loss 0.3407, Acc 0.9394\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss 0.7144, Acc 0.7273 | Val Loss 0.3748, Acc 0.9091\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss 0.6796, Acc 0.7512 | Val Loss 0.3562, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss 0.7132, Acc 0.7086 | Val Loss 0.3366, Acc 0.9293\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss 0.6956, Acc 0.7399 | Val Loss 0.3485, Acc 0.9192\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss 0.6700, Acc 0.7500 | Val Loss 0.3634, Acc 0.9091\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss 0.7068, Acc 0.7411 | Val Loss 0.3515, Acc 0.9192\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss 0.6281, Acc 0.7872 | Val Loss 0.3346, Acc 0.9293\n",
      "EarlyStopping counter: 8 / 8\n",
      "Early stopping at epoch 36\n",
      "\n",
      "Test set results (CBAM):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2851, Test Acc: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.92      0.96        37\n",
      "Healthy Leaf       0.91      1.00      0.95        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n",
      "Test ROC-AUC (macro): 0.9982\n",
      "\n",
      "Test-Time Augmentation (TTA) Evaluation (CBAM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.97      0.95      0.96        37\n",
      "Healthy Leaf       0.94      1.00      0.97        31\n",
      "  straw_mite       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "from cbam_resnet import cbam_resnet50  # Make sure this is in your path\n",
    "\n",
    "# ---------- SEED & DEVICE ----------\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_all()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- PATHS & CLASSES ----------\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_cbam_pretrained_final.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# ---------- MIXUP ----------\n",
    "def mixup_data(x, y, alpha=0.3):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ---------- DATALOADERS ----------\n",
    "def get_loaders(batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "\n",
    "    class_counts = np.bincount(train_ds.targets)\n",
    "    weights = 1. / class_counts[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(weights, len(train_ds), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader, test_ds\n",
    "\n",
    "# ---------- MODEL ----------\n",
    "class FineTuneCBAM(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        backbone = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        ckpt = torch.load(pretrained_path, map_location=device)\n",
    "        if 'backbone' in ckpt:\n",
    "            self.backbone.load_state_dict(ckpt['backbone'], strict=False)\n",
    "        else:\n",
    "            self.backbone.load_state_dict(ckpt, strict=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ---------- LR SCHEDULER ----------\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "def get_scheduler(optimizer, total_epochs, warmup_epochs=5):\n",
    "    warmup = LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
    "    cosine = CosineAnnealingLR(optimizer, T_max=total_epochs-warmup_epochs)\n",
    "    return SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
    "\n",
    "# ---------- TRAINING & EVAL ----------\n",
    "def train_epoch(model, loader, criterion, optimizer, use_mixup=True, mixup_alpha=0.3):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "            outputs = model(imgs)\n",
    "            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, all_labels, all_probs = 0, 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader.dataset), acc, np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# ---------- EARLY STOPPING ----------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.best_state = None\n",
    "        self.verbose = verbose\n",
    "    def __call__(self, val_acc, model):\n",
    "        if (self.best_acc is None) or (val_acc > self.best_acc):\n",
    "            self.best_acc = val_acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            if self.verbose: print(\"Validation accuracy improved, saving best state.\")\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "# ---------- PLOTTING ----------\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "    plt.title('Normalized Confusion Matrix (CBAM)')\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_per_class(y_true, y_score, n_classes, class_names, save_path=None):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        if np.sum(y_true==i) == 0: continue\n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve((y_true==i).astype(int), y_score[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "        except Exception as e:\n",
    "            print(f\"ROC error for class {class_names[i]}: {e}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Per-class ROC Curves (CBAM)')\n",
    "    plt.legend()\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_reliability(y_true, y_prob, n_bins=10):\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    plt.figure(figsize=(5,5))\n",
    "    for i, name in enumerate(class_names):\n",
    "        try:\n",
    "            prob_true, prob_pred = calibration_curve((y_true==i).astype(int), y_prob[:,i], n_bins=n_bins, strategy='uniform')\n",
    "            plt.plot(prob_pred, prob_true, marker='o', label=f\"{name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Reliability curve failed for {name}: {e}\")\n",
    "    plt.plot([0,1],[0,1],'--', color='gray')\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Reliability Diagram (CBAM)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"reliability_diagram_cbam.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curves (CBAM)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy Curves (CBAM)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"loss_acc_curves_cbam.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ---------- TTA ----------\n",
    "def tta_eval(model, test_ds, batch_size, class_names):\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomHorizontalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomVerticalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomRotation(15),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(280), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.GaussianBlur(3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    ]\n",
    "    tta_probs = []\n",
    "    model.eval()\n",
    "    for t in tta_transforms:\n",
    "        test_ds.transform = t\n",
    "        loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "        tta_probs.append(np.concatenate(preds))\n",
    "    tta_probs = np.array(tta_probs)\n",
    "    mean_probs = np.mean(tta_probs, axis=0)\n",
    "    final_preds = np.argmax(mean_probs, axis=1)\n",
    "    return mean_probs, final_preds\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3):\n",
    "    train_loader, val_loader, test_loader, test_ds = get_loaders(batch_size)\n",
    "    model = FineTuneCBAM(pretrained_path, num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = get_scheduler(optimizer, epochs, warmup_epochs=5)\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "\n",
    "    # (OPTIONAL) Freeze backbone for warmup\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch == 5:\n",
    "            for param in model.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "        t_loss, t_acc = train_epoch(model, train_loader, criterion, optimizer, use_mixup=True, mixup_alpha=mixup_alpha)\n",
    "        v_loss, v_acc, _, _ = eval_epoch(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "        train_losses.append(t_loss)\n",
    "        train_accs.append(t_acc)\n",
    "        val_losses.append(v_loss)\n",
    "        val_accs.append(v_acc)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss {t_loss:.4f}, Acc {t_acc:.4f} | Val Loss {v_loss:.4f}, Acc {v_acc:.4f}\")\n",
    "        if early_stopper(v_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs)\n",
    "    model.load_state_dict(early_stopper.best_state)\n",
    "\n",
    "    print(\"\\nTest set results (CBAM):\")\n",
    "    test_loss, test_acc, test_labels, test_probs = eval_epoch(model, test_loader, criterion)\n",
    "    test_preds = np.argmax(test_probs, axis=1)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_labels, test_preds, class_names, save_path=\"cbam_norm_confmat.png\")\n",
    "\n",
    "    try:\n",
    "        test_labels_onehot = np.eye(num_classes)[test_labels]\n",
    "        roc_macro = roc_auc_score(test_labels_onehot, test_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "        plot_roc_per_class(test_labels, test_probs, num_classes, class_names, save_path=\"cbam_perclass_roc.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    plot_reliability(test_labels, test_probs)\n",
    "\n",
    "    # -------- TTA --------\n",
    "    print(\"\\nTest-Time Augmentation (TTA) Evaluation (CBAM):\")\n",
    "    mean_probs, final_preds = tta_eval(model, test_ds, batch_size, class_names)\n",
    "    print(classification_report(test_ds.targets, final_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_ds.targets, final_preds, class_names, save_path=\"cbam_tta_confmat.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hybrid SupCon+CE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T23:14:23.080483Z",
     "iopub.status.busy": "2025-07-06T23:14:23.079690Z",
     "iopub.status.idle": "2025-07-06T23:43:45.456002Z",
     "shell.execute_reply": "2025-07-06T23:43:45.455110Z",
     "shell.execute_reply.started": "2025-07-06T23:14:23.080455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 2.2487, Acc 0.3898 | Val Loss 1.1088, Acc 0.3131\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 2.2073, Acc 0.4732 | Val Loss 1.1009, Acc 0.3131\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 2.1854, Acc 0.4149 | Val Loss 1.0241, Acc 0.4646\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 2.1509, Acc 0.3909 | Val Loss 0.9630, Acc 0.5556\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 2.1198, Acc 0.4880 | Val Loss 0.9547, Acc 0.5051\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 2.2027, Acc 0.4493 | Val Loss 0.9060, Acc 0.5859\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 2.1879, Acc 0.4928 | Val Loss 0.8403, Acc 0.6465\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 2.1510, Acc 0.5059 | Val Loss 0.7801, Acc 0.7677\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 2.1323, Acc 0.5324 | Val Loss 0.7574, Acc 0.7273\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 2.1112, Acc 0.5755 | Val Loss 0.7450, Acc 0.6970\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 2.1601, Acc 0.5789 | Val Loss 0.6835, Acc 0.7273\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 2.1311, Acc 0.5866 | Val Loss 0.5978, Acc 0.8384\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 2.1179, Acc 0.6101 | Val Loss 0.5575, Acc 0.8081\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 2.0786, Acc 0.6883 | Val Loss 0.4622, Acc 0.8889\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 2.0899, Acc 0.6630 | Val Loss 0.4747, Acc 0.8283\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss 2.0270, Acc 0.6823 | Val Loss 0.4400, Acc 0.8889\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss 2.0749, Acc 0.6422 | Val Loss 0.4603, Acc 0.8283\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss 2.0704, Acc 0.6573 | Val Loss 0.4909, Acc 0.8586\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss 2.0773, Acc 0.6651 | Val Loss 0.4470, Acc 0.8788\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss 2.0559, Acc 0.6503 | Val Loss 0.4231, Acc 0.9192\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss 2.0119, Acc 0.7370 | Val Loss 0.4326, Acc 0.8990\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss 2.0867, Acc 0.6377 | Val Loss 0.4136, Acc 0.8889\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss 2.0443, Acc 0.6928 | Val Loss 0.4408, Acc 0.9293\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss 2.0399, Acc 0.6767 | Val Loss 0.4642, Acc 0.8485\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss 1.9983, Acc 0.6738 | Val Loss 0.4130, Acc 0.9192\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss 2.0241, Acc 0.6965 | Val Loss 0.4057, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss 1.9852, Acc 0.6989 | Val Loss 0.4227, Acc 0.9091\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss 1.9733, Acc 0.7095 | Val Loss 0.3969, Acc 0.9091\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss 2.0262, Acc 0.6961 | Val Loss 0.3916, Acc 0.9192\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss 1.9875, Acc 0.7056 | Val Loss 0.3999, Acc 0.8889\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss 1.9295, Acc 0.7617 | Val Loss 0.3832, Acc 0.9394\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss 1.9527, Acc 0.7137 | Val Loss 0.3812, Acc 0.9293\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss 1.9037, Acc 0.7407 | Val Loss 0.3880, Acc 0.9293\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss 1.9424, Acc 0.7320 | Val Loss 0.3910, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss 1.9574, Acc 0.7187 | Val Loss 0.3765, Acc 0.9394\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss 1.8872, Acc 0.7782 | Val Loss 0.3792, Acc 0.9394\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss 1.8645, Acc 0.7565 | Val Loss 0.3805, Acc 0.9192\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss 1.9698, Acc 0.7004 | Val Loss 0.3763, Acc 0.9293\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss 1.9289, Acc 0.7224 | Val Loss 0.3786, Acc 0.9293\n",
      "EarlyStopping counter: 8 / 8\n",
      "Early stopping at epoch 39\n",
      "\n",
      "Test set results (CBAM Hybrid):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3125, Test Acc: 0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.89      0.94        37\n",
      "Healthy Leaf       0.89      1.00      0.94        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.96        99\n",
      "   macro avg       0.96      0.96      0.96        99\n",
      "weighted avg       0.96      0.96      0.96        99\n",
      "\n",
      "Test ROC-AUC (macro): 0.9988\n",
      "\n",
      "Test-Time Augmentation (TTA) Evaluation (CBAM Hybrid):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.97      0.89      0.93        37\n",
      "Healthy Leaf       0.88      0.97      0.92        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.95      0.95      0.95        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "from cbam_resnet import cbam_resnet50\n",
    "\n",
    "# ---------- SEED & DEVICE ----------\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_all()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- PATHS & CLASSES ----------\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_cbam_pretrained_final.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# ---------- MIXUP ----------\n",
    "def mixup_data(x, y, alpha=0.3):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ---------- SUPERVISED CONTRASTIVE LOSS ----------\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.eps = 1e-8\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.size(0)\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        anchor_dot_contrast = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(batch_size, device=device))\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + self.eps)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + self.eps)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss\n",
    "\n",
    "# ---------- DATALOADERS ----------\n",
    "def get_loaders(batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "\n",
    "    class_counts = np.bincount(train_ds.targets)\n",
    "    weights = 1. / class_counts[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(weights, len(train_ds), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader, test_ds\n",
    "\n",
    "# ---------- MODEL ----------\n",
    "class FineTuneCBAM(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        backbone = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        ckpt = torch.load(pretrained_path, map_location=device)\n",
    "        if 'backbone' in ckpt:\n",
    "            self.backbone.load_state_dict(ckpt['backbone'], strict=False)\n",
    "        else:\n",
    "            self.backbone.load_state_dict(ckpt, strict=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        self.feature_layer = nn.Linear(2048, 128)  # For SupCon\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        feats = self.backbone(x).flatten(1)\n",
    "        features = F.normalize(self.feature_layer(feats), dim=1)\n",
    "        logits = self.classifier(feats)\n",
    "        if return_features:\n",
    "            return logits, features\n",
    "        return logits\n",
    "\n",
    "# ---------- LR SCHEDULER ----------\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "def get_scheduler(optimizer, total_epochs, warmup_epochs=5):\n",
    "    warmup = LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
    "    cosine = CosineAnnealingLR(optimizer, T_max=total_epochs-warmup_epochs)\n",
    "    return SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
    "\n",
    "# ---------- TRAINING & EVAL ----------\n",
    "def train_epoch(model, loader, ce_loss_fn, supcon_loss_fn, optimizer,\n",
    "                use_mixup=True, mixup_alpha=0.3, supcon_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss, total_ce, total_supcon, correct = 0, 0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "            logits, features = model(imgs, return_features=True)\n",
    "            loss_ce = mixup_criterion(ce_loss_fn, logits, y_a, y_b, lam)\n",
    "            loss_supcon = supcon_loss_fn(features, labels)\n",
    "            loss = (1 - supcon_weight) * loss_ce + supcon_weight * loss_supcon\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            logits, features = model(imgs, return_features=True)\n",
    "            loss_ce = ce_loss_fn(logits, labels)\n",
    "            loss_supcon = supcon_loss_fn(features, labels)\n",
    "            loss = (1 - supcon_weight) * loss_ce + supcon_weight * loss_supcon\n",
    "            correct += logits.argmax(1).eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        total_ce += loss_ce.item() * imgs.size(0)\n",
    "        total_supcon += loss_supcon.item() * imgs.size(0)\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, correct / n, total_ce / n, total_supcon / n\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, all_labels, all_probs = 0, 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader.dataset), acc, np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# ---------- EARLY STOPPING ----------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.best_state = None\n",
    "        self.verbose = verbose\n",
    "    def __call__(self, val_acc, model):\n",
    "        if (self.best_acc is None) or (val_acc > self.best_acc):\n",
    "            self.best_acc = val_acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            if self.verbose: print(\"Validation accuracy improved, saving best state.\")\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "# ---------- PLOTTING ----------\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "    plt.title('Normalized Confusion Matrix (CBAM)')\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc_per_class(y_true, y_score, n_classes, class_names, save_path=None):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(n_classes):\n",
    "        if np.sum(y_true==i) == 0: continue\n",
    "        try:\n",
    "            fpr, tpr, _ = roc_curve((y_true==i).astype(int), y_score[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "        except Exception as e:\n",
    "            print(f\"ROC error for class {class_names[i]}: {e}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Per-class ROC Curves (CBAM)')\n",
    "    plt.legend()\n",
    "    if save_path: plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_reliability(y_true, y_prob, n_bins=10):\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    plt.figure(figsize=(5,5))\n",
    "    for i, name in enumerate(class_names):\n",
    "        try:\n",
    "            prob_true, prob_pred = calibration_curve((y_true==i).astype(int), y_prob[:,i], n_bins=n_bins, strategy='uniform')\n",
    "            plt.plot(prob_pred, prob_true, marker='o', label=f\"{name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Reliability curve failed for {name}: {e}\")\n",
    "    plt.plot([0,1],[0,1],'--', color='gray')\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Reliability Diagram (CBAM)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"reliability_diagram_cbam.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs, train_ce_losses, train_supcon_losses):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Total')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.plot(train_ce_losses, label='Train CE')\n",
    "    plt.plot(train_supcon_losses, label='Train SupCon')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss Curves (CBAM Hybrid)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy Curves (CBAM Hybrid)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"loss_acc_curves_cbam_hybrid.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ---------- TTA ----------\n",
    "def tta_eval(model, test_ds, batch_size, class_names):\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomHorizontalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomVerticalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomRotation(15),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(280), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.GaussianBlur(3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    ]\n",
    "    tta_probs = []\n",
    "    model.eval()\n",
    "    for t in tta_transforms:\n",
    "        test_ds.transform = t\n",
    "        loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "        tta_probs.append(np.concatenate(preds))\n",
    "    tta_probs = np.array(tta_probs)\n",
    "    mean_probs = np.mean(tta_probs, axis=0)\n",
    "    final_preds = np.argmax(mean_probs, axis=1)\n",
    "    return mean_probs, final_preds\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3, supcon_weight=0.5):\n",
    "    train_loader, val_loader, test_loader, test_ds = get_loaders(batch_size)\n",
    "    model = FineTuneCBAM(pretrained_path, num_classes=num_classes).to(device)\n",
    "    ce_loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    supcon_loss_fn = SupConLoss(temperature=0.07)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = get_scheduler(optimizer, epochs, warmup_epochs=5)\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "\n",
    "    # (OPTIONAL) Freeze backbone for warmup\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.feature_layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "    train_ce_losses, train_supcon_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch == 5:\n",
    "            for param in model.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "        t_loss, t_acc, t_ce, t_sup = train_epoch(\n",
    "            model, train_loader, ce_loss_fn, supcon_loss_fn, optimizer,\n",
    "            use_mixup=True, mixup_alpha=mixup_alpha, supcon_weight=supcon_weight)\n",
    "        v_loss, v_acc, _, _ = eval_epoch(model, val_loader, ce_loss_fn)\n",
    "        scheduler.step()\n",
    "        train_losses.append(t_loss)\n",
    "        train_accs.append(t_acc)\n",
    "        train_ce_losses.append(t_ce)\n",
    "        train_supcon_losses.append(t_sup)\n",
    "        val_losses.append(v_loss)\n",
    "        val_accs.append(v_acc)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss {t_loss:.4f}, Acc {t_acc:.4f} | Val Loss {v_loss:.4f}, Acc {v_acc:.4f}\")\n",
    "        if early_stopper(v_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    plot_loss_acc_curves(train_losses, val_losses, train_accs, val_accs, train_ce_losses, train_supcon_losses)\n",
    "    model.load_state_dict(early_stopper.best_state)\n",
    "\n",
    "    print(\"\\nTest set results (CBAM Hybrid):\")\n",
    "    test_loss, test_acc, test_labels, test_probs = eval_epoch(model, test_loader, ce_loss_fn)\n",
    "    test_preds = np.argmax(test_probs, axis=1)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_labels, test_preds, class_names, save_path=\"cbam_norm_confmat_hybrid.png\")\n",
    "\n",
    "    try:\n",
    "        test_labels_onehot = np.eye(num_classes)[test_labels]\n",
    "        roc_macro = roc_auc_score(test_labels_onehot, test_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "        plot_roc_per_class(test_labels, test_probs, num_classes, class_names, save_path=\"cbam_perclass_roc_hybrid.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    plot_reliability(test_labels, test_probs)\n",
    "\n",
    "    # -------- TTA --------\n",
    "    print(\"\\nTest-Time Augmentation (TTA) Evaluation (CBAM Hybrid):\")\n",
    "    mean_probs, final_preds = tta_eval(model, test_ds, batch_size, class_names)\n",
    "    print(classification_report(test_ds.targets, final_preds, target_names=class_names))\n",
    "    plot_confusion_matrix(test_ds.targets, final_preds, class_names, save_path=\"cbam_tta_confmat_hybrid.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3, supcon_weight=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fine-tuning training pipeline with Gaussian noise and Salt and Pepper noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T21:30:29.694011Z",
     "iopub.status.busy": "2025-07-06T21:30:29.693654Z",
     "iopub.status.idle": "2025-07-06T22:26:00.390868Z",
     "shell.execute_reply": "2025-07-06T22:26:00.389989Z",
     "shell.execute_reply.started": "2025-07-06T21:30:29.693985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running: NoNoise ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.4464, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.4424, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.4197, Val 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.4436, Val 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.4606, Val 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.5252, Val 0.7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.5449, Val 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.5732, Val 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.5855, Val 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.6835, Val 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train 0.6723, Val 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train 0.7151, Val 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train 0.6953, Val 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train 0.7013, Val 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train 0.7098, Val 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train 0.7051, Val 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train 0.7088, Val 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train 0.7235, Val 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train 0.7281, Val 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train 0.7111, Val 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train 0.7653, Val 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train 0.7803, Val 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train 0.7134, Val 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train 0.7387, Val 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train 0.7328, Val 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train 0.7194, Val 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train 0.7011, Val 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train 0.7489, Val 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train 0.7699, Val 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train 0.7423, Val 0.8889\n",
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9596\n",
      "ROC-AUC (macro): 0.9992\n",
      "ECE: 15.68%\n",
      "Results saved to ablation_results.csv\n",
      "\n",
      "==== Running: GaussianOnly ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.4270, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.4421, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.3956, Val 0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.4600, Val 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.4598, Val 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.4616, Val 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.5562, Val 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.5846, Val 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.5611, Val 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.6435, Val 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train 0.6600, Val 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train 0.6896, Val 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train 0.6919, Val 0.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train 0.7071, Val 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train 0.7316, Val 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train 0.6717, Val 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train 0.7083, Val 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train 0.7259, Val 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train 0.7310, Val 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train 0.7007, Val 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train 0.7600, Val 0.8586\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9293\n",
      "ROC-AUC (macro): 0.9956\n",
      "ECE: 19.45%\n",
      "Results saved to ablation_results.csv\n",
      "\n",
      "==== Running: SaltPepperOnly ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.4504, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.4199, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.4287, Val 0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.4198, Val 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.4635, Val 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.4535, Val 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.5350, Val 0.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.5412, Val 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.5963, Val 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.6179, Val 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train 0.6398, Val 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train 0.6537, Val 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train 0.6900, Val 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train 0.6655, Val 0.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train 0.6947, Val 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train 0.6382, Val 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train 0.6881, Val 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train 0.7041, Val 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train 0.7009, Val 0.7677\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8384\n",
      "ROC-AUC (macro): 0.9614\n",
      "ECE: 22.08%\n",
      "Results saved to ablation_results.csv\n",
      "\n",
      "==== Running: BothNoises ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 0.4414, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.4440, Val 0.3131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.4231, Val 0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.4768, Val 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.4423, Val 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train 0.4916, Val 0.6566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train 0.5181, Val 0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train 0.5507, Val 0.7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train 0.5409, Val 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train 0.5880, Val 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train 0.6519, Val 0.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train 0.7015, Val 0.7172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train 0.6640, Val 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train 0.6725, Val 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train 0.6482, Val 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train 0.6535, Val 0.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train 0.6710, Val 0.6768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train 0.7345, Val 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train 0.7127, Val 0.7273\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8889\n",
      "ROC-AUC (macro): 0.9876\n",
      "ECE: 30.33%\n",
      "Results saved to ablation_results.csv\n",
      "\n",
      "All ablation runs complete.\n",
      "             name  test_acc  roc_auc_macro        ece use_gaussian  \\\n",
      "0         NoNoise  0.959596       0.999248  15.679369          NaN   \n",
      "1    GaussianOnly  0.929293       0.995645  19.453843         True   \n",
      "2  SaltPepperOnly  0.838384       0.961374  22.078380          NaN   \n",
      "3      BothNoises  0.888889       0.987576  30.332287         True   \n",
      "\n",
      "   gaussian_std  gaussian_p use_saltpepper  salt_prob  pepper_prob  \\\n",
      "0           NaN         NaN            NaN        NaN          NaN   \n",
      "1          0.05         1.0            NaN        NaN          NaN   \n",
      "2           NaN         NaN           True       0.01         0.01   \n",
      "3          0.05         1.0           True       0.01         0.01   \n",
      "\n",
      "   saltpepper_p  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           1.0  \n",
      "3           1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "from cbam_resnet import cbam_resnet50\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_all()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Paths and Classes ---\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_cbam_pretrained_final.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# --- Custom Noise Transforms ---\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std + self.mean\n",
    "    def __repr__(self):\n",
    "        return f\"AddGaussianNoise(mean={self.mean}, std={self.std})\"\n",
    "\n",
    "class AddSaltPepperNoise(object):\n",
    "    def __init__(self, salt_prob=0.01, pepper_prob=0.01):\n",
    "        self.salt_prob = salt_prob\n",
    "        self.pepper_prob = pepper_prob\n",
    "    def __call__(self, tensor):\n",
    "        c, h, w = tensor.shape\n",
    "        mask = torch.rand((h, w))\n",
    "        salt = (mask < self.salt_prob).float()\n",
    "        pepper = (mask > 1 - self.pepper_prob).float()\n",
    "        for i in range(c):\n",
    "            tensor[i] = tensor[i] * (1 - salt - pepper) + salt + 0 * pepper\n",
    "        return tensor\n",
    "    def __repr__(self):\n",
    "        return f\"AddSaltPepperNoise(salt_prob={self.salt_prob}, pepper_prob={self.pepper_prob})\"\n",
    "\n",
    "# --- Mixup ---\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# --- Data Loader with Configurable Noise ---\n",
    "def get_loaders(batch_size=32, noise_cfg=None):\n",
    "    if noise_cfg is None: noise_cfg = {}\n",
    "    tfms = [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    if noise_cfg.get('use_gaussian', False):\n",
    "        tfms.append(transforms.RandomApply([AddGaussianNoise(std=noise_cfg.get('gaussian_std', 0.05))], p=noise_cfg.get('gaussian_p', 1.0)))\n",
    "    if noise_cfg.get('use_saltpepper', False):\n",
    "        tfms.append(transforms.RandomApply([AddSaltPepperNoise(salt_prob=noise_cfg.get('salt_prob',0.01), pepper_prob=noise_cfg.get('pepper_prob',0.01))], p=noise_cfg.get('saltpepper_p',1.0)))\n",
    "    tfms.append(transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "    train_transform = transforms.Compose(tfms)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "    class_counts = np.bincount(train_ds.targets)\n",
    "    weights = 1. / class_counts[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(weights, len(train_ds), replacement=True)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# --- CBAM Fine-tune Model ---\n",
    "class FineTuneCBAM(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        backbone = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        ckpt = torch.load(pretrained_path, map_location=device)\n",
    "        if 'backbone' in ckpt:\n",
    "            self.backbone.load_state_dict(ckpt['backbone'], strict=False)\n",
    "        else:\n",
    "            self.backbone.load_state_dict(ckpt, strict=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# --- LR Scheduler with Warmup ---\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "\n",
    "def get_scheduler(optimizer, total_epochs, warmup_epochs=5):\n",
    "    warmup = LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
    "    cosine = CosineAnnealingLR(optimizer, T_max=total_epochs - warmup_epochs)\n",
    "    return SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
    "\n",
    "# --- Training and Evaluation ---\n",
    "def train_epoch(model, loader, criterion, optimizer, use_mixup=True):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        if use_mixup:\n",
    "            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, all_labels, all_probs = 0, 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc='Eval', leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader.dataset), acc, np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# --- Early Stopping ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.best_state = None\n",
    "    def __call__(self, val_acc, model):\n",
    "        if (self.best_acc is None) or (val_acc > self.best_acc):\n",
    "            self.best_acc = val_acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "# --- Reliability Diagram (ECE) ---\n",
    "def compute_ece(labels, probs, n_bins=10):\n",
    "    \"\"\"Expected Calibration Error for multi-class softmax\"\"\"\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    accuracies = predictions == labels\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if np.any(mask):\n",
    "            bin_acc = np.mean(accuracies[mask])\n",
    "            bin_conf = np.mean(confidences[mask])\n",
    "            ece += np.abs(bin_acc - bin_conf) * np.sum(mask) / len(probs)\n",
    "    return 100 * ece  # Percentage\n",
    "\n",
    "# --- Main Experiment Runner ---\n",
    "def run_ablation_experiments(ablation_configs, epochs=50, batch_size=32, patience=10, csv_path=\"ablation_results.csv\"):\n",
    "    results = []\n",
    "    for cfg in ablation_configs:\n",
    "        print(f\"\\n==== Running: {cfg['name']} ====\")\n",
    "        seed_all()  # Reset seed for reproducibility\n",
    "        train_loader, val_loader, test_loader = get_loaders(batch_size, noise_cfg=cfg)\n",
    "        model = FineTuneCBAM(pretrained_path, num_classes=num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "        scheduler = get_scheduler(optimizer, epochs, warmup_epochs=5)\n",
    "        early_stopper = EarlyStopping(patience=patience)\n",
    "        for param in model.backbone.parameters(): param.requires_grad = False\n",
    "        for param in model.classifier.parameters(): param.requires_grad = True\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if epoch == 5:  # Unfreeze backbone after warmup\n",
    "                for param in model.backbone.parameters(): param.requires_grad = True\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, use_mixup=True)\n",
    "            val_loss, val_acc, _, _ = eval_epoch(model, val_loader, criterion)\n",
    "            scheduler.step()\n",
    "            print(f\"Epoch {epoch+1}: Train {train_acc:.4f}, Val {val_acc:.4f}\")\n",
    "            if early_stopper(val_acc, model):\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Load best state\n",
    "        model.load_state_dict(early_stopper.best_state)\n",
    "\n",
    "        # ---- Final Test & Evaluation ----\n",
    "        _, test_acc, labels, probs = eval_epoch(model, test_loader, criterion)\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        # ROC-AUC macro (one-vs-rest)\n",
    "        try:\n",
    "            labels_onehot = np.eye(num_classes)[labels]\n",
    "            roc_macro = roc_auc_score(labels_onehot, probs, average='macro', multi_class='ovr')\n",
    "        except Exception as e:\n",
    "            roc_macro = None\n",
    "        # ECE\n",
    "        ece = compute_ece(labels, probs)\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"ROC-AUC (macro): {roc_macro:.4f}\" if roc_macro else \"ROC-AUC N/A\")\n",
    "        print(f\"ECE: {ece:.2f}%\")\n",
    "        # Save results\n",
    "        row = dict(cfg)\n",
    "        row.update({\n",
    "            \"test_acc\": test_acc,\n",
    "            \"roc_auc_macro\": roc_macro,\n",
    "            \"ece\": ece,\n",
    "        })\n",
    "        results.append(row)\n",
    "        pd.DataFrame(results).to_csv(csv_path, index=False)\n",
    "        print(f\"Results saved to {csv_path}\")\n",
    "    print(\"\\nAll ablation runs complete.\")\n",
    "    print(pd.DataFrame(results))\n",
    "    return results\n",
    "\n",
    "# --- Define Ablation Study Conditions ---\n",
    "ablation_configs = [\n",
    "    {\"name\": \"NoNoise\"},\n",
    "    {\"name\": \"GaussianOnly\", \"use_gaussian\": True, \"gaussian_std\": 0.05, \"gaussian_p\": 1.0},\n",
    "    {\"name\": \"SaltPepperOnly\", \"use_saltpepper\": True, \"salt_prob\": 0.01, \"pepper_prob\": 0.01, \"saltpepper_p\": 1.0},\n",
    "    {\"name\": \"BothNoises\", \"use_gaussian\": True, \"gaussian_std\": 0.05, \"gaussian_p\": 1.0, \"use_saltpepper\": True, \"salt_prob\": 0.01, \"pepper_prob\": 0.01, \"saltpepper_p\": 1.0},\n",
    "]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_ablation_experiments(ablation_configs, epochs=50, batch_size=32, patience=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images after Noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:41:38.358886Z",
     "iopub.status.busy": "2025-07-06T22:41:38.358109Z",
     "iopub.status.idle": "2025-07-06T22:42:13.073582Z",
     "shell.execute_reply": "2025-07-06T22:42:13.072840Z",
     "shell.execute_reply.started": "2025-07-06T22:41:38.358861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /kaggle/working/noised_samples/Alternaria__alternaria (1)_ORIGINAL.png\n",
      "Saved: /kaggle/working/noised_samples/Alternaria__alternaria (1)_GAUSSIAN.png\n",
      "Saved: /kaggle/working/noised_samples/Alternaria__alternaria (1)_SALTPEPPER.png\n",
      "Saved: /kaggle/working/noised_samples/Alternaria__alternaria (1)_BOTHNOISES.png\n",
      "Saved: /kaggle/working/noised_samples/Healthy Leaf__healthy (10)_ORIGINAL.png\n",
      "Saved: /kaggle/working/noised_samples/Healthy Leaf__healthy (10)_GAUSSIAN.png\n",
      "Saved: /kaggle/working/noised_samples/Healthy Leaf__healthy (10)_SALTPEPPER.png\n",
      "Saved: /kaggle/working/noised_samples/Healthy Leaf__healthy (10)_BOTHNOISES.png\n",
      "Saved: /kaggle/working/noised_samples/straw_mite__straw_mite (10)_ORIGINAL.png\n",
      "Saved: /kaggle/working/noised_samples/straw_mite__straw_mite (10)_GAUSSIAN.png\n",
      "Saved: /kaggle/working/noised_samples/straw_mite__straw_mite (10)_SALTPEPPER.png\n",
      "Saved: /kaggle/working/noised_samples/straw_mite__straw_mite (10)_BOTHNOISES.png\n",
      "All versions saved in /kaggle/working/noised_samples/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "# ---- Define noise transforms ----\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=0.07):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std + self.mean\n",
    "\n",
    "class AddSaltPepperNoise(object):\n",
    "    def __init__(self, salt_prob=0.03, pepper_prob=0.03):\n",
    "        self.salt_prob = salt_prob\n",
    "        self.pepper_prob = pepper_prob\n",
    "    def __call__(self, tensor):\n",
    "        c, h, w = tensor.shape\n",
    "        mask = torch.rand((h, w))\n",
    "        salt = (mask < self.salt_prob).float()\n",
    "        pepper = (mask > 1 - self.pepper_prob).float()\n",
    "        for i in range(c):\n",
    "            tensor[i] = tensor[i] * (1 - salt - pepper) + salt + 0 * pepper\n",
    "        return tensor\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "# ----- Output directory -----\n",
    "output_dir = '/kaggle/working/noised_samples/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ----- Dataset: one image per class -----\n",
    "train_dir = '/kaggle/input/minida/mini_output1/train'\n",
    "ds = ImageFolder(train_dir)\n",
    "class_to_idx = ds.class_to_idx\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "imgs_per_class = {}\n",
    "for img_path, label in ds.samples:\n",
    "    if label not in imgs_per_class:\n",
    "        imgs_per_class[label] = img_path\n",
    "    if len(imgs_per_class) == len(idx_to_class):\n",
    "        break\n",
    "\n",
    "# ----- Define the 4 noise pipelines -----\n",
    "def no_noise_pipeline():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "def gaussian_pipeline():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([AddGaussianNoise(std=0.07)], p=1.0)\n",
    "    ])\n",
    "def saltpepper_pipeline():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([AddSaltPepperNoise(salt_prob=0.03, pepper_prob=0.03)], p=1.0)\n",
    "    ])\n",
    "def both_pipeline():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([AddGaussianNoise(std=0.07)], p=1.0),\n",
    "        transforms.RandomApply([AddSaltPepperNoise(salt_prob=0.03, pepper_prob=0.03)], p=1.0)\n",
    "    ])\n",
    "\n",
    "pipelines = [\n",
    "    (\"ORIGINAL\", no_noise_pipeline()),\n",
    "    (\"GAUSSIAN\", gaussian_pipeline()),\n",
    "    (\"SALTPEPPER\", saltpepper_pipeline()),\n",
    "    (\"BOTHNOISES\", both_pipeline()),\n",
    "]\n",
    "\n",
    "# ----- Save all versions -----\n",
    "for label, img_path in imgs_per_class.items():\n",
    "    class_name = idx_to_class[label]\n",
    "    orig_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    for ver_name, pipeline in pipelines:\n",
    "        tensor_img = pipeline(img)\n",
    "        tensor_img = tensor_img.clamp(0,1)\n",
    "        out_img = to_pil(tensor_img)\n",
    "        save_path = os.path.join(\n",
    "            output_dir, f\"{class_name}__{orig_name}_{ver_name}.png\"\n",
    "        )\n",
    "        out_img.save(save_path)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n",
    "print(\"All versions saved in\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T18:32:55.697084Z",
     "iopub.status.busy": "2025-07-12T18:32:55.695517Z",
     "iopub.status.idle": "2025-07-12T18:58:56.416937Z",
     "shell.execute_reply": "2025-07-12T18:58:56.415853Z",
     "shell.execute_reply.started": "2025-07-12T18:32:55.697039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 1.0797, Acc 0.4428 | Val Loss 1.1021, Acc 0.3131\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 1.0514, Acc 0.4315 | Val Loss 1.1091, Acc 0.3131\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 1.0452, Acc 0.4233 | Val Loss 1.0132, Acc 0.4747\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 1.0478, Acc 0.4563 | Val Loss 0.9460, Acc 0.6869\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 1.0646, Acc 0.4371 | Val Loss 0.9650, Acc 0.6162\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 1.0260, Acc 0.4961 | Val Loss 0.8190, Acc 0.6869\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.9878, Acc 0.5293 | Val Loss 0.7635, Acc 0.7273\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.9395, Acc 0.5544 | Val Loss 0.5978, Acc 0.8384\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.9318, Acc 0.5686 | Val Loss 0.5133, Acc 0.8788\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.8408, Acc 0.6399 | Val Loss 0.4725, Acc 0.8384\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.8235, Acc 0.6594 | Val Loss 0.5732, Acc 0.7778\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.8280, Acc 0.6499 | Val Loss 0.4551, Acc 0.8485\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.8032, Acc 0.6788 | Val Loss 0.4415, Acc 0.8889\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.7189, Acc 0.7159 | Val Loss 0.4325, Acc 0.8889\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.8371, Acc 0.6578 | Val Loss 0.4500, Acc 0.8990\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss 0.7392, Acc 0.7146 | Val Loss 0.4594, Acc 0.8182\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss 0.8212, Acc 0.6590 | Val Loss 0.4256, Acc 0.8990\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss 0.7327, Acc 0.7387 | Val Loss 0.4640, Acc 0.8283\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss 0.7776, Acc 0.6827 | Val Loss 0.3873, Acc 0.9091\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss 0.7947, Acc 0.7034 | Val Loss 0.3819, Acc 0.9293\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss 0.6738, Acc 0.7706 | Val Loss 0.4699, Acc 0.8485\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss 0.7487, Acc 0.7139 | Val Loss 0.3828, Acc 0.8889\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss 0.7398, Acc 0.7155 | Val Loss 0.4218, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss 0.7984, Acc 0.6800 | Val Loss 0.3936, Acc 0.9091\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss 0.7769, Acc 0.6762 | Val Loss 0.4109, Acc 0.9091\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss 0.7512, Acc 0.7150 | Val Loss 0.4405, Acc 0.8788\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss 0.7297, Acc 0.7033 | Val Loss 0.3844, Acc 0.8788\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss 0.6994, Acc 0.7555 | Val Loss 0.3401, Acc 0.9495\n",
      "Validation accuracy improved, saving best state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss 0.7122, Acc 0.7373 | Val Loss 0.3407, Acc 0.9394\n",
      "EarlyStopping counter: 1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss 0.7144, Acc 0.7273 | Val Loss 0.3748, Acc 0.9091\n",
      "EarlyStopping counter: 2 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss 0.6796, Acc 0.7512 | Val Loss 0.3562, Acc 0.9192\n",
      "EarlyStopping counter: 3 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss 0.7132, Acc 0.7086 | Val Loss 0.3366, Acc 0.9293\n",
      "EarlyStopping counter: 4 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss 0.6956, Acc 0.7399 | Val Loss 0.3485, Acc 0.9192\n",
      "EarlyStopping counter: 5 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss 0.6700, Acc 0.7500 | Val Loss 0.3634, Acc 0.9091\n",
      "EarlyStopping counter: 6 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss 0.7068, Acc 0.7411 | Val Loss 0.3515, Acc 0.9192\n",
      "EarlyStopping counter: 7 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss 0.6281, Acc 0.7872 | Val Loss 0.3346, Acc 0.9293\n",
      "EarlyStopping counter: 8 / 8\n",
      "Early stopping at epoch 36\n",
      "Model saved as best_finetuned_cbam.pth\n",
      "\n",
      "Test set results (CBAM):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2851, Test Acc: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.92      0.96        37\n",
      "Healthy Leaf       0.91      1.00      0.95        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from cbam_resnet import cbam_resnet50  # Ensure this file is in your working directory\n",
    "\n",
    "# ---------- SEED & DEVICE ----------\n",
    "def seed_all(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_all()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- PATHS & CLASSES ----------\n",
    "data_root = \"/kaggle/input/minida/mini_output1\"\n",
    "pretrained_path = \"/kaggle/working/simsiam_cbam_pretrained_final.pth\"\n",
    "train_dir, val_dir, test_dir = [os.path.join(data_root, x) for x in [\"train\", \"val\", \"test\"]]\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# ---------- DATALOADERS ----------\n",
    "def get_loaders(batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, train_transform)\n",
    "    val_ds = ImageFolder(val_dir, val_transform)\n",
    "    test_ds = ImageFolder(test_dir, val_transform)\n",
    "\n",
    "    class_counts = np.bincount(train_ds.targets)\n",
    "    weights = 1. / class_counts[train_ds.targets]\n",
    "    sampler = WeightedRandomSampler(weights, len(train_ds), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader, test_ds\n",
    "\n",
    "# ---------- MODEL ----------\n",
    "class FineTuneCBAM(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes=3):\n",
    "        super().__init__()\n",
    "        backbone = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        ckpt = torch.load(pretrained_path, map_location=device)\n",
    "        if 'backbone' in ckpt:\n",
    "            self.backbone.load_state_dict(ckpt['backbone'], strict=False)\n",
    "        else:\n",
    "            self.backbone.load_state_dict(ckpt, strict=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# ---------- LR SCHEDULER ----------\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "def get_scheduler(optimizer, total_epochs, warmup_epochs=5):\n",
    "    warmup = LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
    "    cosine = CosineAnnealingLR(optimizer, T_max=total_epochs-warmup_epochs)\n",
    "    return SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
    "\n",
    "# ---------- MIXUP ----------\n",
    "def mixup_data(x, y, alpha=0.3):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ---------- TRAINING & EVAL ----------\n",
    "def train_epoch(model, loader, criterion, optimizer, use_mixup=True, mixup_alpha=0.3):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if use_mixup:\n",
    "            imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha)\n",
    "            outputs = model(imgs)\n",
    "            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (lam * preds.eq(y_a).sum().item() + (1 - lam) * preds.eq(y_b).sum().item())\n",
    "        else:\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, all_labels, all_probs = 0, 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            correct += outputs.argmax(1).eq(labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    acc = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader.dataset), acc, np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# ---------- EARLY STOPPING ----------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=8, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.best_state = None\n",
    "        self.verbose = verbose\n",
    "    def __call__(self, val_acc, model):\n",
    "        if (self.best_acc is None) or (val_acc > self.best_acc):\n",
    "            self.best_acc = val_acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            if self.verbose: print(\"Validation accuracy improved, saving best state.\")\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "# ---------- MAIN ----------\n",
    "def main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3):\n",
    "    train_loader, val_loader, test_loader, test_ds = get_loaders(batch_size)\n",
    "    model = FineTuneCBAM(pretrained_path, num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    scheduler = get_scheduler(optimizer, epochs, warmup_epochs=5)\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "\n",
    "    # Freeze backbone for warmup\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch == 5:\n",
    "            for param in model.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "        t_loss, t_acc = train_epoch(model, train_loader, criterion, optimizer, use_mixup=True, mixup_alpha=mixup_alpha)\n",
    "        v_loss, v_acc, _, _ = eval_epoch(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "        train_losses.append(t_loss)\n",
    "        train_accs.append(t_acc)\n",
    "        val_losses.append(v_loss)\n",
    "        val_accs.append(v_acc)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss {t_loss:.4f}, Acc {t_acc:.4f} | Val Loss {v_loss:.4f}, Acc {v_acc:.4f}\")\n",
    "        if early_stopper(v_acc, model):\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # --- Always restore best state and eval before testing ---\n",
    "    model.load_state_dict(early_stopper.best_state)\n",
    "    model.eval()\n",
    "    # --- Save model at its best state ---\n",
    "    torch.save(model.state_dict(), \"best_finetuned_cbam.pth\")\n",
    "    print(\"Model saved as best_finetuned_cbam.pth\")\n",
    "\n",
    "    # --- Test evaluation ---\n",
    "    print(\"\\nTest set results (CBAM):\")\n",
    "    test_loss, test_acc, test_labels, test_probs = eval_epoch(model, test_loader, criterion)\n",
    "    test_preds = np.argmax(test_probs, axis=1)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    # (Add your plotting here as needed)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(epochs=40, batch_size=32, patience=8, mixup_alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- XAI-Ready Loader + GradCAMs All-in-One Cell ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# ---- Model definition (match your finetune) ----\n",
    "from cbam_resnet import cbam_resnet50\n",
    "\n",
    "class FineTuneCBAM(nn.Module):\n",
    "    def __init__(self, pretrained_path=None, num_classes=3):\n",
    "        super().__init__()\n",
    "        backbone = cbam_resnet50(num_classes=1000)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512), nn.ReLU(inplace=True), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        if pretrained_path:\n",
    "            ckpt = torch.load(pretrained_path, map_location='cpu')\n",
    "            if 'backbone' in ckpt:\n",
    "                self.backbone.load_state_dict(ckpt['backbone'], strict=False)\n",
    "            else:\n",
    "                self.backbone.load_state_dict(ckpt, strict=False)\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# --- Load model weights (set this to your actual path if needed) ---\n",
    "finetuned_ckpt_path = \"best_finetuned_cbam.pth\"\n",
    "num_classes = 3\n",
    "class_names = ['Alternaria', 'Healthy Leaf', 'straw_mite']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FineTuneCBAM(pretrained_path=None, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(finetuned_ckpt_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Loaded fine-tuned model.\")\n",
    "\n",
    "# --- Test dataset loader ---\n",
    "test_dir = \"/kaggle/input/minida/mini_output1/test\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "inv_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.])\n",
    "])\n",
    "dataset = ImageFolder(test_dir, transform=transform)\n",
    "print(f\"Loaded {len(dataset)} test images.\")\n",
    "\n",
    "# --- XAI classes: GradCAM, GradCAM++, LayerCAM ---\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "    def _register_hooks(self):\n",
    "        def fw_hook(_, __, output):\n",
    "            self.activations = output.detach()\n",
    "        def bw_hook(_, __, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "        self.target_layer.register_forward_hook(fw_hook)\n",
    "        self.target_layer.register_full_backward_hook(bw_hook)\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward(retain_graph=True)\n",
    "        weights = self.gradients.mean(dim=(2,3))[0]\n",
    "        cam = torch.zeros(self.activations.shape[2:], device=input_tensor.device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * self.activations[0, i]\n",
    "        cam = F.relu(cam)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-10)\n",
    "        return cam.cpu().numpy(), class_idx\n",
    "\n",
    "class GradCAMPlusPlus(GradCAM):\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward(retain_graph=True)\n",
    "        g = self.gradients\n",
    "        a = self.activations\n",
    "        alpha_num = g.pow(2)\n",
    "        alpha_denom = 2 * g.pow(2) + (a * g.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
    "        alpha = alpha_num / (alpha_denom + 1e-7)\n",
    "        weights = (alpha * F.relu(g)).sum(dim=(2, 3))[0]\n",
    "        cam = torch.zeros(a.shape[2:], device=input_tensor.device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * a[0, i]\n",
    "        cam = F.relu(cam)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-10)\n",
    "        return cam.cpu().numpy(), class_idx\n",
    "\n",
    "class LayerCAM(GradCAM):\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward(retain_graph=True)\n",
    "        cam = (self.gradients * self.activations).sum(dim=1)[0]\n",
    "        cam = F.relu(cam)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-10)\n",
    "        return cam.cpu().numpy(), class_idx\n",
    "\n",
    "# --- Choose a target layer (typically last conv, but -2/-3 sometimes better) ---\n",
    "target_layer = model.backbone[-1]  # You can try -2, -3 for more spatial\n",
    "print(\"Target layer for CAM:\", target_layer)\n",
    "\n",
    "# --- Pick one sample per class ---\n",
    "seen = set()\n",
    "samples = []\n",
    "for img, label in dataset:\n",
    "    if label not in seen:\n",
    "        samples.append((img, label))\n",
    "        seen.add(label)\n",
    "    if len(seen) == num_classes:\n",
    "        break\n",
    "\n",
    "# --- Visualize CAMs for each class ---\n",
    "for img_tensor, label in samples:\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "    # Get the original image for overlay\n",
    "    original_img = inv_transform(img_tensor[0].cpu()).permute(1,2,0).numpy()\n",
    "    original_img = np.clip(original_img * 255, 0, 255).astype(np.uint8)\n",
    "    # Generate CAMs\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    cam1, _ = gradcam.generate(img_tensor)\n",
    "    gradcampp = GradCAMPlusPlus(model, target_layer)\n",
    "    cam2, _ = gradcampp.generate(img_tensor)\n",
    "    layercam = LayerCAM(model, target_layer)\n",
    "    cam3, _ = layercam.generate(img_tensor)\n",
    "    # Overlay utility\n",
    "    def overlay(img, cam):\n",
    "        cam = cv2.resize(cam, (224,224))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
    "        overlayed = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\n",
    "        return overlayed\n",
    "    # Plot all\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(original_img)\n",
    "    plt.title(f\"Original\\nClass: {class_names[label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(overlay(original_img, cam1))\n",
    "    plt.title(\"GradCAM\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(overlay(original_img, cam2))\n",
    "    plt.title(\"GradCAM++\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(overlay(original_img, cam3))\n",
    "    plt.title(\"LayerCAM\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7808913,
     "sourceId": 12383979,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
