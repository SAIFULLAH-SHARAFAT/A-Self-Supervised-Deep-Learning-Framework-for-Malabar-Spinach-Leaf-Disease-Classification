{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12383979,"sourceType":"datasetVersion","datasetId":7808913}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile simsiam_model.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as tv_models\n\n\nclass ProjectionMLP(nn.Module):\n    \"\"\"\n    SimSiam projection MLP (3-layer, paper-style):\n    fc -> BN -> ReLU -> fc -> BN -> ReLU -> fc -> BN(affine=False)\n    \"\"\"\n    def __init__(self, in_dim: int = 2048, hidden_dim: int = 2048, out_dim: int = 2048):\n        super().__init__()\n        self.layer1 = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim, bias=False),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n        )\n        self.layer2 = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim, bias=False),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n        )\n        self.layer3 = nn.Sequential(\n            nn.Linear(hidden_dim, out_dim, bias=False),\n            nn.BatchNorm1d(out_dim, affine=False),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        return x\n\n\nclass PredictionMLP(nn.Module):\n    \"\"\"\n    SimSiam prediction MLP:\n    fc -> BN -> ReLU -> fc\n    \"\"\"\n    def __init__(self, in_dim: int = 2048, hidden_dim: int = 512, out_dim: int = 2048):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim, bias=False),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, out_dim, bias=True),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.net(x)\n\n\ndef _resnet50_backbone(weights=None) -> nn.Module:\n    resnet = tv_models.resnet50(weights=weights)\n    return nn.Sequential(*list(resnet.children())[:-1])  \n\n\nclass SimSiam(nn.Module):\n    def __init__(self, backbone_weights=None):\n        super().__init__()\n        self.backbone = _resnet50_backbone(weights=backbone_weights)\n        self.projector = ProjectionMLP(2048, 2048, 2048)\n        self.predictor = PredictionMLP(2048, 512, 2048)\n\n    def forward_backbone(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.backbone(x)          # (B, 2048, 1, 1)\n        return torch.flatten(x, 1)    # (B, 2048)\n\n    def forward(self, x1: torch.Tensor, x2: torch.Tensor):\n        f1 = self.forward_backbone(x1)\n        f2 = self.forward_backbone(x2)\n\n        z1 = self.projector(f1)\n        z2 = self.projector(f2)\n\n        p1 = self.predictor(z1)\n        p2 = self.predictor(z2)\n\n        # stop-grad targets\n        return p1, p2, z1.detach(), z2.detach()\n\n\ndef neg_cosine_sim(p: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n    p = F.normalize(p, dim=1)\n    z = F.normalize(z, dim=1)\n    return -(p * z).sum(dim=1).mean()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T11:14:37.750499Z","iopub.execute_input":"2025-12-04T11:14:37.750864Z","iopub.status.idle":"2025-12-04T11:14:37.759906Z","shell.execute_reply.started":"2025-12-04T11:14:37.750839Z","shell.execute_reply":"2025-12-04T11:14:37.759087Z"}},"outputs":[{"name":"stdout","text":"Overwriting simsiam_model.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%writefile simsiam_pretrain.py\nimport os\nimport time\nimport random\nimport numpy as np\nfrom typing import Tuple\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\nfrom simsiam_model import SimSiam, neg_cosine_sim\n\n\ndef seed_all(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\nclass TwoCropsDataset(Dataset):\n    def __init__(self, root_dir: str, transform):\n        self.transform = transform\n        exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".webp\")\n\n        paths = []\n        for dp, _, fns in os.walk(root_dir):\n            for fn in fns:\n                if fn.lower().endswith(exts):\n                    paths.append(os.path.join(dp, fn))\n        self.paths = sorted(paths)\n        if len(self.paths) == 0:\n            raise RuntimeError(f\"No images found in: {root_dir}\")\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        x1 = self.transform(img)\n        x2 = self.transform(img)\n        return x1, x2\n\n\ndef save_checkpoint(path: str, epoch: int, model, optimizer, scheduler, scaler):\n    tmp = path + \".tmp\"\n    torch.save(\n        {\n            \"epoch\": epoch,\n            \"backbone\": model.backbone.state_dict(),\n            \"projector\": model.projector.state_dict(),\n            \"predictor\": model.predictor.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n            \"scheduler\": scheduler.state_dict(),\n            \"scaler\": scaler.state_dict(),\n        },\n        tmp,\n    )\n    os.replace(tmp, path)\n\n\ndef load_checkpoint(path: str, device, model, optimizer, scheduler, scaler):\n    ckpt = torch.load(path, map_location=device)\n    model.backbone.load_state_dict(ckpt[\"backbone\"])\n    model.projector.load_state_dict(ckpt[\"projector\"])\n    model.predictor.load_state_dict(ckpt[\"predictor\"])\n    optimizer.load_state_dict(ckpt[\"optimizer\"])\n    scheduler.load_state_dict(ckpt[\"scheduler\"])\n    scaler.load_state_dict(ckpt[\"scaler\"])\n    return int(ckpt[\"epoch\"]) + 1\n\n\ndef main(\n    root_path: str = \"/kaggle/input/minida/mini_output1/pretrain\",\n    out_dir: str = \"/kaggle/working/simsiam_resnet50\",\n    epochs: int = 200,\n    batch_size: int = 64,\n    num_workers: int = 2,\n    lr: float = None,\n    wd: float = 1e-4,\n    seed: int = 42,\n    save_every: int = 10,\n):\n    os.makedirs(out_dir, exist_ok=True)\n    seed_all(seed)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Device:\", device)\n\n    transform = transforms.Compose([\n        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n        transforms.RandomGrayscale(p=0.2),\n        transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225]),\n    ])\n\n    ds = TwoCropsDataset(root_path, transform)\n    loader = DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=True,\n        num_workers=num_workers,\n        pin_memory=(device.type == \"cuda\"),\n        persistent_workers=(num_workers > 0),\n    )\n\n    model = SimSiam(backbone_weights=None).to(device)\n\n    if lr is None:\n        lr = 0.05 * batch_size / 256.0\n\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n\n    ckpt_path = os.path.join(out_dir, \"checkpoint.pth\")\n    start_epoch = 0\n    if os.path.exists(ckpt_path):\n        print(\"Resuming from:\", ckpt_path)\n        start_epoch = load_checkpoint(ckpt_path, device, model, optimizer, scheduler, scaler)\n        print(\"Start epoch:\", start_epoch)\n\n    for epoch in range(start_epoch, epochs):\n        model.train()\n        t0 = time.time()\n        running = 0.0\n\n        for x1, x2 in loader:\n            x1 = x1.to(device, non_blocking=True)\n            x2 = x2.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n                p1, p2, z1, z2 = model(x1, x2)\n                # z1,z2 already detached by model, but keeping detach here is extra-safe\n                loss = 0.5 * (neg_cosine_sim(p1, z2) + neg_cosine_sim(p2, z1))\n\n            # sanity check (can remove after first run)\n            # assert loss.requires_grad, \"Loss must require grad\"\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            running += float(loss.item())\n\n        scheduler.step()\n        avg_loss = running / len(loader)\n        print(f\"Epoch {epoch+1:03d}/{epochs} | loss {avg_loss:.4f} | time {time.time()-t0:.1f}s\")\n\n        if (epoch + 1) % save_every == 0 or (epoch + 1) == epochs:\n            save_checkpoint(ckpt_path, epoch, model, optimizer, scheduler, scaler)\n\n    final_path = os.path.join(out_dir, \"simsiam_pretrained.pth\")\n    torch.save(\n        {\n            \"backbone\": model.backbone.state_dict(),\n            \"projector\": model.projector.state_dict(),\n            \"predictor\": model.predictor.state_dict(),\n        },\n        final_path,\n    )\n    print(\"Saved:\", final_path)\n\n\nif __name__ == \"__main__\":\n    main() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T11:20:58.282017Z","iopub.execute_input":"2025-12-04T11:20:58.282324Z","iopub.status.idle":"2025-12-04T11:20:58.289877Z","shell.execute_reply.started":"2025-12-04T11:20:58.282295Z","shell.execute_reply":"2025-12-04T11:20:58.289002Z"}},"outputs":[{"name":"stdout","text":"Overwriting simsiam_pretrain.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!python simsiam_pretrain.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T11:21:02.285361Z","iopub.execute_input":"2025-12-04T11:21:02.286134Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nResuming from: /kaggle/working/simsiam_resnet50/checkpoint.pth\nStart epoch: 190\nEpoch 191/200 | loss -0.9204 | time 88.3s\nEpoch 192/200 | loss -0.9110 | time 89.9s\nEpoch 193/200 | loss -0.9124 | time 85.1s\nEpoch 194/200 | loss -0.9207 | time 89.9s\nEpoch 195/200 | loss -0.9231 | time 87.1s\nEpoch 196/200 | loss -0.9337 | time 88.2s\nEpoch 197/200 | loss -0.9083 | time 93.2s\nEpoch 198/200 | loss -0.9249 | time 96.4s\nEpoch 199/200 | loss -0.9297 | time 90.4s\nEpoch 200/200 | loss -0.9186 | time 91.1s\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"%%writefile finetune_eval.py\nimport os\nos.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\")\n\nimport json\nimport random\nimport argparse\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import RandAugment\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, f1_score\n\n\n# ----------------------------\n# AMP compatibility wrapper\n# ----------------------------\ndef make_amp(device: torch.device):\n    use_cuda = (device.type == \"cuda\")\n    if hasattr(torch, \"amp\") and hasattr(torch.amp, \"autocast\") and hasattr(torch.amp, \"GradScaler\"):\n        autocast_fn = lambda: torch.amp.autocast(device_type=\"cuda\", enabled=use_cuda)\n        scaler = torch.amp.GradScaler(\"cuda\", enabled=use_cuda)\n        return autocast_fn, scaler\n    autocast_fn = lambda: torch.cuda.amp.autocast(enabled=use_cuda)\n    scaler = torch.cuda.amp.GradScaler(enabled=use_cuda)\n    return autocast_fn, scaler\n\n\n# ----------------------------\n# Determinism (review-proof)\n# ----------------------------\ndef seed_all(seed: int):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n    # TF32 off for more repeatability\n    try:\n        torch.backends.cuda.matmul.allow_tf32 = False\n        torch.backends.cudnn.allow_tf32 = False\n    except Exception:\n        pass\n\n    try:\n        torch.use_deterministic_algorithms(True)\n    except Exception:\n        pass\n\n\ndef seed_worker(worker_id: int):\n    wseed = torch.initial_seed() % 2**32\n    np.random.seed(wseed)\n    random.seed(wseed)\n\n\n# ----------------------------\n# Mixup\n# ----------------------------\ndef mixup_data(x: torch.Tensor, y: torch.Tensor, alpha: float, device: torch.device):\n    if alpha and alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n    bs = x.size(0)\n    idx = torch.randperm(bs, device=device)\n    mixed = lam * x + (1.0 - lam) * x[idx]\n    return mixed, y, y[idx], lam\n\n\ndef mixup_ce_loss(ce, logits, y_a, y_b, lam: float):\n    return lam * ce(logits, y_a) + (1.0 - lam) * ce(logits, y_b)\n\n\n# ----------------------------\n# SupCon (MULTI-VIEW, CORRECT MASK)\n# ----------------------------\nclass SupConLoss(nn.Module):\n    \"\"\"\n    Multi-view supervised contrastive loss.\n    Expects feats of shape (B, V, D) where V>=2.\n    \"\"\"\n    def __init__(self, temperature: float = 0.07, eps: float = 1e-8):\n        super().__init__()\n        self.t = float(temperature)\n        self.eps = float(eps)\n\n    def forward(self, feats: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        device = feats.device\n        B, V, D = feats.shape\n\n        feats = F.normalize(feats, dim=2).float()      # (B,V,D)\n        feats = feats.view(B * V, D)                   # (BV,D)\n\n        labels = labels.contiguous().view(B, 1)        # (B,1)\n        labels = labels.repeat(1, V).view(B * V, 1)    # (BV,1)\n        mask = torch.eq(labels, labels.T).float().to(device)  # (BV,BV)\n        mask.fill_diagonal_(0)\n\n        logits = (feats @ feats.T) / self.t\n        logits = logits - logits.max(dim=1, keepdim=True).values.detach()\n\n        eye = torch.eye(B * V, device=device)\n        exp_logits = torch.exp(logits) * (1.0 - eye)\n        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + self.eps)\n\n        pos_count = mask.sum(dim=1)\n        mean_log_prob_pos = (mask * log_prob).sum(dim=1) / (pos_count + self.eps)\n        return -mean_log_prob_pos.mean()\n\n\n# ----------------------------\n# Two-view dataset wrapper (HYBRID only)\n# ----------------------------\nclass TwoCropTransform:\n    def __init__(self, base_transform):\n        self.base = base_transform\n\n    def __call__(self, img):\n        return self.base(img), self.base(img)\n\n\nclass ImageFolderTwoView(ImageFolder):\n    def __getitem__(self, index):\n        path, y = self.samples[index]\n        img = self.loader(path)\n        x1, x2 = self.transform(img)\n        return (x1, x2), y\n\n\n# ----------------------------\n# Model\n# ----------------------------\nclass FineTuneModel(nn.Module):\n    def __init__(self, pretrained_path: str, num_classes: int, hybrid: bool):\n        super().__init__()\n        try:\n            resnet = models.resnet50(weights=None)\n        except TypeError:\n            resnet = models.resnet50(pretrained=False)\n\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n\n        self.classifier = nn.Sequential(\n            nn.Linear(2048, 512, bias=True),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.30),\n            nn.Linear(512, num_classes, bias=True),\n        )\n\n        self.hybrid = bool(hybrid)\n        self.supcon_proj = nn.Linear(2048, 128, bias=True) if self.hybrid else None\n\n        ckpt = torch.load(pretrained_path, map_location=\"cpu\")\n        sd = ckpt.get(\"backbone\", ckpt)\n        missing, unexpected = self.backbone.load_state_dict(sd, strict=False)\n        if missing or unexpected:\n            print(f\"[state_dict notice] missing: {missing} | unexpected: {unexpected}\")\n\n    def forward_feats(self, x: torch.Tensor) -> torch.Tensor:\n        return self.backbone(x).flatten(1)  # (B,2048)\n\n    def logits_from_feats(self, feats: torch.Tensor) -> torch.Tensor:\n        return self.classifier(feats)\n\n    def supcon_from_feats(self, feats: torch.Tensor) -> torch.Tensor:\n        if not self.hybrid:\n            raise RuntimeError(\"supcon_from_feats called while hybrid=False\")\n        return F.normalize(self.supcon_proj(feats), dim=1)\n\n    def forward(self, x: torch.Tensor):\n        feats = self.forward_feats(x)\n        return self.logits_from_feats(feats)\n\n\ndef count_params_m(model: nn.Module) -> float:\n    return sum(p.numel() for p in model.parameters()) / 1e6\n\n\n# ----------------------------\n# Data\n# ----------------------------\ndef build_datasets(data_root: str):\n    train_dir = os.path.join(data_root, \"train\")\n    val_dir   = os.path.join(data_root, \"val\")\n    test_dir  = os.path.join(data_root, \"test\")\n\n    train_tf = transforms.Compose([\n        transforms.RandomResizedCrop(224, scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        RandAugment(num_ops=2, magnitude=7),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n    ])\n\n    eval_tf = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n    ])\n\n    train_ds_ce = ImageFolder(train_dir, transform=train_tf)\n    train_ds_hybrid = ImageFolderTwoView(train_dir, transform=TwoCropTransform(train_tf))\n\n    val_ds   = ImageFolder(val_dir,   transform=eval_tf)\n    test_ds  = ImageFolder(test_dir,  transform=eval_tf)\n\n    class_names = train_ds_ce.classes\n    assert val_ds.classes == class_names and test_ds.classes == class_names, \\\n        \"Class folder names/order mismatch across splits.\"\n    assert train_ds_hybrid.classes == class_names, \"HYBRID train classes mismatch.\"\n\n    return train_ds_ce, train_ds_hybrid, val_ds, test_ds, class_names, train_dir, val_dir, test_dir\n\n\ndef build_loaders(train_ds, val_ds, test_ds, batch_size, num_workers, seed, use_weighted_sampler: bool):\n    g = torch.Generator()\n    g.manual_seed(seed)\n    pin = torch.cuda.is_available()\n\n    if use_weighted_sampler:\n        targets = np.array(train_ds.targets, dtype=np.int64)\n        counts = np.bincount(targets)\n        counts[counts == 0] = 1\n        class_w = 1.0 / counts\n        sample_w = class_w[targets]\n        sampler = WeightedRandomSampler(\n            weights=torch.as_tensor(sample_w, dtype=torch.double),\n            num_samples=len(sample_w),\n            replacement=True\n        )\n        shuffle = False\n    else:\n        sampler = None\n        shuffle = True\n\n    train_loader = DataLoader(\n        train_ds, batch_size=batch_size,\n        shuffle=shuffle, sampler=sampler,\n        num_workers=num_workers, pin_memory=pin,\n        worker_init_fn=seed_worker, generator=g,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    val_loader = DataLoader(\n        val_ds, batch_size=batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=pin,\n        worker_init_fn=seed_worker, generator=g,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    test_loader = DataLoader(\n        test_ds, batch_size=batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=pin,\n        worker_init_fn=seed_worker, generator=g,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    return train_loader, val_loader, test_loader\n\n\n# ----------------------------\n# Metrics / eval\n# ----------------------------\ndef macro_roc_auc(y_true: np.ndarray, probs: np.ndarray, n_classes: int) -> float:\n    onehot = np.eye(n_classes)[y_true]\n    return float(roc_auc_score(onehot, probs, average=\"macro\", multi_class=\"ovr\"))\n\n\n@torch.no_grad()\ndef eval_loader(model, loader, device) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float]:\n    model.eval()\n    ce_plain = nn.CrossEntropyLoss()\n    ys, preds, probs = [], [], []\n    total_loss = 0.0\n    n = 0\n    for x, y in loader:\n        x = x.to(device)\n        y = y.to(device)\n        logits = model(x)\n        pr = F.softmax(logits, dim=1)\n        loss = ce_plain(logits, y)\n\n        bs = x.size(0)\n        total_loss += float(loss.item()) * bs\n        n += bs\n\n        ys.append(y.cpu().numpy())\n        preds.append(logits.argmax(1).cpu().numpy())\n        probs.append(pr.cpu().numpy())\n\n    y = np.concatenate(ys)\n    p = np.concatenate(preds)\n    pr = np.concatenate(probs)\n    return y, p, pr, total_loss / max(n, 1)\n\n\n# ----------------------------\n# TTA policies\n# ----------------------------\ndef _tta_views_transforms(n_views: int):\n    norm = transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n    v1 = [\n        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), norm]),\n    ]\n    v2 = [\n        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), norm]),\n        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224),\n                            transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), norm]),\n    ]\n    v4 = [\n        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), norm]),\n        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224),\n                            transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), norm]),\n        transforms.Compose([transforms.Resize(288), transforms.CenterCrop(224), transforms.ToTensor(), norm]),\n        transforms.Compose([transforms.Resize(288), transforms.CenterCrop(224),\n                            transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), norm]),\n    ]\n    if n_views == 1:\n        return v1, \"V1: center@256\"\n    if n_views == 2:\n        return v2, \"V2: center@256 + hflip@256\"\n    if n_views == 4:\n        return v4, \"V4: center/hflip @256 and @288\"\n    raise ValueError(\"n_views must be one of {1,2,4}\")\n\n\n@torch.no_grad()\ndef tta_probs(model, dataset_dir: str, class_names: List[str], device, batch_size, num_workers, seed, n_views: int):\n    g = torch.Generator()\n    g.manual_seed(seed)\n\n    base_ds = ImageFolder(dataset_dir)\n    assert base_ds.classes == class_names, \"TTA dataset class order mismatch.\"\n\n    tfms, policy = _tta_views_transforms(n_views)\n    y_true = np.array(base_ds.targets, dtype=np.int64)\n\n    model.eval()\n    probs_all = []\n    for tfm in tfms:\n        base_ds.transform = tfm\n        loader = DataLoader(\n            base_ds, batch_size=batch_size, shuffle=False,\n            num_workers=num_workers, pin_memory=torch.cuda.is_available(),\n            worker_init_fn=seed_worker, generator=g,\n            persistent_workers=True if num_workers > 0 else False\n        )\n        chunks = []\n        for x, _ in loader:\n            x = x.to(device)\n            logits = model(x)\n            chunks.append(F.softmax(logits, dim=1).cpu().numpy())\n        probs_all.append(np.concatenate(chunks, axis=0))\n\n    mean_probs = np.mean(probs_all, axis=0)\n    return y_true, mean_probs, policy\n\n\ndef pick_tta_policy_on_val(model, val_dir: str, class_names: List[str], device, batch_size, num_workers, seed,\n                           candidate_views=(1, 2, 4)):\n    best = {\"views\": 1, \"acc\": -1.0, \"policy\": \"\"}\n    per_policy = {}\n\n    for k in candidate_views:\n        y, probs, policy = tta_probs(\n            model=model, dataset_dir=val_dir, class_names=class_names,\n            device=device, batch_size=batch_size, num_workers=num_workers, seed=seed, n_views=k\n        )\n        pred = probs.argmax(axis=1)\n        acc = float(accuracy_score(y, pred))\n        per_policy[str(k)] = {\"val_acc\": acc, \"policy\": policy}\n        if acc > best[\"acc\"]:\n            best = {\"views\": int(k), \"acc\": acc, \"policy\": policy}\n\n    return best, per_policy\n\n\n# ----------------------------\n# Train one seed\n# ----------------------------\ndef train_one_seed(\n    mode: str,\n    seed: int,\n    pretrained_path: str,\n    train_ds, val_ds, test_ds,\n    class_names: List[str],\n    val_dir: str,\n    test_dir: str,\n    device: torch.device,\n    out_dir: str,\n    epochs: int,\n    patience: int,\n    batch_size: int,\n    num_workers: int,\n    use_weighted_sampler: bool,\n    lr_backbone: float,\n    lr_head: float,\n    weight_decay: float,\n    label_smoothing: float,\n    mixup_alpha: float,\n    supcon_weight: float,\n    temperature: float,\n    tta_candidates: List[int],\n) -> Dict:\n    seed_all(seed)\n    os.makedirs(out_dir, exist_ok=True)\n\n    hybrid = (mode.upper() == \"HYBRID\")\n    model = FineTuneModel(pretrained_path, num_classes=len(class_names), hybrid=hybrid).to(device)\n\n    # BN trainable\n    model.train()\n    for m in model.modules():\n        if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n            m.train()\n            for p in m.parameters():\n                p.requires_grad = True\n\n    train_loader, val_loader, test_loader = build_loaders(\n        train_ds, val_ds, test_ds,\n        batch_size=batch_size, num_workers=num_workers, seed=seed,\n        use_weighted_sampler=use_weighted_sampler\n    )\n\n    # sampler => unweighted CE (avoid double-compensation)\n    if use_weighted_sampler:\n        ce = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n    else:\n        targets = np.array(train_ds.targets, dtype=np.int64)\n        counts = np.bincount(targets)\n        counts[counts == 0] = 1\n        w = (1.0 / counts)\n        w = w / w.mean()\n        ce = nn.CrossEntropyLoss(\n            weight=torch.tensor(w, dtype=torch.float32, device=device),\n            label_smoothing=label_smoothing\n        )\n\n    supcon = SupConLoss(temperature=temperature) if hybrid else None\n\n    backbone_params, head_params = [], []\n    for n, p in model.named_parameters():\n        if not p.requires_grad:\n            continue\n        if n.startswith(\"backbone\"):\n            backbone_params.append(p)\n        else:\n            head_params.append(p)\n\n    optimizer = torch.optim.AdamW(\n        [{\"params\": backbone_params, \"lr\": lr_backbone},\n         {\"params\": head_params, \"lr\": lr_head}],\n        weight_decay=weight_decay\n    )\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n    autocast_ctx, scaler = make_amp(device)\n\n    best_val_acc = -1.0\n    bad = 0\n    best_path = os.path.join(out_dir, f\"best_{mode.lower()}_seed{seed}.pth\")\n\n    for ep in range(1, epochs + 1):\n        model.train()\n        total_loss = 0.0\n        correct = 0.0\n        nseen = 0\n\n        for batch in train_loader:\n            optimizer.zero_grad(set_to_none=True)\n\n            if hybrid:\n                (x1, x2), y = batch\n                x1 = x1.to(device, non_blocking=True)\n                x2 = x2.to(device, non_blocking=True)\n                y = y.to(device, non_blocking=True)\n\n                with autocast_ctx():\n                    # ---- CE (view-1), optional mixup on view-1 only ----\n                    if mixup_alpha and mixup_alpha > 0:\n                        xmix, ya, yb, lam = mixup_data(x1, y, mixup_alpha, device)\n                        feats_mix = model.forward_feats(xmix)\n                        logits_mix = model.logits_from_feats(feats_mix)\n                        loss_ce = mixup_ce_loss(ce, logits_mix, ya, yb, lam)\n\n                        pred = logits_mix.argmax(1)\n                        correct += lam * pred.eq(ya).sum().item() + (1.0 - lam) * pred.eq(yb).sum().item()\n                    else:\n                        feats1 = model.forward_feats(x1)\n                        logits1 = model.logits_from_feats(feats1)\n                        loss_ce = ce(logits1, y)\n\n                        pred = logits1.argmax(1)\n                        correct += pred.eq(y).sum().item()\n\n                    # ---- SupCon on clean views (x1,x2) ----\n                    feats1_clean = model.forward_feats(x1)\n                    feats2_clean = model.forward_feats(x2)\n                    z1 = model.supcon_from_feats(feats1_clean)\n                    z2 = model.supcon_from_feats(feats2_clean)\n                    feats = torch.stack([z1, z2], dim=1)  # (B,2,128)\n                    loss_sup = supcon(feats, y)\n\n                    # CE-dominant additive form\n                    loss = loss_ce + supcon_weight * loss_sup\n\n            else:\n                x, y = batch\n                x = x.to(device, non_blocking=True)\n                y = y.to(device, non_blocking=True)\n\n                with autocast_ctx():\n                    if mixup_alpha and mixup_alpha > 0:\n                        xmix, ya, yb, lam = mixup_data(x, y, mixup_alpha, device)\n                        feats_mix = model.forward_feats(xmix)\n                        logits = model.logits_from_feats(feats_mix)\n                        loss = mixup_ce_loss(ce, logits, ya, yb, lam)\n\n                        pred = logits.argmax(1)\n                        correct += lam * pred.eq(ya).sum().item() + (1.0 - lam) * pred.eq(yb).sum().item()\n                    else:\n                        feats = model.forward_feats(x)\n                        logits = model.logits_from_feats(feats)\n                        loss = ce(logits, y)\n\n                        pred = logits.argmax(1)\n                        correct += pred.eq(y).sum().item()\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            bs = y.size(0)\n            total_loss += float(loss.item()) * bs\n            nseen += bs\n\n        scheduler.step()\n\n        train_loss = total_loss / max(nseen, 1)\n        train_acc = float(correct) / max(nseen, 1)\n\n        yv, pv, _, vloss = eval_loader(model, val_loader, device)\n        val_acc = float(accuracy_score(yv, pv))\n        val_f1  = float(f1_score(yv, pv, average=\"macro\"))\n\n        saved = \"\"\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            bad = 0\n            torch.save(model.state_dict(), best_path)\n            saved = \"(saved)\"\n        else:\n            bad += 1\n\n        print(f\"[{mode}][seed={seed}] Epoch {ep:02d}/{epochs} | \"\n              f\"train loss {train_loss:.4f} acc {train_acc:.4f} || \"\n              f\"val loss {vloss:.4f} acc {val_acc:.4f} macroF1 {val_f1:.4f} {saved}\")\n\n        if bad >= patience:\n            print(f\"[{mode}][seed={seed}] Early stopping.\")\n            break\n\n    # Load best\n    model.load_state_dict(torch.load(best_path, map_location=device))\n    model.eval()\n\n    # Test single-crop\n    yt, pt, prt, tloss = eval_loader(model, test_loader, device)\n    test_acc = float(accuracy_score(yt, pt))\n    auc = float(macro_roc_auc(yt, prt, len(class_names)))\n\n    # Select TTA policy on VAL, then apply once on TEST\n    best_tta, per_policy = pick_tta_policy_on_val(\n        model=model,\n        val_dir=val_dir,\n        class_names=class_names,\n        device=device,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        seed=seed,\n        candidate_views=tuple(tta_candidates)\n    )\n\n    ytta, prob_tta, chosen_policy = tta_probs(\n        model=model,\n        dataset_dir=test_dir,\n        class_names=class_names,\n        device=device,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        seed=seed,\n        n_views=best_tta[\"views\"]\n    )\n    pred_tta = prob_tta.argmax(axis=1)\n    tta_acc = float(accuracy_score(ytta, pred_tta))\n    auc_tta = float(macro_roc_auc(ytta, prob_tta, len(class_names)))\n\n    rep = classification_report(yt, pt, target_names=class_names, digits=4)\n    cm = confusion_matrix(yt, pt).tolist()\n\n    return {\n        \"mode\": mode,\n        \"seed\": int(seed),\n        \"epochs_ran\": int(ep),\n        \"best_val_acc\": float(best_val_acc),\n        \"test_loss\": float(tloss),\n        \"test_acc\": float(test_acc),\n        \"tta_acc\": float(tta_acc),\n        \"macro_auc\": float(auc),\n        \"macro_auc_tta\": float(auc_tta),\n        \"params_m\": float(round(count_params_m(model), 4)),\n        \"tta_candidates\": list(map(int, tta_candidates)),\n        \"tta_val_selection\": {\n            \"picked_views\": int(best_tta[\"views\"]),\n            \"picked_val_acc\": float(best_tta[\"acc\"]),\n            \"picked_policy\": best_tta[\"policy\"],\n            \"all_candidates\": per_policy\n        },\n        \"tta_policy_applied_to_test\": chosen_policy,\n        \"confusion_matrix\": cm,\n        \"classification_report\": rep,\n        \"checkpoint_path\": best_path\n    }\n\n\n# ----------------------------\n# Summary\n# ----------------------------\n@dataclass\nclass SummaryStats:\n    mean: float\n    std: float\n\n\ndef summarize(values: List[float]) -> SummaryStats:\n    a = np.array(values, dtype=np.float64)\n    if len(a) <= 1:\n        return SummaryStats(mean=float(a.mean()) if len(a) else 0.0, std=0.0)\n    return SummaryStats(mean=float(a.mean()), std=float(a.std(ddof=1)))\n\n\n# ----------------------------\n# Main\n# ----------------------------\ndef main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data_root\", type=str, required=True)\n    ap.add_argument(\"--pretrained_path\", type=str, required=True)\n    ap.add_argument(\"--out_json\", type=str, default=\"results_3seeds.json\")\n    ap.add_argument(\"--out_dir\", type=str, default=\"./runs_reviewproof\")\n\n    ap.add_argument(\"--seeds\", type=int, nargs=\"+\", default=[0, 1, 2])\n    ap.add_argument(\"--epochs\", type=int, default=60)\n    ap.add_argument(\"--patience\", type=int, default=10)\n    ap.add_argument(\"--batch_size\", type=int, default=32)\n    ap.add_argument(\"--num_workers\", type=int, default=2)\n\n    ap.add_argument(\"--use_weighted_sampler\", action=\"store_true\")\n\n    ap.add_argument(\"--label_smoothing\", type=float, default=0.0)\n    ap.add_argument(\"--weight_decay\", type=float, default=1e-4)\n\n    # CE defaults (safe)\n    ap.add_argument(\"--ce_lr_backbone\", type=float, default=3e-5)\n    ap.add_argument(\"--ce_lr_head\", type=float, default=2e-4)\n    ap.add_argument(\"--ce_mixup_alpha\", type=float, default=0.0)\n\n    # HYBRID defaults (safer than 1e-3 head LR)\n    ap.add_argument(\"--hy_lr_backbone\", type=float, default=3e-5)\n    ap.add_argument(\"--hy_lr_head\", type=float, default=1e-4)\n    ap.add_argument(\"--hy_mixup_alpha\", type=float, default=0.05)\n    ap.add_argument(\"--supcon_weight\", type=float, default=0.04)\n    ap.add_argument(\"--temperature\", type=float, default=0.07)\n\n    ap.add_argument(\"--tta_candidates\", type=int, nargs=\"+\", default=[1, 2, 4],\n                    help=\"TTA candidates to try on VAL (subset of {1,2,4}).\")\n\n    args = ap.parse_args()\n\n    allowed = {1, 2, 4}\n    cand = [int(x) for x in args.tta_candidates]\n    if any(x not in allowed for x in cand) or len(cand) == 0:\n        raise ValueError(\"--tta_candidates must be a non-empty subset of {1,2,4} (e.g., 1 2 4).\")\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Device: {device}\")\n\n    if not os.path.exists(args.pretrained_path):\n        raise FileNotFoundError(f\"Pretrained weights not found: {args.pretrained_path}\")\n\n    train_ds_ce, train_ds_hybrid, val_ds, test_ds, class_names, train_dir, val_dir, test_dir = build_datasets(args.data_root)\n    print(\"Classes:\", class_names)\n    print(\"Split dirs:\", {\"train\": train_dir, \"val\": val_dir, \"test\": test_dir})\n\n    all_results = {\"config\": vars(args), \"class_names\": class_names, \"per_seed\": []}\n\n    for mode in [\"CE\", \"HYBRID\"]:\n        train_ds = train_ds_ce if mode == \"CE\" else train_ds_hybrid\n        for seed in args.seeds:\n            r = train_one_seed(\n                mode=mode,\n                seed=seed,\n                pretrained_path=args.pretrained_path,\n                train_ds=train_ds,\n                val_ds=val_ds,\n                test_ds=test_ds,\n                class_names=class_names,\n                val_dir=val_dir,\n                test_dir=test_dir,\n                device=device,\n                out_dir=args.out_dir,\n                epochs=args.epochs,\n                patience=args.patience,\n                batch_size=args.batch_size,\n                num_workers=args.num_workers,\n                use_weighted_sampler=args.use_weighted_sampler,\n                lr_backbone=(args.ce_lr_backbone if mode == \"CE\" else args.hy_lr_backbone),\n                lr_head=(args.ce_lr_head if mode == \"CE\" else args.hy_lr_head),\n                weight_decay=args.weight_decay,\n                label_smoothing=args.label_smoothing,\n                mixup_alpha=(args.ce_mixup_alpha if mode == \"CE\" else args.hy_mixup_alpha),\n                supcon_weight=args.supcon_weight,\n                temperature=args.temperature,\n                tta_candidates=cand\n            )\n            all_results[\"per_seed\"].append(r)\n\n    def collect(mode: str, key: str) -> List[float]:\n        return [x[key] for x in all_results[\"per_seed\"] if x[\"mode\"] == mode]\n\n    summary = {}\n    for mode in [\"CE\", \"HYBRID\"]:\n        s = {\n            \"test_acc_%\": asdict(summarize([v * 100.0 for v in collect(mode, \"test_acc\")])),\n            \"tta_acc_%\": asdict(summarize([v * 100.0 for v in collect(mode, \"tta_acc\")])),\n            \"macro_auc\": asdict(summarize(collect(mode, \"macro_auc\"))),\n            \"macro_auc_tta\": asdict(summarize(collect(mode, \"macro_auc_tta\"))),\n            \"params_m\": asdict(summarize(collect(mode, \"params_m\"))),\n        }\n        summary[mode] = s\n\n    all_results[\"summary\"] = summary\n\n    print(\"\\n================ SUMMARY (mean ± std over seeds) ================\\n\")\n    for mode in [\"CE\", \"HYBRID\"]:\n        s = summary[mode]\n        print(f\"MODE: {mode}\")\n        print(f\"Test Acc (%): {s['test_acc_%']['mean']:.2f} ± {s['test_acc_%']['std']:.2f}\")\n        print(f\"TTA  Acc (%): {s['tta_acc_%']['mean']:.2f} ± {s['tta_acc_%']['std']:.2f}\")\n        print(f\"Macro ROC-AUC (single): {s['macro_auc']['mean']:.4f} ± {s['macro_auc']['std']:.4f}\")\n        print(f\"Macro ROC-AUC (TTA):    {s['macro_auc_tta']['mean']:.4f} ± {s['macro_auc_tta']['std']:.4f}\")\n        print(f\"# Params (M): {s['params_m']['mean']:.2f} ± {s['params_m']['std']:.2f}\")\n        print()\n\n    with open(args.out_json, \"w\") as f:\n        json.dump(all_results, f, indent=2)\n    print(f\"Saved per-seed metrics: {args.out_json}\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T22:01:24.763091Z","iopub.execute_input":"2025-12-05T22:01:24.763867Z","iopub.status.idle":"2025-12-05T22:01:24.780111Z","shell.execute_reply.started":"2025-12-05T22:01:24.763837Z","shell.execute_reply":"2025-12-05T22:01:24.779385Z"}},"outputs":[{"name":"stdout","text":"Overwriting finetune_eval.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python finetune_eval.py \\\n  --data_root /kaggle/input/minida/mini_output1 \\\n  --pretrained_path /kaggle/working/simsiam_resnet50/simsiam_pretrained.pth \\\n  --seeds 0 1 2 \\\n  --epochs 60 --patience 10 --batch_size 32 --num_workers 2 \\\n  --label_smoothing 0.0 --weight_decay 1e-4 \\\n  --ce_lr_backbone 3e-5 --ce_lr_head 2e-4 --ce_mixup_alpha 0.0 \\\n  --hy_lr_backbone 3e-5 --hy_lr_head 1e-4 --hy_mixup_alpha 0.05 \\\n  --supcon_weight 0.04 --temperature 0.07 \\\n  --tta_candidates 1 2 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T22:01:37.309381Z","iopub.execute_input":"2025-12-05T22:01:37.309769Z","iopub.status.idle":"2025-12-06T00:13:40.862258Z","shell.execute_reply.started":"2025-12-05T22:01:37.309743Z","shell.execute_reply":"2025-12-06T00:13:40.861316Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nClasses: ['Alternaria', 'Healthy Leaf', 'straw_mite']\nSplit dirs: {'train': '/kaggle/input/minida/mini_output1/train', 'val': '/kaggle/input/minida/mini_output1/val', 'test': '/kaggle/input/minida/mini_output1/test'}\n[CE][seed=0] Epoch 01/60 | train loss 0.9798 acc 0.5624 || val loss 0.9109 acc 0.7980 macroF1 0.7908 (saved)\n[CE][seed=0] Epoch 02/60 | train loss 0.8449 acc 0.6364 || val loss 0.7515 acc 0.7980 macroF1 0.7880 \n[CE][seed=0] Epoch 03/60 | train loss 0.7737 acc 0.6871 || val loss 0.6464 acc 0.7172 macroF1 0.6744 \n[CE][seed=0] Epoch 04/60 | train loss 0.7244 acc 0.6977 || val loss 0.5547 acc 0.7576 macroF1 0.7328 \n[CE][seed=0] Epoch 05/60 | train loss 0.7351 acc 0.6956 || val loss 0.4381 acc 0.8788 macroF1 0.8803 (saved)\n[CE][seed=0] Epoch 06/60 | train loss 0.6099 acc 0.7569 || val loss 0.3714 acc 0.8788 macroF1 0.8804 \n[CE][seed=0] Epoch 07/60 | train loss 0.5594 acc 0.7569 || val loss 0.3461 acc 0.8586 macroF1 0.8633 \n[CE][seed=0] Epoch 08/60 | train loss 0.6008 acc 0.7400 || val loss 0.5422 acc 0.7576 macroF1 0.7518 \n[CE][seed=0] Epoch 09/60 | train loss 0.5575 acc 0.7569 || val loss 0.3399 acc 0.8788 macroF1 0.8808 \n[CE][seed=0] Epoch 10/60 | train loss 0.4792 acc 0.7970 || val loss 0.3113 acc 0.8990 macroF1 0.9002 (saved)\n[CE][seed=0] Epoch 11/60 | train loss 0.4846 acc 0.8224 || val loss 0.2837 acc 0.8990 macroF1 0.9009 \n[CE][seed=0] Epoch 12/60 | train loss 0.4898 acc 0.8076 || val loss 0.2896 acc 0.8889 macroF1 0.8888 \n[CE][seed=0] Epoch 13/60 | train loss 0.4809 acc 0.8013 || val loss 0.2824 acc 0.8889 macroF1 0.8898 \n[CE][seed=0] Epoch 14/60 | train loss 0.4520 acc 0.7886 || val loss 0.2889 acc 0.8788 macroF1 0.8803 \n[CE][seed=0] Epoch 15/60 | train loss 0.4778 acc 0.7928 || val loss 0.2745 acc 0.8990 macroF1 0.8992 \n[CE][seed=0] Epoch 16/60 | train loss 0.4411 acc 0.7992 || val loss 0.3391 acc 0.8586 macroF1 0.8620 \n[CE][seed=0] Epoch 17/60 | train loss 0.4709 acc 0.8161 || val loss 0.2462 acc 0.8687 macroF1 0.8703 \n[CE][seed=0] Epoch 18/60 | train loss 0.4303 acc 0.8097 || val loss 0.2288 acc 0.8889 macroF1 0.8903 \n[CE][seed=0] Epoch 19/60 | train loss 0.4219 acc 0.8288 || val loss 0.3046 acc 0.8485 macroF1 0.8531 \n[CE][seed=0] Epoch 20/60 | train loss 0.3852 acc 0.8182 || val loss 0.3155 acc 0.8384 macroF1 0.8416 \n[CE][seed=0] Early stopping.\n[CE][seed=1] Epoch 01/60 | train loss 1.0242 acc 0.5962 || val loss 0.9436 acc 0.6364 macroF1 0.5394 (saved)\n[CE][seed=1] Epoch 02/60 | train loss 0.8200 acc 0.6469 || val loss 0.7276 acc 0.7071 macroF1 0.6657 (saved)\n[CE][seed=1] Epoch 03/60 | train loss 0.8147 acc 0.6385 || val loss 0.6902 acc 0.6768 macroF1 0.6094 \n[CE][seed=1] Epoch 04/60 | train loss 0.7402 acc 0.6956 || val loss 0.5596 acc 0.7879 macroF1 0.7749 (saved)\n[CE][seed=1] Epoch 05/60 | train loss 0.6392 acc 0.7252 || val loss 0.4632 acc 0.8182 macroF1 0.8155 (saved)\n[CE][seed=1] Epoch 06/60 | train loss 0.5893 acc 0.7336 || val loss 0.4120 acc 0.8687 macroF1 0.8698 (saved)\n[CE][seed=1] Epoch 07/60 | train loss 0.5848 acc 0.7611 || val loss 0.4539 acc 0.8182 macroF1 0.8147 \n[CE][seed=1] Epoch 08/60 | train loss 0.5694 acc 0.7569 || val loss 0.3979 acc 0.8283 macroF1 0.8261 \n[CE][seed=1] Epoch 09/60 | train loss 0.5434 acc 0.7738 || val loss 0.2938 acc 0.8990 macroF1 0.9013 (saved)\n[CE][seed=1] Epoch 10/60 | train loss 0.4976 acc 0.7970 || val loss 0.3097 acc 0.8990 macroF1 0.9012 \n[CE][seed=1] Epoch 11/60 | train loss 0.5046 acc 0.8076 || val loss 0.2814 acc 0.8889 macroF1 0.8896 \n[CE][seed=1] Epoch 12/60 | train loss 0.4316 acc 0.8097 || val loss 0.3207 acc 0.8485 macroF1 0.8535 \n[CE][seed=1] Epoch 13/60 | train loss 0.5003 acc 0.7844 || val loss 0.3185 acc 0.8990 macroF1 0.8985 \n[CE][seed=1] Epoch 14/60 | train loss 0.4296 acc 0.8309 || val loss 0.2973 acc 0.8687 macroF1 0.8701 \n[CE][seed=1] Epoch 15/60 | train loss 0.4247 acc 0.8288 || val loss 0.2929 acc 0.8990 macroF1 0.8992 \n[CE][seed=1] Epoch 16/60 | train loss 0.4750 acc 0.8140 || val loss 0.2995 acc 0.8990 macroF1 0.8976 \n[CE][seed=1] Epoch 17/60 | train loss 0.4005 acc 0.8330 || val loss 0.3135 acc 0.8687 macroF1 0.8689 \n[CE][seed=1] Epoch 18/60 | train loss 0.4978 acc 0.8055 || val loss 0.3892 acc 0.8283 macroF1 0.8306 \n[CE][seed=1] Epoch 19/60 | train loss 0.4569 acc 0.8055 || val loss 0.2313 acc 0.8990 macroF1 0.9003 \n[CE][seed=1] Early stopping.\n[CE][seed=2] Epoch 01/60 | train loss 1.1041 acc 0.4863 || val loss 0.9392 acc 0.7677 macroF1 0.7755 (saved)\n[CE][seed=2] Epoch 02/60 | train loss 0.9020 acc 0.6216 || val loss 0.7754 acc 0.7172 macroF1 0.6747 \n[CE][seed=2] Epoch 03/60 | train loss 0.8221 acc 0.6490 || val loss 0.6524 acc 0.8283 macroF1 0.8252 (saved)\n[CE][seed=2] Epoch 04/60 | train loss 0.7328 acc 0.6977 || val loss 0.5736 acc 0.7980 macroF1 0.7923 \n[CE][seed=2] Epoch 05/60 | train loss 0.6719 acc 0.7378 || val loss 0.4848 acc 0.8687 macroF1 0.8692 (saved)\n[CE][seed=2] Epoch 06/60 | train loss 0.6104 acc 0.7484 || val loss 0.4073 acc 0.8889 macroF1 0.8908 (saved)\n[CE][seed=2] Epoch 07/60 | train loss 0.6046 acc 0.7632 || val loss 0.3861 acc 0.8586 macroF1 0.8603 \n[CE][seed=2] Epoch 08/60 | train loss 0.5578 acc 0.7696 || val loss 0.3557 acc 0.8889 macroF1 0.8907 \n[CE][seed=2] Epoch 09/60 | train loss 0.5339 acc 0.7632 || val loss 0.4858 acc 0.8182 macroF1 0.8213 \n[CE][seed=2] Epoch 10/60 | train loss 0.4765 acc 0.7886 || val loss 0.3221 acc 0.8384 macroF1 0.8410 \n[CE][seed=2] Epoch 11/60 | train loss 0.5118 acc 0.7907 || val loss 0.2870 acc 0.8990 macroF1 0.9000 (saved)\n[CE][seed=2] Epoch 12/60 | train loss 0.4966 acc 0.7738 || val loss 0.2585 acc 0.8990 macroF1 0.9008 \n[CE][seed=2] Epoch 13/60 | train loss 0.4833 acc 0.7759 || val loss 0.2552 acc 0.8889 macroF1 0.8903 \n[CE][seed=2] Epoch 14/60 | train loss 0.4694 acc 0.8245 || val loss 0.2988 acc 0.8687 macroF1 0.8698 \n[CE][seed=2] Epoch 15/60 | train loss 0.4686 acc 0.8140 || val loss 0.2621 acc 0.8788 macroF1 0.8814 \n[CE][seed=2] Epoch 16/60 | train loss 0.4498 acc 0.8245 || val loss 0.2752 acc 0.8889 macroF1 0.8903 \n[CE][seed=2] Epoch 17/60 | train loss 0.3814 acc 0.8414 || val loss 0.2251 acc 0.8990 macroF1 0.9021 \n[CE][seed=2] Epoch 18/60 | train loss 0.4067 acc 0.8097 || val loss 0.2890 acc 0.9091 macroF1 0.9083 (saved)\n[CE][seed=2] Epoch 19/60 | train loss 0.4747 acc 0.7907 || val loss 0.2363 acc 0.8889 macroF1 0.8901 \n[CE][seed=2] Epoch 20/60 | train loss 0.3986 acc 0.8097 || val loss 0.2911 acc 0.8687 macroF1 0.8669 \n[CE][seed=2] Epoch 21/60 | train loss 0.4048 acc 0.8478 || val loss 0.3546 acc 0.8788 macroF1 0.8818 \n[CE][seed=2] Epoch 22/60 | train loss 0.4595 acc 0.8013 || val loss 0.2905 acc 0.8687 macroF1 0.8684 \n[CE][seed=2] Epoch 23/60 | train loss 0.4016 acc 0.8330 || val loss 0.2835 acc 0.8788 macroF1 0.8802 \n[CE][seed=2] Epoch 24/60 | train loss 0.3614 acc 0.8499 || val loss 0.2912 acc 0.8889 macroF1 0.8864 \n[CE][seed=2] Epoch 25/60 | train loss 0.3601 acc 0.8499 || val loss 0.2018 acc 0.8889 macroF1 0.8910 \n[CE][seed=2] Epoch 26/60 | train loss 0.3708 acc 0.8520 || val loss 0.2225 acc 0.8990 macroF1 0.9003 \n[CE][seed=2] Epoch 27/60 | train loss 0.3447 acc 0.8330 || val loss 0.3063 acc 0.8990 macroF1 0.9009 \n[CE][seed=2] Epoch 28/60 | train loss 0.3660 acc 0.8520 || val loss 0.1962 acc 0.9293 macroF1 0.9306 (saved)\n[CE][seed=2] Epoch 29/60 | train loss 0.3685 acc 0.8245 || val loss 0.2187 acc 0.8889 macroF1 0.8922 \n[CE][seed=2] Epoch 30/60 | train loss 0.3667 acc 0.8393 || val loss 0.2246 acc 0.8889 macroF1 0.8910 \n[CE][seed=2] Epoch 31/60 | train loss 0.3334 acc 0.8520 || val loss 0.2215 acc 0.9293 macroF1 0.9306 \n[CE][seed=2] Epoch 32/60 | train loss 0.3695 acc 0.8414 || val loss 0.2462 acc 0.8990 macroF1 0.8991 \n[CE][seed=2] Epoch 33/60 | train loss 0.3145 acc 0.8732 || val loss 0.2563 acc 0.9192 macroF1 0.9198 \n[CE][seed=2] Epoch 34/60 | train loss 0.3129 acc 0.8626 || val loss 0.3017 acc 0.8788 macroF1 0.8823 \n[CE][seed=2] Epoch 35/60 | train loss 0.3458 acc 0.8393 || val loss 0.2158 acc 0.9293 macroF1 0.9301 \n[CE][seed=2] Epoch 36/60 | train loss 0.3191 acc 0.8710 || val loss 0.1968 acc 0.9293 macroF1 0.9299 \n[CE][seed=2] Epoch 37/60 | train loss 0.3398 acc 0.8626 || val loss 0.2253 acc 0.9293 macroF1 0.9295 \n[CE][seed=2] Epoch 38/60 | train loss 0.3388 acc 0.8499 || val loss 0.2243 acc 0.9293 macroF1 0.9301 \n[CE][seed=2] Early stopping.\n[HYBRID][seed=0] Epoch 01/60 | train loss 1.1374 acc 0.5388 || val loss 0.9320 acc 0.6566 macroF1 0.6178 (saved)\n[HYBRID][seed=0] Epoch 02/60 | train loss 1.0331 acc 0.5829 || val loss 0.6954 acc 0.7374 macroF1 0.7142 (saved)\n[HYBRID][seed=0] Epoch 03/60 | train loss 0.9103 acc 0.6616 || val loss 0.6697 acc 0.7677 macroF1 0.7513 (saved)\n[HYBRID][seed=0] Epoch 04/60 | train loss 0.9250 acc 0.6615 || val loss 0.6044 acc 0.7273 macroF1 0.6913 \n[HYBRID][seed=0] Epoch 05/60 | train loss 0.9108 acc 0.7014 || val loss 0.5044 acc 0.8586 macroF1 0.8578 (saved)\n[HYBRID][seed=0] Epoch 06/60 | train loss 0.8079 acc 0.7248 || val loss 0.5610 acc 0.8687 macroF1 0.8702 (saved)\n[HYBRID][seed=0] Epoch 07/60 | train loss 0.7435 acc 0.7686 || val loss 0.3796 acc 0.8687 macroF1 0.8680 \n[HYBRID][seed=0] Epoch 08/60 | train loss 0.7542 acc 0.7480 || val loss 0.3471 acc 0.8889 macroF1 0.8902 (saved)\n[HYBRID][seed=0] Epoch 09/60 | train loss 0.8429 acc 0.7136 || val loss 0.3875 acc 0.8586 macroF1 0.8579 \n[HYBRID][seed=0] Epoch 10/60 | train loss 0.7712 acc 0.7605 || val loss 0.3625 acc 0.8788 macroF1 0.8799 \n[HYBRID][seed=0] Epoch 11/60 | train loss 0.7383 acc 0.7558 || val loss 0.3652 acc 0.8788 macroF1 0.8825 \n[HYBRID][seed=0] Epoch 12/60 | train loss 0.7617 acc 0.7643 || val loss 0.3224 acc 0.8687 macroF1 0.8666 \n[HYBRID][seed=0] Epoch 13/60 | train loss 0.6866 acc 0.7855 || val loss 0.3213 acc 0.8788 macroF1 0.8805 \n[HYBRID][seed=0] Epoch 14/60 | train loss 0.7094 acc 0.7776 || val loss 0.2845 acc 0.9091 macroF1 0.9111 (saved)\n[HYBRID][seed=0] Epoch 15/60 | train loss 0.6325 acc 0.8150 || val loss 0.3140 acc 0.8586 macroF1 0.8591 \n[HYBRID][seed=0] Epoch 16/60 | train loss 0.6210 acc 0.7912 || val loss 0.2493 acc 0.9192 macroF1 0.9203 (saved)\n[HYBRID][seed=0] Epoch 17/60 | train loss 0.6336 acc 0.8008 || val loss 0.3235 acc 0.8990 macroF1 0.9009 \n[HYBRID][seed=0] Epoch 18/60 | train loss 0.7118 acc 0.7786 || val loss 0.2616 acc 0.8990 macroF1 0.9005 \n[HYBRID][seed=0] Epoch 19/60 | train loss 0.6064 acc 0.8153 || val loss 0.2579 acc 0.8889 macroF1 0.8893 \n[HYBRID][seed=0] Epoch 20/60 | train loss 0.5834 acc 0.8278 || val loss 0.2764 acc 0.8990 macroF1 0.8985 \n[HYBRID][seed=0] Epoch 21/60 | train loss 0.6804 acc 0.8002 || val loss 0.2387 acc 0.8990 macroF1 0.9009 \n[HYBRID][seed=0] Epoch 22/60 | train loss 0.7256 acc 0.7764 || val loss 0.2340 acc 0.8990 macroF1 0.9005 \n[HYBRID][seed=0] Epoch 23/60 | train loss 0.7058 acc 0.7695 || val loss 0.2529 acc 0.8889 macroF1 0.8903 \n[HYBRID][seed=0] Epoch 24/60 | train loss 0.5602 acc 0.8363 || val loss 0.2609 acc 0.8990 macroF1 0.9008 \n[HYBRID][seed=0] Epoch 25/60 | train loss 0.5826 acc 0.8024 || val loss 0.2109 acc 0.9091 macroF1 0.9108 \n[HYBRID][seed=0] Epoch 26/60 | train loss 0.6684 acc 0.7752 || val loss 0.2300 acc 0.9091 macroF1 0.9108 \n[HYBRID][seed=0] Early stopping.\n[HYBRID][seed=1] Epoch 01/60 | train loss 1.2575 acc 0.4988 || val loss 1.0138 acc 0.6364 macroF1 0.5461 (saved)\n[HYBRID][seed=1] Epoch 02/60 | train loss 1.0461 acc 0.6310 || val loss 0.7314 acc 0.7980 macroF1 0.7857 (saved)\n[HYBRID][seed=1] Epoch 03/60 | train loss 0.9392 acc 0.6637 || val loss 0.6802 acc 0.7172 macroF1 0.6767 \n[HYBRID][seed=1] Epoch 04/60 | train loss 0.8841 acc 0.6818 || val loss 0.5154 acc 0.7778 macroF1 0.7586 \n[HYBRID][seed=1] Epoch 05/60 | train loss 0.8649 acc 0.6900 || val loss 0.4774 acc 0.8384 macroF1 0.8341 (saved)\n[HYBRID][seed=1] Epoch 06/60 | train loss 0.8261 acc 0.7213 || val loss 0.4917 acc 0.8283 macroF1 0.8252 \n[HYBRID][seed=1] Epoch 07/60 | train loss 0.8196 acc 0.7597 || val loss 0.4909 acc 0.8586 macroF1 0.8588 (saved)\n[HYBRID][seed=1] Epoch 08/60 | train loss 0.7276 acc 0.7778 || val loss 0.3295 acc 0.8889 macroF1 0.8898 (saved)\n[HYBRID][seed=1] Epoch 09/60 | train loss 0.7690 acc 0.7693 || val loss 0.3154 acc 0.8788 macroF1 0.8803 \n[HYBRID][seed=1] Epoch 10/60 | train loss 0.7177 acc 0.7702 || val loss 0.2959 acc 0.8990 macroF1 0.9022 (saved)\n[HYBRID][seed=1] Epoch 11/60 | train loss 0.7395 acc 0.7452 || val loss 0.3063 acc 0.8788 macroF1 0.8800 \n[HYBRID][seed=1] Epoch 12/60 | train loss 0.7839 acc 0.7362 || val loss 0.3087 acc 0.8788 macroF1 0.8803 \n[HYBRID][seed=1] Epoch 13/60 | train loss 0.6486 acc 0.7870 || val loss 0.5711 acc 0.8687 macroF1 0.8683 \n[HYBRID][seed=1] Epoch 14/60 | train loss 0.7201 acc 0.7443 || val loss 0.2738 acc 0.8889 macroF1 0.8910 \n[HYBRID][seed=1] Epoch 15/60 | train loss 0.7746 acc 0.7445 || val loss 0.4444 acc 0.8889 macroF1 0.8897 \n[HYBRID][seed=1] Epoch 16/60 | train loss 0.6634 acc 0.7923 || val loss 0.3096 acc 0.9091 macroF1 0.9098 (saved)\n[HYBRID][seed=1] Epoch 17/60 | train loss 0.6310 acc 0.8011 || val loss 0.3118 acc 0.8990 macroF1 0.9020 \n[HYBRID][seed=1] Epoch 18/60 | train loss 0.6940 acc 0.7926 || val loss 0.2886 acc 0.8687 macroF1 0.8702 \n[HYBRID][seed=1] Epoch 19/60 | train loss 0.6998 acc 0.7615 || val loss 0.2460 acc 0.8990 macroF1 0.9009 \n[HYBRID][seed=1] Epoch 20/60 | train loss 0.5534 acc 0.8365 || val loss 0.2282 acc 0.9495 macroF1 0.9509 (saved)\n[HYBRID][seed=1] Epoch 21/60 | train loss 0.6086 acc 0.8061 || val loss 0.3094 acc 0.8687 macroF1 0.8689 \n[HYBRID][seed=1] Epoch 22/60 | train loss 0.6082 acc 0.8053 || val loss 0.2270 acc 0.9192 macroF1 0.9210 \n[HYBRID][seed=1] Epoch 23/60 | train loss 0.5822 acc 0.8295 || val loss 0.2383 acc 0.9293 macroF1 0.9310 \n[HYBRID][seed=1] Epoch 24/60 | train loss 0.6010 acc 0.8179 || val loss 0.2331 acc 0.8990 macroF1 0.9021 \n[HYBRID][seed=1] Epoch 25/60 | train loss 0.6338 acc 0.8113 || val loss 0.2517 acc 0.8889 macroF1 0.8903 \n[HYBRID][seed=1] Epoch 26/60 | train loss 0.5655 acc 0.8413 || val loss 0.2315 acc 0.9091 macroF1 0.9106 \n[HYBRID][seed=1] Epoch 27/60 | train loss 0.5723 acc 0.8279 || val loss 0.2460 acc 0.8788 macroF1 0.8803 \n[HYBRID][seed=1] Epoch 28/60 | train loss 0.6614 acc 0.8005 || val loss 0.3026 acc 0.8990 macroF1 0.9005 \n[HYBRID][seed=1] Epoch 29/60 | train loss 0.5520 acc 0.8413 || val loss 0.2400 acc 0.9192 macroF1 0.9201 \n[HYBRID][seed=1] Epoch 30/60 | train loss 0.5772 acc 0.8076 || val loss 0.2175 acc 0.8990 macroF1 0.9003 \n[HYBRID][seed=1] Early stopping.\n[HYBRID][seed=2] Epoch 01/60 | train loss 1.1789 acc 0.5253 || val loss 1.1635 acc 0.6566 macroF1 0.5817 (saved)\n[HYBRID][seed=2] Epoch 02/60 | train loss 1.0408 acc 0.6233 || val loss 0.8242 acc 0.6869 macroF1 0.6329 (saved)\n[HYBRID][seed=2] Epoch 03/60 | train loss 0.8924 acc 0.6916 || val loss 0.5494 acc 0.7879 macroF1 0.7727 (saved)\n[HYBRID][seed=2] Epoch 04/60 | train loss 0.9468 acc 0.6645 || val loss 0.7142 acc 0.7475 macroF1 0.7201 \n[HYBRID][seed=2] Epoch 05/60 | train loss 0.8332 acc 0.7283 || val loss 0.4594 acc 0.8384 macroF1 0.8349 (saved)\n[HYBRID][seed=2] Epoch 06/60 | train loss 0.8866 acc 0.7103 || val loss 0.4260 acc 0.8485 macroF1 0.8507 (saved)\n[HYBRID][seed=2] Epoch 07/60 | train loss 0.8422 acc 0.6965 || val loss 0.3646 acc 0.8687 macroF1 0.8714 (saved)\n[HYBRID][seed=2] Epoch 08/60 | train loss 0.7407 acc 0.7795 || val loss 0.3181 acc 0.8889 macroF1 0.8909 (saved)\n[HYBRID][seed=2] Epoch 09/60 | train loss 0.7249 acc 0.7827 || val loss 0.3189 acc 0.9192 macroF1 0.9201 (saved)\n[HYBRID][seed=2] Epoch 10/60 | train loss 0.7455 acc 0.7628 || val loss 0.3395 acc 0.8687 macroF1 0.8710 \n[HYBRID][seed=2] Epoch 11/60 | train loss 0.6818 acc 0.7968 || val loss 0.2714 acc 0.8788 macroF1 0.8804 \n[HYBRID][seed=2] Epoch 12/60 | train loss 0.7334 acc 0.7611 || val loss 0.2716 acc 0.8990 macroF1 0.9019 \n[HYBRID][seed=2] Epoch 13/60 | train loss 0.6654 acc 0.8000 || val loss 0.3199 acc 0.8687 macroF1 0.8697 \n[HYBRID][seed=2] Epoch 14/60 | train loss 0.6527 acc 0.7877 || val loss 0.2742 acc 0.8788 macroF1 0.8806 \n[HYBRID][seed=2] Epoch 15/60 | train loss 0.6760 acc 0.7694 || val loss 0.3039 acc 0.8586 macroF1 0.8596 \n[HYBRID][seed=2] Epoch 16/60 | train loss 0.6497 acc 0.7858 || val loss 0.2913 acc 0.8788 macroF1 0.8800 \n[HYBRID][seed=2] Epoch 17/60 | train loss 0.6747 acc 0.7913 || val loss 0.2586 acc 0.9091 macroF1 0.9116 \n[HYBRID][seed=2] Epoch 18/60 | train loss 0.6144 acc 0.8168 || val loss 0.2638 acc 0.8889 macroF1 0.8906 \n[HYBRID][seed=2] Epoch 19/60 | train loss 0.6732 acc 0.7986 || val loss 0.2135 acc 0.9293 macroF1 0.9313 (saved)\n[HYBRID][seed=2] Epoch 20/60 | train loss 0.6552 acc 0.7702 || val loss 0.2891 acc 0.8788 macroF1 0.8799 \n[HYBRID][seed=2] Epoch 21/60 | train loss 0.5979 acc 0.8049 || val loss 0.2680 acc 0.9394 macroF1 0.9406 (saved)\n[HYBRID][seed=2] Epoch 22/60 | train loss 0.5888 acc 0.8247 || val loss 0.2614 acc 0.8990 macroF1 0.9013 \n[HYBRID][seed=2] Epoch 23/60 | train loss 0.6579 acc 0.7881 || val loss 0.2064 acc 0.9293 macroF1 0.9303 \n[HYBRID][seed=2] Epoch 24/60 | train loss 0.6389 acc 0.8129 || val loss 0.2189 acc 0.9192 macroF1 0.9201 \n[HYBRID][seed=2] Epoch 25/60 | train loss 0.5635 acc 0.8322 || val loss 0.2525 acc 0.9192 macroF1 0.9207 \n[HYBRID][seed=2] Epoch 26/60 | train loss 0.6209 acc 0.8139 || val loss 0.1930 acc 0.9495 macroF1 0.9504 (saved)\n[HYBRID][seed=2] Epoch 27/60 | train loss 0.5715 acc 0.8086 || val loss 0.2304 acc 0.9091 macroF1 0.9106 \n[HYBRID][seed=2] Epoch 28/60 | train loss 0.5721 acc 0.8487 || val loss 0.2563 acc 0.8687 macroF1 0.8703 \n[HYBRID][seed=2] Epoch 29/60 | train loss 0.5794 acc 0.8237 || val loss 0.2542 acc 0.9192 macroF1 0.9206 \n[HYBRID][seed=2] Epoch 30/60 | train loss 0.5536 acc 0.8282 || val loss 0.2274 acc 0.8990 macroF1 0.9009 \n[HYBRID][seed=2] Epoch 31/60 | train loss 0.6257 acc 0.8150 || val loss 0.2647 acc 0.8990 macroF1 0.9013 \n[HYBRID][seed=2] Epoch 32/60 | train loss 0.5168 acc 0.8579 || val loss 0.2129 acc 0.9293 macroF1 0.9309 \n[HYBRID][seed=2] Epoch 33/60 | train loss 0.6284 acc 0.8004 || val loss 0.2251 acc 0.8990 macroF1 0.9005 \n[HYBRID][seed=2] Epoch 34/60 | train loss 0.5511 acc 0.8519 || val loss 0.2297 acc 0.8788 macroF1 0.8791 \n[HYBRID][seed=2] Epoch 35/60 | train loss 0.5435 acc 0.8346 || val loss 0.2105 acc 0.8889 macroF1 0.8902 \n[HYBRID][seed=2] Epoch 36/60 | train loss 0.5964 acc 0.8329 || val loss 0.2202 acc 0.8990 macroF1 0.8972 \n[HYBRID][seed=2] Early stopping.\n\n================ SUMMARY (mean ± std over seeds) ================\n\nMODE: CE\nTest Acc (%): 91.92 ± 5.34\nTTA  Acc (%): 91.92 ± 5.34\nMacro ROC-AUC (single): 0.9921 ± 0.0071\nMacro ROC-AUC (TTA):    0.9921 ± 0.0071\n# Params (M): 24.56 ± 0.00\n\nMODE: HYBRID\nTest Acc (%): 94.61 ± 1.54\nTTA  Acc (%): 94.61 ± 1.54\nMacro ROC-AUC (single): 0.9850 ± 0.0026\nMacro ROC-AUC (TTA):    0.9850 ± 0.0026\n# Params (M): 24.82 ± 0.00\n\nSaved per-seed metrics: results_3seeds.json\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# --- Single cell: generate Confusion Matrix + ROC (CE & HYBRID) from saved checkpoints ---\n\nimport os, json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# -----------------------------\n# USER SETTINGS (edit if needed)\n# -----------------------------\nDATA_ROOT = \"/kaggle/input/minida/mini_output1\"   # has train/val/test folders\nRESULTS_JSON = \"/kaggle/working/results_3seeds.json\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBATCH_SIZE = 64\nNUM_WORKERS = 2\n\n# Where to save figures\nOUT_DIR = \"/kaggle/working\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# -----------------------------\n# Model definition (must match finetune_eval.py)\n# -----------------------------\nclass FineTuneModel(nn.Module):\n    def __init__(self, num_classes: int, hybrid: bool):\n        super().__init__()\n        try:\n            resnet = models.resnet50(weights=None)\n        except TypeError:\n            resnet = models.resnet50(pretrained=False)\n\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n        self.classifier = nn.Sequential(\n            nn.Linear(2048, 512, bias=True),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.30),\n            nn.Linear(512, num_classes, bias=True),\n        )\n\n        self.hybrid = bool(hybrid)\n        self.supcon_proj = nn.Linear(2048, 128, bias=True) if self.hybrid else None\n\n    def forward(self, x):\n        feats = self.backbone(x).flatten(1)\n        return self.classifier(feats)\n\n# -----------------------------\n# Data\n# -----------------------------\neval_tf = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n])\n\ntest_dir = os.path.join(DATA_ROOT, \"test\")\ntest_ds = ImageFolder(test_dir, transform=eval_tf)\nclass_names = test_ds.classes\nn_classes = len(class_names)\n\ntest_loader = DataLoader(\n    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available(),\n    persistent_workers=True if NUM_WORKERS > 0 else False\n)\n\n# -----------------------------\n# Helper: pick best checkpoint per mode from results_3seeds.json\n# -----------------------------\nwith open(RESULTS_JSON, \"r\") as f:\n    R = json.load(f)\n\ndef pick_best(mode: str):\n    candidates = [x for x in R[\"per_seed\"] if x[\"mode\"].upper() == mode.upper()]\n    if len(candidates) == 0:\n        raise RuntimeError(f\"No entries found for mode={mode} in {RESULTS_JSON}\")\n    # best is highest best_val_acc; tie-breaker: higher test_acc\n    candidates.sort(key=lambda x: (x.get(\"best_val_acc\", -1), x.get(\"test_acc\", -1)), reverse=True)\n    return candidates[0]\n\nbest_ce = pick_best(\"CE\")\nbest_hy = pick_best(\"HYBRID\")\n\nprint(\"Picked CE checkpoint:\", best_ce[\"checkpoint_path\"], \"| seed:\", best_ce[\"seed\"], \"| best_val_acc:\", best_ce[\"best_val_acc\"])\nprint(\"Picked HYBRID checkpoint:\", best_hy[\"checkpoint_path\"], \"| seed:\", best_hy[\"seed\"], \"| best_val_acc:\", best_hy[\"best_val_acc\"])\n\n# -----------------------------\n# Inference: get y_true, probs, preds\n# -----------------------------\n@torch.no_grad()\ndef infer(checkpoint_path: str, hybrid: bool):\n    model = FineTuneModel(num_classes=n_classes, hybrid=hybrid).to(DEVICE)\n    sd = torch.load(checkpoint_path, map_location=DEVICE)\n    model.load_state_dict(sd, strict=True)\n    model.eval()\n\n    y_true = []\n    probs = []\n    preds = []\n\n    for x, y in test_loader:\n        x = x.to(DEVICE)\n        logits = model(x)\n        pr = F.softmax(logits, dim=1).cpu().numpy()\n        pd = np.argmax(pr, axis=1)\n\n        probs.append(pr)\n        preds.append(pd)\n        y_true.append(y.numpy())\n\n    y_true = np.concatenate(y_true)\n    probs = np.concatenate(probs)\n    preds = np.concatenate(preds)\n    return y_true, probs, preds\n\n# -----------------------------\n# Plot: Confusion Matrix (looks like your example)\n# -----------------------------\ndef plot_confusion(y_true, y_pred, title, out_path):\n    cm = confusion_matrix(y_true, y_pred)\n    fig = plt.figure(figsize=(6.2, 5.4))\n    ax = fig.add_subplot(111)\n    im = ax.imshow(cm, interpolation=\"nearest\")\n    fig.colorbar(im)\n\n    ax.set_title(title)\n    ax.set_xlabel(\"Predicted label\")\n    ax.set_ylabel(\"True label\")\n    ax.set_xticks(np.arange(n_classes))\n    ax.set_yticks(np.arange(n_classes))\n    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n    ax.set_yticklabels(class_names)\n\n    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(\n                j, i, format(cm[i, j], \"d\"),\n                ha=\"center\", va=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\",\n                fontsize=11\n            )\n\n    fig.tight_layout()\n    fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n    plt.close(fig)\n    print(\"Saved:\", out_path)\n\n# -----------------------------\n# Plot: ROC curves (per-class + micro + macro)\n# -----------------------------\ndef plot_roc(y_true, probs, title, out_path):\n    # Binarize labels\n    y_bin = label_binarize(y_true, classes=list(range(n_classes)))  # (N,C)\n\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    # per-class\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # micro-average\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_bin.ravel(), probs.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n    # macro-average\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n    mean_tpr /= n_classes\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n    fig = plt.figure(figsize=(6.2, 5.4))\n    ax = fig.add_subplot(111)\n\n    # Plot micro/macro first (thicker)\n    ax.plot(fpr[\"micro\"], tpr[\"micro\"], linewidth=2.5, label=f\"micro-average (AUC = {roc_auc['micro']:.4f})\")\n    ax.plot(fpr[\"macro\"], tpr[\"macro\"], linewidth=2.5, label=f\"macro-average (AUC = {roc_auc['macro']:.4f})\")\n\n    # Plot each class\n    for i, name in enumerate(class_names):\n        ax.plot(fpr[i], tpr[i], linewidth=1.8, label=f\"{name} (AUC = {roc_auc[i]:.4f})\")\n\n    # diagonal baseline\n    ax.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1.5)\n\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive Rate\")\n    ax.set_title(title)\n    ax.legend(loc=\"lower right\", fontsize=9)\n    fig.tight_layout()\n    fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n    plt.close(fig)\n    print(\"Saved:\", out_path)\n\n# -----------------------------\n# Generate for CE\n# -----------------------------\ny_ce, pr_ce, pd_ce = infer(best_ce[\"checkpoint_path\"], hybrid=False)\nplot_confusion(y_ce, pd_ce, \"Confusion Matrix (SimSiam-ResNet-50, CE)\", os.path.join(OUT_DIR, \"SSVC_v2_CE.png\"))\nplot_roc(y_ce, pr_ce, \"ROC Curve (SimSiam-ResNet-50, CE)\", os.path.join(OUT_DIR, \"SSVR_v2_CE.png\"))\n\n# -----------------------------\n# Generate for HYBRID\n# -----------------------------\ny_hy, pr_hy, pd_hy = infer(best_hy[\"checkpoint_path\"], hybrid=True)\nplot_confusion(y_hy, pd_hy, \"Confusion Matrix (SimSiam-ResNet-50, Hybrid)\", os.path.join(OUT_DIR, \"SSVC_v2_HYBRID.png\"))\nplot_roc(y_hy, pr_hy, \"ROC Curve (SimSiam-ResNet-50, Hybrid)\", os.path.join(OUT_DIR, \"SSVR_v2_HYBRID.png\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T00:29:14.885733Z","iopub.execute_input":"2025-12-06T00:29:14.886393Z","iopub.status.idle":"2025-12-06T00:29:37.269924Z","shell.execute_reply.started":"2025-12-06T00:29:14.886362Z","shell.execute_reply":"2025-12-06T00:29:37.269021Z"}},"outputs":[{"name":"stdout","text":"Picked CE checkpoint: ./runs_reviewproof/best_ce_seed2.pth | seed: 2 | best_val_acc: 0.9292929292929293\nPicked HYBRID checkpoint: ./runs_reviewproof/best_hybrid_seed2.pth | seed: 2 | best_val_acc: 0.9494949494949495\nSaved: /kaggle/working/SSVC_v2_CE.png\nSaved: /kaggle/working/SSVR_v2_CE.png\nSaved: /kaggle/working/SSVC_v2_HYBRID.png\nSaved: /kaggle/working/SSVR_v2_HYBRID.png\n","output_type":"stream"}],"execution_count":9}]}