{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T22:01:47.511517Z",
     "iopub.status.busy": "2025-08-27T22:01:47.511227Z",
     "iopub.status.idle": "2025-08-27T22:03:07.838858Z",
     "shell.execute_reply": "2025-08-27T22:03:07.838147Z",
     "shell.execute_reply.started": "2025-08-27T22:01:47.511491Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grad-cam\n",
      "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from grad-cam) (11.2.1)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.21.0+cu124)\n",
      "Collecting ttach (from grad-cam)\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.67.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from grad-cam) (3.7.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.1->grad-cam)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (25.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->grad-cam) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->grad-cam) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->grad-cam) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->grad-cam) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->grad-cam) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->grad-cam) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: grad-cam\n",
      "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=3a0f787a2956c024f285506704a12131c4e75fd0645753f3d0c6ba8e7492cd13\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/52/78/893c3b94279ef238f43a9e89608af648de401b96415bebbd1f\n",
      "Successfully built grad-cam\n",
      "Installing collected packages: ttach, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, grad-cam\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed grad-cam-1.5.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ttach-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimSiam ResNet PreTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-28T02:08:52.491043Z",
     "iopub.status.busy": "2025-08-28T02:08:52.490703Z",
     "iopub.status.idle": "2025-08-28T02:08:52.498105Z",
     "shell.execute_reply": "2025-08-28T02:08:52.497414Z",
     "shell.execute_reply.started": "2025-08-28T02:08:52.491006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simsiam_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simsiam_model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import torchvision.models as tv_models\n",
    "\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    \"\"\"\n",
    "    SimSiam projection MLP:\n",
    "      Linear -> BN -> ReLU -> Linear -> BN(affine=False)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int = 2048, hidden_dim: int = 2048, out_dim: int = 2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim, bias=False),\n",
    "            nn.BatchNorm1d(out_dim, affine=False),  # per SimSiam\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    SimSiam prediction MLP:\n",
    "      Linear -> BN -> ReLU -> Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int = 2048, hidden_dim: int = 512, out_dim: int = 2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim),  # bias=True default is fine\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def _build_resnet50_backbone() -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    Create a ResNet-50 backbone up to the global avgpool (drops the FC).\n",
    "    Handles torchvision API differences around 'weights' vs 'pretrained'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # torchvision >= 0.13\n",
    "        resnet = tv_models.resnet50(weights=None)\n",
    "    except TypeError:\n",
    "        # older torchvision\n",
    "        resnet = tv_models.resnet50(pretrained=False)\n",
    "    backbone = nn.Sequential(*list(resnet.children())[:-1])  # up to avgpool\n",
    "    return backbone\n",
    "\n",
    "\n",
    "class SimSiam(nn.Module):\n",
    "    \"\"\"\n",
    "    SimSiam with a ResNet-50 backbone, projection head, and prediction head.\n",
    "\n",
    "    Args:\n",
    "        fix_backbone_bn: If True, keep backbone BatchNorm layers in eval mode\n",
    "                         and freeze their params; helpful for small batches.\n",
    "    \"\"\"\n",
    "    def __init__(self, fix_backbone_bn: bool = True):\n",
    "        super().__init__()\n",
    "        self.backbone = _build_resnet50_backbone()\n",
    "        self.projector = MLPHead(2048)\n",
    "        self.predictor = PredictionHead()\n",
    "        self.fix_backbone_bn = fix_backbone_bn\n",
    "\n",
    "        if self.fix_backbone_bn:\n",
    "            # Freeze BN params and set them to eval once.\n",
    "            for m in self.backbone.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "                    m.requires_grad_(False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _forward_backbone(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)                # (N, 2048, 1, 1)\n",
    "        x = torch.flatten(x, 1)             # (N, 2048)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            p1, p2: predictions (gradients flow through)\n",
    "            z1, z2: stop-grad targets (detached)\n",
    "        \"\"\"\n",
    "        z1 = self.projector(self._forward_backbone(x1))\n",
    "        z2 = self.projector(self._forward_backbone(x2))\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        \"\"\"\n",
    "        Override to keep backbone BN layers in eval mode when requested.\n",
    "        \"\"\"\n",
    "        super().train(mode)\n",
    "        if self.fix_backbone_bn:\n",
    "            for m in self.backbone.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"SimSiam(backbone=ResNet50, \"\n",
    "            f\"projector={self.projector}, predictor={self.predictor}, \"\n",
    "            f\"fix_backbone_bn={self.fix_backbone_bn})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T02:08:58.564665Z",
     "iopub.status.busy": "2025-08-28T02:08:58.564403Z",
     "iopub.status.idle": "2025-08-28T02:08:58.571868Z",
     "shell.execute_reply": "2025-08-28T02:08:58.571044Z",
     "shell.execute_reply.started": "2025-08-28T02:08:58.564645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simsiam_pretrain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simsiam_pretrain.py\n",
    "import os\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "\n",
    "from simsiam_model import SimSiam\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def seed_all(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    import random, numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset\n",
    "# ----------------------------\n",
    "class UnlabeledDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Recursively loads images from a root directory and returns two augmented views.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir: str, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        exts = ('.png', '.jpg', '.jpeg', '.bmp', '.webp')\n",
    "        filepaths = []\n",
    "        for dp, _, fns in os.walk(root_dir):\n",
    "            for fn in fns:\n",
    "                if fn.lower().endswith(exts):\n",
    "                    filepaths.append(os.path.join(dp, fn))\n",
    "        self.filepaths = sorted(filepaths)\n",
    "        if len(self.filepaths) == 0:\n",
    "            raise RuntimeError(f\"No images found in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img = Image.open(self.filepaths[idx]).convert('RGB')\n",
    "        if self.transform is None:\n",
    "            raise RuntimeError(\"Transform must be provided for SimSiam pretraining.\")\n",
    "        v1 = self.transform(img)\n",
    "        v2 = self.transform(img)\n",
    "        return v1, v2\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Loss\n",
    "# ----------------------------\n",
    "def negative_cosine_similarity(p: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    SimSiam loss: -cosine(p, z.detach())\n",
    "    \"\"\"\n",
    "    p = F.normalize(p, dim=1)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    return -(p * z).sum(dim=1).mean()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Training\n",
    "# ----------------------------\n",
    "def pretrain(\n",
    "    root_path: str = \"/kaggle/input/minida/mini_output1/pretrain\",\n",
    "    checkpoint_dir: str = \"/kaggle/working/simsiam_vanilla_resnet\",\n",
    "    epochs: int = 150,\n",
    "    batch_size: int = 64,\n",
    "    fix_backbone_bn: bool = True,   # flip to False to let BN use batch stats\n",
    "    num_workers: int = 2,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"logs\"))\n",
    "\n",
    "    # SimSiam-style augmentations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),  # odd kernel; 23 works well for 224 crops\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset = UnlabeledDataset(root_dir=root_path, transform=train_transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=True if num_workers > 0 else False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    model = SimSiam(fix_backbone_bn=fix_backbone_bn).to(device)\n",
    "\n",
    "    # Linear LR scaling with batch size (ImageNet folklore; works fine here)\n",
    "    base_lr = 0.05 * batch_size / 256\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    # AMP for faster training on GPU\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"simsiam_checkpoint.pth\")\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(\"Resuming from checkpoint...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.backbone.load_state_dict(checkpoint['backbone'])\n",
    "        model.projector.load_state_dict(checkpoint['projector'])\n",
    "        model.predictor.load_state_dict(checkpoint['predictor'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        if 'scaler' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resumed at epoch {start_epoch}\")\n",
    "\n",
    "    print(f\"Starting SimSiam pretraining for {epochs} epochs (from epoch {start_epoch})...\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, (x1, x2) in enumerate(dataloader):\n",
    "            x1 = x1.to(device, non_blocking=True)\n",
    "            x2 = x2.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                p1, p2, z1, z2 = model(x1, x2)\n",
    "                loss = 0.5 * (\n",
    "                    negative_cosine_similarity(p1, z2) +\n",
    "                    negative_cosine_similarity(p2, z1)\n",
    "                )\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # periodic checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'backbone': model.backbone.state_dict(),\n",
    "                'projector': model.projector.state_dict(),\n",
    "                'predictor': model.predictor.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'scaler': scaler.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "    # final weights for downstream use (no optimizer/scheduler)\n",
    "    final_path = os.path.join(checkpoint_dir, \"simsiam_pretrained.pth\")\n",
    "    torch.save({\n",
    "        'backbone': model.backbone.state_dict(),\n",
    "        'projector': model.projector.state_dict(),\n",
    "        'predictor': model.predictor.state_dict(),\n",
    "    }, final_path)\n",
    "    writer.close()\n",
    "    print(\"Pretraining complete! Model saved to\", final_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T02:11:09.822164Z",
     "iopub.status.busy": "2025-08-28T02:11:09.821768Z",
     "iopub.status.idle": "2025-08-28T03:29:15.720066Z",
     "shell.execute_reply": "2025-08-28T03:29:15.719323Z",
     "shell.execute_reply.started": "2025-08-28T02:11:09.822137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-28 02:11:13.291002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756347073.311885    1906 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756347073.318152    1906 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using device: cuda\n",
      "/kaggle/working/simsiam_pretrain.py:120: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "Resuming from checkpoint...\n",
      "Resumed at epoch 100\n",
      "Starting SimSiam pretraining for 150 epochs (from epoch 100)...\n",
      "/kaggle/working/simsiam_pretrain.py:149: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "Epoch [101/150] Batch [0] Loss: -0.2153\n",
      "Epoch [101/150] Average Loss: -0.2193\n",
      "Epoch [102/150] Batch [0] Loss: -0.2458\n",
      "Epoch [102/150] Average Loss: -0.2179\n",
      "Epoch [103/150] Batch [0] Loss: -0.2423\n",
      "Epoch [103/150] Average Loss: -0.2272\n",
      "Epoch [104/150] Batch [0] Loss: -0.2021\n",
      "Epoch [104/150] Average Loss: -0.2261\n",
      "Epoch [105/150] Batch [0] Loss: -0.2459\n",
      "Epoch [105/150] Average Loss: -0.2113\n",
      "Epoch [106/150] Batch [0] Loss: -0.1418\n",
      "Epoch [106/150] Average Loss: -0.2141\n",
      "Epoch [107/150] Batch [0] Loss: -0.1967\n",
      "Epoch [107/150] Average Loss: -0.2285\n",
      "Epoch [108/150] Batch [0] Loss: -0.2140\n",
      "Epoch [108/150] Average Loss: -0.2357\n",
      "Epoch [109/150] Batch [0] Loss: -0.1930\n",
      "Epoch [109/150] Average Loss: -0.2440\n",
      "Epoch [110/150] Batch [0] Loss: -0.2097\n",
      "Epoch [110/150] Average Loss: -0.2288\n",
      "Epoch [111/150] Batch [0] Loss: -0.2842\n",
      "Epoch [111/150] Average Loss: -0.2260\n",
      "Epoch [112/150] Batch [0] Loss: -0.2480\n",
      "Epoch [112/150] Average Loss: -0.2164\n",
      "Epoch [113/150] Batch [0] Loss: -0.2913\n",
      "Epoch [113/150] Average Loss: -0.2598\n",
      "Epoch [114/150] Batch [0] Loss: -0.1541\n",
      "Epoch [114/150] Average Loss: -0.2002\n",
      "Epoch [115/150] Batch [0] Loss: -0.2317\n",
      "Epoch [115/150] Average Loss: -0.2416\n",
      "Epoch [116/150] Batch [0] Loss: -0.2360\n",
      "Epoch [116/150] Average Loss: -0.2246\n",
      "Epoch [117/150] Batch [0] Loss: -0.2603\n",
      "Epoch [117/150] Average Loss: -0.2406\n",
      "Epoch [118/150] Batch [0] Loss: -0.2400\n",
      "Epoch [118/150] Average Loss: -0.2320\n",
      "Epoch [119/150] Batch [0] Loss: -0.2278\n",
      "Epoch [119/150] Average Loss: -0.2312\n",
      "Epoch [120/150] Batch [0] Loss: -0.1577\n",
      "Epoch [120/150] Average Loss: -0.2216\n",
      "Epoch [121/150] Batch [0] Loss: -0.2754\n",
      "Epoch [121/150] Average Loss: -0.2377\n",
      "Epoch [122/150] Batch [0] Loss: -0.2328\n",
      "Epoch [122/150] Average Loss: -0.2463\n",
      "Epoch [123/150] Batch [0] Loss: -0.2152\n",
      "Epoch [123/150] Average Loss: -0.2363\n",
      "Epoch [124/150] Batch [0] Loss: -0.1762\n",
      "Epoch [124/150] Average Loss: -0.2468\n",
      "Epoch [125/150] Batch [0] Loss: -0.1473\n",
      "Epoch [125/150] Average Loss: -0.2315\n",
      "Epoch [126/150] Batch [0] Loss: -0.1725\n",
      "Epoch [126/150] Average Loss: -0.2181\n",
      "Epoch [127/150] Batch [0] Loss: -0.2306\n",
      "Epoch [127/150] Average Loss: -0.2330\n",
      "Epoch [128/150] Batch [0] Loss: -0.2166\n",
      "Epoch [128/150] Average Loss: -0.2208\n",
      "Epoch [129/150] Batch [0] Loss: -0.2925\n",
      "Epoch [129/150] Average Loss: -0.2246\n",
      "Epoch [130/150] Batch [0] Loss: -0.2402\n",
      "Epoch [130/150] Average Loss: -0.2212\n",
      "Epoch [131/150] Batch [0] Loss: -0.2721\n",
      "Epoch [131/150] Average Loss: -0.2201\n",
      "Epoch [132/150] Batch [0] Loss: -0.2166\n",
      "Epoch [132/150] Average Loss: -0.2294\n",
      "Epoch [133/150] Batch [0] Loss: -0.2443\n",
      "Epoch [133/150] Average Loss: -0.2459\n",
      "Epoch [134/150] Batch [0] Loss: -0.2257\n",
      "Epoch [134/150] Average Loss: -0.2331\n",
      "Epoch [135/150] Batch [0] Loss: -0.2486\n",
      "Epoch [135/150] Average Loss: -0.2276\n",
      "Epoch [136/150] Batch [0] Loss: -0.2444\n",
      "Epoch [136/150] Average Loss: -0.2241\n",
      "Epoch [137/150] Batch [0] Loss: -0.2281\n",
      "Epoch [137/150] Average Loss: -0.2154\n",
      "Epoch [138/150] Batch [0] Loss: -0.1812\n",
      "Epoch [138/150] Average Loss: -0.2239\n",
      "Epoch [139/150] Batch [0] Loss: -0.2135\n",
      "Epoch [139/150] Average Loss: -0.2214\n",
      "Epoch [140/150] Batch [0] Loss: -0.1384\n",
      "Epoch [140/150] Average Loss: -0.2309\n",
      "Epoch [141/150] Batch [0] Loss: -0.2175\n",
      "Epoch [141/150] Average Loss: -0.2175\n",
      "Epoch [142/150] Batch [0] Loss: -0.2818\n",
      "Epoch [142/150] Average Loss: -0.2490\n",
      "Epoch [143/150] Batch [0] Loss: -0.2790\n",
      "Epoch [143/150] Average Loss: -0.2362\n",
      "Epoch [144/150] Batch [0] Loss: -0.2146\n",
      "Epoch [144/150] Average Loss: -0.2258\n",
      "Epoch [145/150] Batch [0] Loss: -0.2457\n",
      "Epoch [145/150] Average Loss: -0.2264\n",
      "Epoch [146/150] Batch [0] Loss: -0.2286\n",
      "Epoch [146/150] Average Loss: -0.2146\n",
      "Epoch [147/150] Batch [0] Loss: -0.2309\n",
      "Epoch [147/150] Average Loss: -0.2486\n",
      "Epoch [148/150] Batch [0] Loss: -0.2881\n",
      "Epoch [148/150] Average Loss: -0.2200\n",
      "Epoch [149/150] Batch [0] Loss: -0.2711\n",
      "Epoch [149/150] Average Loss: -0.2308\n",
      "Epoch [150/150] Batch [0] Loss: -0.2273\n",
      "Epoch [150/150] Average Loss: -0.2291\n",
      "Pretraining complete! Model saved to /kaggle/working/simsiam_vanilla_resnet/simsiam_pretrained.pth\n"
     ]
    }
   ],
   "source": [
    "!python simsiam_pretrain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FineTune SimSiam Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T03:31:34.175931Z",
     "iopub.status.busy": "2025-08-28T03:31:34.175670Z",
     "iopub.status.idle": "2025-08-28T03:31:34.188097Z",
     "shell.execute_reply": "2025-08-28T03:31:34.187493Z",
     "shell.execute_reply.started": "2025-08-28T03:31:34.175907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting finetune_simsiam.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile finetune_simsiam.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def seed_all(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Mixup helpers\n",
    "# ----------------------------\n",
    "def mixup_data(x: torch.Tensor, y: torch.Tensor, alpha: float = 0.4, device=None):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=device)\n",
    "    mixed_x = lam * x + (1.0 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam: float):\n",
    "    return lam * criterion(pred, y_a) + (1.0 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataloaders\n",
    "# ----------------------------\n",
    "def get_loaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str,\n",
    "    test_dir: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 2,\n",
    "):\n",
    "    pin = torch.cuda.is_available()\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    eval_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, transform=train_transform)\n",
    "    val_ds   = ImageFolder(val_dir,   transform=eval_transform)\n",
    "    test_ds  = ImageFolder(test_dir,  transform=eval_transform)\n",
    "\n",
    "    # Derive class names from the data to avoid ordering surprises\n",
    "    class_names = train_ds.classes\n",
    "\n",
    "    # Balanced sampling\n",
    "    targets_np = np.array(train_ds.targets)\n",
    "    classes = np.unique(targets_np)\n",
    "    class_sample_count = np.array([(targets_np == t).sum() for t in classes], dtype=np.float64)\n",
    "    # Avoid division by zero in pathological cases\n",
    "    class_sample_count[class_sample_count == 0] = 1.0\n",
    "    weights = 1.0 / class_sample_count\n",
    "    samples_weights = weights[targets_np.astype(int)]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.as_tensor(samples_weights, dtype=torch.double),\n",
    "        num_samples=len(samples_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, sampler=sampler,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader, class_names\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model definition\n",
    "# ----------------------------\n",
    "class FineTuneModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Load a ResNet-50 backbone and initialize a small classifier head.\n",
    "    backbone weights come from SimSiam pretraining ('backbone' key).\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_path: str, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])  # up to avgpool\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        # Load SimSiam backbone weights (robust to minor key diffs)\n",
    "        ckpt = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        missing, unexpected = self.backbone.load_state_dict(ckpt.get(\"backbone\", ckpt), strict=False)\n",
    "        if missing or unexpected:\n",
    "            print(f\"[state_dict notice] missing: {missing} | unexpected: {unexpected}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval\n",
    "# ----------------------------\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    scaler: torch.cuda.amp.GradScaler,\n",
    "    use_mixup: bool = True,\n",
    "    mixup_alpha: float = 0.4\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "            if use_mixup:\n",
    "                imgs, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha, device=device)\n",
    "                outputs = model(imgs)\n",
    "                loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                preds = outputs.argmax(1)\n",
    "                correct_batch = (lam * preds.eq(y_a).sum().item() +\n",
    "                                 (1.0 - lam) * preds.eq(y_b).sum().item())\n",
    "            else:\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = outputs.argmax(1)\n",
    "                correct_batch = preds.eq(labels).sum().item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct += int(correct_batch)\n",
    "\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    all_labels: List[int] = []\n",
    "    all_preds:  List[int] = []\n",
    "    all_probs:  List[np.ndarray] = []\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return (total_loss / len(loader.dataset),\n",
    "            correct / len(loader.dataset),\n",
    "            np.array(all_labels),\n",
    "            np.array(all_preds),\n",
    "            np.array(all_probs))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Early stopping\n",
    "# ----------------------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int = 7, verbose: bool = False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_acc: float, model: nn.Module, path: str):\n",
    "        if self.best_acc is None or val_acc > self.best_acc:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(\"Validation accuracy improved, saving model.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Reliability diagram\n",
    "# ----------------------------\n",
    "def plot_reliability(y_true: np.ndarray, y_prob: np.ndarray, class_names: List[str], n_bins: int = 10):\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i, name in enumerate(class_names):\n",
    "        prob_true, prob_pred = calibration_curve((y_true == i).astype(int), y_prob[:, i],\n",
    "                                                 n_bins=n_bins, strategy='uniform')\n",
    "        plt.plot(prob_pred, prob_true, marker='o', label=f\"{name}\")\n",
    "    plt.plot([0, 1], [0, 1], '--')\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Reliability Diagram\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main(\n",
    "    data_root: str = \"/kaggle/input/minida/mini_output1\",\n",
    "    pretrained_path: str = \"/kaggle/working/simsiam_vanilla_resnet/simsiam_pretrained.pth\",\n",
    "    epochs: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 2,\n",
    "    mixup_alpha: float = 0.4,\n",
    "    patience: int = 7\n",
    "):\n",
    "    seed_all(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_dir = os.path.join(data_root, \"train\")\n",
    "    val_dir   = os.path.join(data_root, \"val\")\n",
    "    test_dir  = os.path.join(data_root, \"test\")\n",
    "    if not os.path.exists(pretrained_path):\n",
    "        raise FileNotFoundError(f\"Pretrained weights not found at {pretrained_path}\")\n",
    "\n",
    "    train_loader, val_loader, test_loader, class_names = get_loaders(\n",
    "        train_dir, val_dir, test_dir, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # Build model\n",
    "    model = FineTuneModel(pretrained_path, num_classes=len(class_names)).to(device)\n",
    "\n",
    "    # Ensure BN uses batch stats during supervised finetune\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.train()\n",
    "            m.requires_grad_(True)\n",
    "\n",
    "    # Parameter groups: smaller LR for backbone\n",
    "    backbone_params, classifier_params = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        (classifier_params if \"classifier\" in n else backbone_params).append(p)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": 3e-5},\n",
    "            {\"params\": classifier_params, \"lr\": 1e-4},\n",
    "        ],\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "    early_stopper = EarlyStopping(patience=patience, verbose=True)\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, scaler,\n",
    "            use_mixup=True, mixup_alpha=mixup_alpha\n",
    "        )\n",
    "        val_loss, val_acc, _, _, _ = eval_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        early_stopper(val_acc, model, best_model_path)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # Final test eval\n",
    "    print(\"\\nTest set results:\")\n",
    "    test_loss, test_acc, test_labels, test_preds, test_probs = eval_epoch(model, test_loader, criterion, device)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=class_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "    # ROC-AUC (macro)\n",
    "    try:\n",
    "        test_labels_onehot = np.eye(len(class_names))[test_labels]\n",
    "        roc_macro = roc_auc_score(test_labels_onehot, test_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    # Reliability diagram\n",
    "    plot_reliability(test_labels, test_probs, class_names, n_bins=10)\n",
    "\n",
    "    # TTA evaluation\n",
    "    print(\"\\nTTA Evaluation:\")\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomHorizontalFlip(1.0),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.RandomRotation(15),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(280), transforms.CenterCrop(224),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.GaussianBlur(3),\n",
    "                            transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                        [0.229, 0.224, 0.225])]),\n",
    "    ]\n",
    "\n",
    "    # Build a raw dataset we can retarget transforms onto\n",
    "    tta_base_ds = ImageFolder(os.path.join(data_root, \"test\"))  # no transform here\n",
    "    y_true = np.array(tta_base_ds.targets)\n",
    "    y_agg = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t in tta_transforms:\n",
    "            tta_base_ds.transform = t\n",
    "            loader = DataLoader(tta_base_ds, batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "            probs_chunks = []\n",
    "            for imgs, _ in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                logits = model(imgs)\n",
    "                probs_chunks.append(F.softmax(logits, dim=1).cpu().numpy())\n",
    "            y_agg.append(np.concatenate(probs_chunks, axis=0))\n",
    "\n",
    "    final_probs = np.mean(y_agg, axis=0)\n",
    "    final_preds = final_probs.argmax(axis=1)\n",
    "    print(classification_report(y_true, final_preds, target_names=class_names))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, final_preds))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T03:31:37.385047Z",
     "iopub.status.busy": "2025-08-28T03:31:37.384557Z",
     "iopub.status.idle": "2025-08-28T03:52:37.614461Z",
     "shell.execute_reply": "2025-08-28T03:52:37.613329Z",
     "shell.execute_reply.started": "2025-08-28T03:31:37.385025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/kaggle/working/finetune_simsiam.py:318: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "\n",
      "Epoch 1/50\n",
      "Train:   0%|                                             | 0/15 [00:00<?, ?it/s]/kaggle/working/finetune_simsiam.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "Train Loss: 1.1041, Acc: 0.4038 | Val Loss: 1.1329, Acc: 0.3131                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 2/50\n",
      "Train Loss: 1.0602, Acc: 0.4207 | Val Loss: 1.1042, Acc: 0.3131                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 3/50\n",
      "Train Loss: 1.0708, Acc: 0.4017 | Val Loss: 1.0249, Acc: 0.3434                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 4/50\n",
      "Train Loss: 1.0383, Acc: 0.4292 | Val Loss: 0.8619, Acc: 0.6566                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 5/50\n",
      "Train Loss: 1.0468, Acc: 0.4482 | Val Loss: 0.9029, Acc: 0.6162                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 6/50\n",
      "Train Loss: 1.0258, Acc: 0.4545 | Val Loss: 0.8405, Acc: 0.6667                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 7/50\n",
      "Train Loss: 1.0044, Acc: 0.5159 | Val Loss: 0.8352, Acc: 0.7172                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 8/50\n",
      "Train Loss: 1.0015, Acc: 0.4863 | Val Loss: 0.8375, Acc: 0.6465                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 9/50\n",
      "Train Loss: 0.9871, Acc: 0.5095 | Val Loss: 0.7904, Acc: 0.6465                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 10/50\n",
      "Train Loss: 0.9652, Acc: 0.5180 | Val Loss: 0.7547, Acc: 0.7172                 \n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 11/50\n",
      "Train Loss: 0.9505, Acc: 0.5624 | Val Loss: 0.7357, Acc: 0.7374                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 12/50\n",
      "Train Loss: 0.9183, Acc: 0.5603 | Val Loss: 0.7268, Acc: 0.6970                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 13/50\n",
      "Train Loss: 0.9134, Acc: 0.5518 | Val Loss: 0.6499, Acc: 0.7677                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 14/50\n",
      "Train Loss: 0.9060, Acc: 0.5814 | Val Loss: 0.6338, Acc: 0.7576                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 15/50\n",
      "Train Loss: 0.8650, Acc: 0.6237 | Val Loss: 0.6167, Acc: 0.7879                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 16/50\n",
      "Train Loss: 0.8853, Acc: 0.6089 | Val Loss: 0.6622, Acc: 0.7576                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 17/50\n",
      "Train Loss: 0.8964, Acc: 0.5899 | Val Loss: 0.5711, Acc: 0.8182                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 18/50\n",
      "Train Loss: 0.9366, Acc: 0.5624 | Val Loss: 0.5783, Acc: 0.8081                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 19/50\n",
      "Train Loss: 0.8995, Acc: 0.6068 | Val Loss: 0.6043, Acc: 0.7879                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 20/50\n",
      "Train Loss: 0.8254, Acc: 0.6279 | Val Loss: 0.4643, Acc: 0.8889                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 21/50\n",
      "Train Loss: 0.8849, Acc: 0.6004 | Val Loss: 0.5498, Acc: 0.8283                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 22/50\n",
      "Train Loss: 0.8529, Acc: 0.5920 | Val Loss: 0.4938, Acc: 0.8485                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 23/50\n",
      "Train Loss: 0.8434, Acc: 0.6195 | Val Loss: 0.4973, Acc: 0.8687                 \n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 24/50\n",
      "Train Loss: 0.8217, Acc: 0.6364 | Val Loss: 0.5026, Acc: 0.8182                 \n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 25/50\n",
      "Train Loss: 0.8563, Acc: 0.6279 | Val Loss: 0.5000, Acc: 0.8384                 \n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 26/50\n",
      "Train Loss: 0.8329, Acc: 0.6427 | Val Loss: 0.5082, Acc: 0.8283                 \n",
      "EarlyStopping counter: 6 / 7\n",
      "\n",
      "Epoch 27/50\n",
      "Train Loss: 0.7662, Acc: 0.6702 | Val Loss: 0.5455, Acc: 0.8182                 \n",
      "EarlyStopping counter: 7 / 7\n",
      "Early stopping triggered.\n",
      "\n",
      "Test set results:\n",
      "Test Loss: 0.4144, Test Acc: 0.9495                                             \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.97      0.89      0.93        37\n",
      "Healthy Leaf       0.88      0.97      0.92        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.95      0.95      0.95        99\n",
      "\n",
      "Confusion Matrix:\n",
      " [[33  4  0]\n",
      " [ 1 30  0]\n",
      " [ 0  0 31]]\n",
      "Test ROC-AUC (macro): 0.9947\n",
      "Figure(500x500)\n",
      "\n",
      "TTA Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       0.94      0.92      0.93        37\n",
      "Healthy Leaf       0.91      0.94      0.92        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.95      0.95      0.95        99\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34  3  0]\n",
      " [ 2 29  0]\n",
      " [ 0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "!python finetune_simsiam.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid loss: Supervised Contrastive + CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T03:56:26.943479Z",
     "iopub.status.busy": "2025-08-28T03:56:26.943151Z",
     "iopub.status.idle": "2025-08-28T03:56:26.956130Z",
     "shell.execute_reply": "2025-08-28T03:56:26.955307Z",
     "shell.execute_reply.started": "2025-08-28T03:56:26.943450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting finetune_hybrid.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile finetune_hybrid.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def seed_all(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Mixup helpers\n",
    "# ----------------------------\n",
    "def mixup_data(x: torch.Tensor, y: torch.Tensor, alpha: float = 0.4, device=None):\n",
    "    if alpha and alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=device)\n",
    "    mixed_x = lam * x + (1.0 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam: float):\n",
    "    return lam * criterion(pred, y_a) + (1.0 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataloaders\n",
    "# ----------------------------\n",
    "def get_loaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str,\n",
    "    test_dir: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 2,\n",
    "):\n",
    "    pin = torch.cuda.is_available()\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    eval_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = ImageFolder(train_dir, transform=train_transform)\n",
    "    val_ds   = ImageFolder(val_dir,   transform=eval_transform)\n",
    "    test_ds  = ImageFolder(test_dir,  transform=eval_transform)\n",
    "\n",
    "    # Derive class names from data\n",
    "    class_names = train_ds.classes\n",
    "\n",
    "    # Balanced sampling\n",
    "    targets_np = np.array(train_ds.targets, dtype=np.int64)\n",
    "    classes = np.unique(targets_np)\n",
    "    class_sample_count = np.array([(targets_np == t).sum() for t in classes], dtype=np.float64)\n",
    "    class_sample_count[class_sample_count == 0] = 1.0\n",
    "    weights = 1.0 / class_sample_count\n",
    "    samples_weights = weights[targets_np]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.as_tensor(samples_weights, dtype=torch.double),\n",
    "        num_samples=len(samples_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, sampler=sampler,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader, class_names, test_ds\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Supervised Contrastive Loss (corrected)\n",
    "# ----------------------------\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature: float = 0.07, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, features: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        features: (B, D) float\n",
    "        labels:   (B,)   int\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        # Compute in float32 for stability (even under autocast)\n",
    "        f = F.normalize(features, dim=1).float()\n",
    "        B = f.size(0)\n",
    "        labels = labels.contiguous().view(-1, 1)  # (B,1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)  # (B,B)\n",
    "        mask.fill_diagonal_(0)  # remove self-positives\n",
    "\n",
    "        logits = (f @ f.T) / self.temperature  # (B,B)\n",
    "        logits_max, _ = torch.max(logits, dim=1, keepdim=True)\n",
    "        logits = logits - logits_max.detach()\n",
    "\n",
    "        # Exclude self from denominator\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(B, device=device))\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + self.eps)\n",
    "\n",
    "        pos_count = mask.sum(1)  # (B,)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (pos_count + self.eps)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model definition\n",
    "# ----------------------------\n",
    "class FineTuneModel(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-50 backbone (loaded from SimSiam 'backbone') +\n",
    "    - feature_layer (D=2048 -> 128) for SupCon\n",
    "    - classifier head for CE\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_path: str, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])  # up to avgpool\n",
    "        self.feature_layer = nn.Linear(2048, 128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Load SimSiam backbone weights (robust to minor key diffs)\n",
    "        ckpt = torch.load(pretrained_path, map_location=\"cpu\")\n",
    "        sd = ckpt.get(\"backbone\", ckpt)\n",
    "        missing, unexpected = self.backbone.load_state_dict(sd, strict=False)\n",
    "        if missing or unexpected:\n",
    "            print(f\"[state_dict notice] missing: {missing} | unexpected: {unexpected}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, return_features: bool = False):\n",
    "        feats = self.backbone(x).flatten(1)           # (B, 2048)\n",
    "        logits = self.classifier(feats)               # (B, C)\n",
    "        proj = F.normalize(self.feature_layer(feats), dim=1)  # (B, 128)\n",
    "        return (logits, proj) if return_features else logits\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval\n",
    "# ----------------------------\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    ce_loss_fn,\n",
    "    supcon_loss_fn: SupConLoss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    scaler: torch.cuda.amp.GradScaler,\n",
    "    use_mixup: bool = True,\n",
    "    mixup_alpha: float = 0.4,\n",
    "    supcon_weight: float = 0.5\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Hybrid loss:\n",
    "      - SupCon on CLEAN images (features from a clean forward)\n",
    "      - CE on MIXED images (logits from a second forward)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = total_ce = total_sup = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs = imgs.to(device); labels = labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "            # Clean forward for SupCon features\n",
    "            logits_clean, feats_clean = model(imgs, return_features=True)\n",
    "            loss_sup = supcon_loss_fn(feats_clean, labels)\n",
    "\n",
    "            # CE branch: mixup (optional)\n",
    "            if use_mixup and mixup_alpha > 0.0:\n",
    "                mixed, y_a, y_b, lam = mixup_data(imgs, labels, alpha=mixup_alpha, device=device)\n",
    "                logits_mixed = model(mixed)\n",
    "                loss_ce = mixup_criterion(ce_loss_fn, logits_mixed, y_a, y_b, lam)\n",
    "                preds = logits_mixed.argmax(1)\n",
    "                correct += (lam * preds.eq(y_a).sum().item()\n",
    "                            + (1.0 - lam) * preds.eq(y_b).sum().item())\n",
    "            else:\n",
    "                loss_ce = ce_loss_fn(logits_clean, labels)\n",
    "                preds = logits_clean.argmax(1)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "\n",
    "            loss = (1.0 - supcon_weight) * loss_ce + supcon_weight * loss_sup\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        total_loss += float(loss.item()) * bs\n",
    "        total_ce   += float(loss_ce.item()) * bs\n",
    "        total_sup  += float(loss_sup.item()) * bs\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, correct / n, total_ce / n, total_sup / n\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    all_labels: List[int] = []\n",
    "    all_preds:  List[int] = []\n",
    "    all_probs:  List[np.ndarray] = []\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += float(loss.item()) * imgs.size(0)\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return (total_loss / len(loader.dataset),\n",
    "            correct / len(loader.dataset),\n",
    "            np.array(all_labels),\n",
    "            np.array(all_preds),\n",
    "            np.array(all_probs))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Early stopping\n",
    "# ----------------------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int = 7, verbose: bool = True):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_acc = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_acc: float, model: nn.Module, path: str):\n",
    "        if self.best_acc is None or val_acc > self.best_acc:\n",
    "            self.best_acc = val_acc\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(\"Validation accuracy improved, saving model.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Grad-CAM (robust, optional)\n",
    "# ----------------------------\n",
    "def save_gradcams(model: nn.Module, test_ds: ImageFolder, class_names: List[str], device: torch.device):\n",
    "    try:\n",
    "        from pytorch_grad_cam import GradCAM\n",
    "        from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "        from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    except Exception as e:\n",
    "        print(f\"[grad-cam] Skipping (package not available): {e}\")\n",
    "        return\n",
    "\n",
    "    # Target the last conv inside layer4\n",
    "    # backbone = [.., layer4, avgpool]; pick last Bottleneck in layer4\n",
    "    try:\n",
    "        last_block = model.backbone[-2][-1]  # layer4[-1]\n",
    "        target_layer = getattr(last_block, \"conv3\", last_block)  # conv3 if present\n",
    "    except Exception:\n",
    "        target_layer = model.backbone[-2]  # fallback: whole layer4\n",
    "\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    model.eval()\n",
    "\n",
    "    from PIL import Image as PILImage\n",
    "    # Build a raw (untransformed) dataset view to re-transform\n",
    "    base_ds = ImageFolder(test_ds.root)\n",
    "\n",
    "    # Use the same eval transform as loaders\n",
    "    eval_transform = transforms.Compose([\n",
    "        transforms.Resize(256), transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    for i, cls in enumerate(class_names):\n",
    "        idxs = [j for j, t in enumerate(base_ds.targets) if t == i]\n",
    "        if not idxs:\n",
    "            print(f\"[grad-cam] No samples for class {cls}\")\n",
    "            continue\n",
    "        idx = random.choice(idxs)\n",
    "        img, _ = base_ds[idx]\n",
    "        img_tensor = eval_transform(PILImage.open(base_ds.samples[idx][0]).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        grayscale_cam = cam(input_tensor=img_tensor, targets=[ClassifierOutputTarget(i)])[0]\n",
    "        # De-normalize for visualization\n",
    "        img_np = np.transpose(img_tensor[0].cpu().numpy(), (1, 2, 0))\n",
    "        img_np = (img_np * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        cam_image = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.imshow(cam_image)\n",
    "        plt.title(f\"Grad-CAM: {cls} (hybrid loss)\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"gradcam_{cls}_hybrid_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main(\n",
    "    data_root: str = \"/kaggle/input/minida/mini_output1\",\n",
    "    pretrained_path: str = \"/kaggle/working/simsiam_vanilla_resnet/simsiam_pretrained.pth\",\n",
    "    epochs: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 2,\n",
    "    mixup_alpha: float = 0.4,\n",
    "    supcon_weight: float = 0.5\n",
    "):\n",
    "    seed_all(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_dir = os.path.join(data_root, \"train\")\n",
    "    val_dir   = os.path.join(data_root, \"val\")\n",
    "    test_dir  = os.path.join(data_root, \"test\")\n",
    "    if not os.path.exists(pretrained_path):\n",
    "        raise FileNotFoundError(f\"Pretrained weights not found at {pretrained_path}\")\n",
    "\n",
    "    train_loader, val_loader, test_loader, class_names, test_ds = get_loaders(\n",
    "        train_dir, val_dir, test_dir, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # Build model\n",
    "    model = FineTuneModel(pretrained_path, num_classes=len(class_names)).to(device)\n",
    "\n",
    "    # Ensure BN uses batch stats during supervised finetune\n",
    "    for m in model.backbone.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.train()\n",
    "            m.requires_grad_(True)\n",
    "\n",
    "    # Parameter groups: smaller LR for backbone\n",
    "    backbone_params, head_params = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        (head_params if (\"classifier\" in n or \"feature_layer\" in n) else backbone_params).append(p)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": backbone_params, \"lr\": 3e-5},\n",
    "            {\"params\": head_params,     \"lr\": 1e-4},\n",
    "        ],\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    ce_loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    supcon_loss_fn = SupConLoss(temperature=0.07)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "    early_stopper = EarlyStopping(patience=7, verbose=True)\n",
    "    best_model_path = \"best_model_hybrid_loss.pth\"\n",
    "\n",
    "    # Train loop\n",
    "    train_losses, train_accs, train_ce_losses, train_sup_losses = [], [], [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        tr_loss, tr_acc, tr_ce, tr_sup = train_epoch(\n",
    "            model, train_loader, ce_loss_fn, supcon_loss_fn, optimizer, device, scaler,\n",
    "            use_mixup=True, mixup_alpha=mixup_alpha, supcon_weight=supcon_weight\n",
    "        )\n",
    "        va_loss, va_acc, _, _, _ = eval_epoch(model, val_loader, ce_loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Train Loss: {tr_loss:.4f}, Acc: {tr_acc:.4f} | \"\n",
    "              f\"Val Loss: {va_loss:.4f}, Acc: {va_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(tr_loss);  train_accs.append(tr_acc)\n",
    "        train_ce_losses.append(tr_ce); train_sup_losses.append(tr_sup)\n",
    "        val_losses.append(va_loss);    val_accs.append(va_acc)\n",
    "\n",
    "        early_stopper(va_acc, model, best_model_path)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Evaluate best model\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "\n",
    "    print(\"\\nTest set results:\")\n",
    "    te_loss, te_acc, te_labels, te_preds, te_probs = eval_epoch(model, test_loader, ce_loss_fn, device)\n",
    "    print(f\"Test Loss: {te_loss:.4f}, Test Acc: {te_acc:.4f}\")\n",
    "    print(classification_report(te_labels, te_preds, target_names=class_names))\n",
    "    try:\n",
    "        te_onehot = np.eye(len(class_names))[te_labels]\n",
    "        roc_macro = roc_auc_score(te_onehot, te_probs, average='macro', multi_class='ovr')\n",
    "        print(f\"Test ROC-AUC (macro): {roc_macro:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "    # Optional Grad-CAM visualizations\n",
    "    print(\"\\nRunning Grad-CAMs (if package available)...\")\n",
    "    save_gradcams(model, test_ds, class_names, device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T03:56:29.301700Z",
     "iopub.status.busy": "2025-08-28T03:56:29.301415Z",
     "iopub.status.idle": "2025-08-28T04:19:13.046127Z",
     "shell.execute_reply": "2025-08-28T04:19:13.045392Z",
     "shell.execute_reply.started": "2025-08-28T03:56:29.301680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/kaggle/working/finetune_hybrid.py:415: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "\n",
      "Epoch 1/50\n",
      "Train:   0%|                                             | 0/15 [00:00<?, ?it/s]/kaggle/working/finetune_hybrid.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "Train Loss: 2.2731, Acc: 0.4010 | Val Loss: 1.1937, Acc: 0.3131                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 2/50\n",
      "Train Loss: 2.2401, Acc: 0.4201 | Val Loss: 1.0096, Acc: 0.5758                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 3/50\n",
      "Train Loss: 2.2215, Acc: 0.4805 | Val Loss: 0.9161, Acc: 0.5556                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 4/50\n",
      "Train Loss: 2.2052, Acc: 0.4573 | Val Loss: 0.8967, Acc: 0.6667                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 5/50\n",
      "Train Loss: 2.1989, Acc: 0.4714 | Val Loss: 0.8267, Acc: 0.6162                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 6/50\n",
      "Train Loss: 2.2027, Acc: 0.4704 | Val Loss: 0.8486, Acc: 0.6263                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 7/50\n",
      "Train Loss: 2.1861, Acc: 0.5162 | Val Loss: 0.8167, Acc: 0.6869                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 8/50\n",
      "Train Loss: 2.1752, Acc: 0.5025 | Val Loss: 0.8035, Acc: 0.6768                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 9/50\n",
      "Train Loss: 2.1313, Acc: 0.5649 | Val Loss: 0.7076, Acc: 0.7071                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 10/50\n",
      "Train Loss: 2.1461, Acc: 0.5430 | Val Loss: 0.7691, Acc: 0.6465                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 11/50\n",
      "Train Loss: 2.1373, Acc: 0.5489 | Val Loss: 0.6849, Acc: 0.7374                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 12/50\n",
      "Train Loss: 2.1270, Acc: 0.5327 | Val Loss: 0.6784, Acc: 0.7071                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 13/50\n",
      "Train Loss: 2.0904, Acc: 0.5913 | Val Loss: 0.6304, Acc: 0.7778                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 14/50\n",
      "Train Loss: 2.0628, Acc: 0.6002 | Val Loss: 0.6243, Acc: 0.7576                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 15/50\n",
      "Train Loss: 2.0826, Acc: 0.5838 | Val Loss: 0.5863, Acc: 0.8485                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 16/50\n",
      "Train Loss: 2.1120, Acc: 0.5535 | Val Loss: 0.6092, Acc: 0.7475                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 17/50\n",
      "Train Loss: 2.0490, Acc: 0.6339 | Val Loss: 0.5747, Acc: 0.7475                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 18/50\n",
      "Train Loss: 2.1389, Acc: 0.5854 | Val Loss: 0.6292, Acc: 0.7374                 \n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 19/50\n",
      "Train Loss: 2.1026, Acc: 0.6254 | Val Loss: 0.5829, Acc: 0.8788                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 20/50\n",
      "Train Loss: 2.0750, Acc: 0.6341 | Val Loss: 0.5147, Acc: 0.8283                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 21/50\n",
      "Train Loss: 2.0447, Acc: 0.6113 | Val Loss: 0.5004, Acc: 0.8586                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 22/50\n",
      "Train Loss: 2.0336, Acc: 0.6548 | Val Loss: 0.5579, Acc: 0.7677                 \n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 23/50\n",
      "Train Loss: 2.0353, Acc: 0.6257 | Val Loss: 0.4455, Acc: 0.8990                 \n",
      "Validation accuracy improved, saving model.\n",
      "\n",
      "Epoch 24/50\n",
      "Train Loss: 2.0187, Acc: 0.6380 | Val Loss: 0.4990, Acc: 0.8586                 \n",
      "EarlyStopping counter: 1 / 7\n",
      "\n",
      "Epoch 25/50\n",
      "Train Loss: 2.0235, Acc: 0.6224 | Val Loss: 0.4963, Acc: 0.8384                 \n",
      "EarlyStopping counter: 2 / 7\n",
      "\n",
      "Epoch 26/50\n",
      "Train Loss: 1.9774, Acc: 0.6858 | Val Loss: 0.4412, Acc: 0.8687                 \n",
      "EarlyStopping counter: 3 / 7\n",
      "\n",
      "Epoch 27/50\n",
      "Train Loss: 1.9898, Acc: 0.6538 | Val Loss: 0.4400, Acc: 0.8788                 \n",
      "EarlyStopping counter: 4 / 7\n",
      "\n",
      "Epoch 28/50\n",
      "Train Loss: 2.0109, Acc: 0.6519 | Val Loss: 0.4407, Acc: 0.8889                 \n",
      "EarlyStopping counter: 5 / 7\n",
      "\n",
      "Epoch 29/50\n",
      "Train Loss: 1.9433, Acc: 0.6764 | Val Loss: 0.4555, Acc: 0.8788                 \n",
      "EarlyStopping counter: 6 / 7\n",
      "\n",
      "Epoch 30/50\n",
      "Train Loss: 1.9667, Acc: 0.6646 | Val Loss: 0.4674, Acc: 0.8485                 \n",
      "EarlyStopping counter: 7 / 7\n",
      "Early stopping triggered.\n",
      "\n",
      "Test set results:\n",
      "Test Loss: 0.4045, Test Acc: 0.9495                                             \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Alternaria       1.00      0.86      0.93        37\n",
      "Healthy Leaf       0.86      1.00      0.93        31\n",
      "  straw_mite       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.95      0.95      0.95        99\n",
      "weighted avg       0.96      0.95      0.95        99\n",
      "\n",
      "Test ROC-AUC (macro): 0.9947\n",
      "\n",
      "Running Grad-CAMs (if package available)...\n"
     ]
    }
   ],
   "source": [
    "!python finetune_hybrid.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7808913,
     "sourceId": 12383979,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
